{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77fd748",
   "metadata": {},
   "source": [
    "# Text-Deconfounded Factorization Model (TDFM)\n",
    "\n",
    "This notebook trains and evaluates:\n",
    "- **MF baseline** (ratings-only)\n",
    "- **TDFM hybrid model** (ratings + text topics + exposure), using the *same train/test split* (no text leakage)\n",
    "\n",
    "Sections:\n",
    "1. Reproducibility utilities (seed + shared split indices)\n",
    "2. Shared data preparation (data loading via fetch+preprocess or `clean_reviews.csv`; vectorizer fit on train only)\n",
    "3. Dataloaders (MF and TDFM share the exact same split)\n",
    "4. MF baseline (same split)\n",
    "5. TDFM model + training (same split)\n",
    "6. Run MF vs TDFM + summary (same split, no leakage)\n",
    "7. Topic inspection (uses saved vocab + full hybrid checkpoint; no vectorizer rebuild)\n",
    "8. Robustness upgrades (trained ablation / topic-collapse diagnostics / ranking sweep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21140202",
   "metadata": {},
   "source": [
    "## How to run this notebook (reproducible)\n",
    "\n",
    "1. **Restart kernel → Run All** (recommended).\n",
    "2. This notebook will (re)create these local artifacts:\n",
    "   - `clean_reviews.csv` (cleaned dataset)\n",
    "   - `split_idx.pt` (fixed train/test indices shared by MF and TDFM)\n",
    "   - `tdfm_vocab.npy` (CountVectorizer vocab **fit on train only**)\n",
    "   - `tdfm_model_seed*.pt` (and related checkpoint files, depending on your seed loop)\n",
    "   - `confounders_baseline.pt` is **optional** (if present, it provides an exposure/confounder proxy for deconfounded ranking / IPW evaluation).\n",
    "\n",
    "**Runtime knobs:** `EPOCHS`, number of seeds, bootstrap iterations `B`, and ranking sweep grid (`N_NEG × K`) control total runtime.\n",
    "\n",
    "**Expected outputs:** (i) MF vs TDFM rating metrics (RMSE/MAE) with bootstrap CIs, (ii) ranking metrics (Recall@K/NDCG@K) with negative sampling sweeps, (iii) topic inspection + collapse diagnostics, and (iv) trained no-topic ablation (fair ablation) results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d469f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & global settings ---\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, html\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Experiment hyperparameters ---\n",
    "SEED = 0\n",
    "\n",
    "NUM_TOPICS = 10\n",
    "EMBEDDING_DIM = 8\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Text settings\n",
    "MAX_FEATURES = 1000\n",
    "STOP_WORDS = \"english\"\n",
    "\n",
    "CSV_PATH = \"clean_reviews.csv\"\n",
    "CONFOUNDER_PATH = \"confounders_baseline.pt\"   # optional\n",
    "SPLIT_PATH = \"split_idx.pt\"\n",
    "\n",
    "DEVICE = \"cpu\" \n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12983197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "def load_and_process_data(min_interactions=2):\n",
    "    print(\"Step 1: Fetching data from UCI Repository (ID=911)...\")\n",
    "    \n",
    "    try:\n",
    "        # Fetch dataset\n",
    "        recipe_data = fetch_ucirepo(id=911)\n",
    "        X = recipe_data.data.features\n",
    "        y = recipe_data.data.targets\n",
    "        \n",
    "        # Combine into one DataFrame\n",
    "        df = pd.concat([X, y], axis=1)\n",
    "        \n",
    "        # --- Map the actual columns found ---\n",
    "        # Output: ['user_id', 'recipe_code', 'stars', 'text', ...]\n",
    "        df = df.rename(columns={\n",
    "            'recipe_code': 'item_id',  # Unique ID for the recipe\n",
    "            'stars': 'rating',         # The target variable\n",
    "            'text': 'review'           # The text for LDA\n",
    "        })\n",
    "        \n",
    "        # Ensure user_id is treated as string/ID\n",
    "        df['user_id'] = df['user_id'].astype(str)\n",
    "        \n",
    "        print(f\"Initial shape: {df.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Drop rows where critical data is missing\n",
    "    df = df.dropna(subset=['rating', 'review', 'user_id', 'item_id'])\n",
    "    \n",
    "    # --- Step 2: Iterative Filtering (Core \"Dense\" Requirement) ---\n",
    "    # This loop removes sparse users, then sparse items, then checks again...\n",
    "    # untill both users and items all have > min_interactions.\n",
    "    print(f\"Step 2: Filtering for dense interactions (> {min_interactions})...\")\n",
    "    \n",
    "    initial_rows = len(df)\n",
    "    while True:\n",
    "        user_counts = df.groupby('user_id').size()\n",
    "        item_counts = df.groupby('item_id').size()\n",
    "        \n",
    "        valid_users = user_counts[user_counts >= min_interactions].index\n",
    "        valid_items = item_counts[item_counts >= min_interactions].index\n",
    "        \n",
    "        old_shape = df.shape\n",
    "        df = df[df['user_id'].isin(valid_users) & df['item_id'].isin(valid_items)]\n",
    "        \n",
    "        if df.shape == old_shape:\n",
    "            break\n",
    "            \n",
    "    print(f\"Final filtered shape: {df.shape} (Removed {initial_rows - len(df)} rows)\")\n",
    "    print(f\"Unique Users: {df['user_id'].nunique()}\")\n",
    "    print(f\"Unique Recipes: {df['item_id'].nunique()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def save_preprocessed_data(df):\n",
    "    print(\"Step 3: Saving clean data to 'clean_reviews.csv'...\")\n",
    "    df.to_csv(\"clean_reviews.csv\", index=False)\n",
    "    print(\"Done! You can now load this CSV for your model training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628164a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Fetching data from UCI Repository (ID=911)...\n",
      "Initial shape: (18182, 15)\n",
      "Step 2: Filtering for dense interactions (> 2)...\n",
      "Final filtered shape: (6478, 15) (Removed 11702 rows)\n",
      "Unique Users: 2110\n",
      "Unique Recipes: 100\n",
      "Step 3: Saving clean data to 'clean_reviews.csv'...\n",
      "Done! You can now load this CSV for your model training.\n"
     ]
    }
   ],
   "source": [
    "df = load_and_process_data(min_interactions=2)\n",
    "if df is not None:\n",
    "    save_preprocessed_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0186e37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "After dropping zeros: 6085 rows; rating min/max: 1 5\n",
      "Dataset Stats: 2021 Users, 100 Items, 6085 Interactions\n",
      "Initializing Poisson Factorization (K=20)...\n",
      "Epoch 0: Loss = 24755.0098\n",
      "Epoch 20: Loss = 17526.0391\n",
      "Epoch 40: Loss = 15140.1084\n",
      "Epoch 60: Loss = 13411.6123\n",
      "Epoch 80: Loss = 12487.6270\n",
      "Epoch 100: Loss = 12005.3574\n",
      "Epoch 120: Loss = 11728.8945\n",
      "Epoch 140: Loss = 11579.7070\n",
      "Epoch 160: Loss = 11527.9326\n",
      "Epoch 180: Loss = 11515.2891\n",
      "Epoch 200: Loss = 11512.5273\n",
      "Epoch 220: Loss = 11511.8242\n",
      "Epoch 240: Loss = 11511.5029\n",
      "Epoch 260: Loss = 11511.3232\n",
      "Epoch 280: Loss = 11511.2178\n",
      "Epoch 300: Loss = 11511.1533\n",
      "Epoch 320: Loss = 11511.1113\n",
      "Epoch 340: Loss = 11511.0830\n",
      "Epoch 360: Loss = 11511.0645\n",
      "Epoch 380: Loss = 11511.0518\n",
      "Epoch 400: Loss = 11511.0430\n",
      "Epoch 420: Loss = 11511.0361\n",
      "Epoch 440: Loss = 11511.0312\n",
      "Epoch 460: Loss = 11511.0293\n",
      "Epoch 480: Loss = 11511.0264\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Complete.\n",
      "Learned Confounder Matrix Shape: torch.Size([2021, 100])\n",
      "Example Confounder values for User 0: [1.9385606e-09 1.5309554e-09 1.9856607e-09 1.7335987e-09 1.3577460e-09]\n",
      "Baseline confounders saved to 'confounders_baseline.pt'\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Data Loading & Matrix Construction ---\n",
    "def load_data(filepath='clean_reviews.csv'):\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    # drop missing/placeholder ratings (keep only 1–5)\n",
    "    df = df[df[\"rating\"] > 0].copy().reset_index(drop=True)\n",
    "    print(\"After dropping zeros:\", len(df), \"rows; rating min/max:\", df[\"rating\"].min(), df[\"rating\"].max())\n",
    "\n",
    "    # Ensure IDs are strings so mapping keys match exactly\n",
    "    df['user_id'] = df['user_id'].astype(str)\n",
    "    df['item_id'] = df['item_id'].astype(str)\n",
    "    \n",
    "    # Map IDs to contiguous integers (0 to N-1)\n",
    "    # We do this to ensure we can index into our embedding matrices correctly\n",
    "    u_unique = np.sort(df['user_id'].unique())\n",
    "    i_unique = np.sort(df['item_id'].unique())\n",
    "    \n",
    "    user_map = {uid: idx for idx, uid in enumerate(u_unique)}\n",
    "    item_map = {iid: idx for idx, iid in enumerate(i_unique)}\n",
    "    \n",
    "    df['u_idx'] = df['user_id'].map(user_map)\n",
    "    df['i_idx'] = df['item_id'].map(item_map)\n",
    "\n",
    "    # Safety check: mapping should not create missing indices\n",
    "    if df['u_idx'].isna().any() or df['i_idx'].isna().any():\n",
    "        bad = df[df['u_idx'].isna() | df['i_idx'].isna()][['user_id','item_id']].head(5)\n",
    "        raise ValueError(f\"Found unmapped user/item ids. Example rows:\\n{bad}\")\n",
    "    df['u_idx'] = df['u_idx'].astype(np.int64)\n",
    "    df['i_idx'] = df['i_idx'].astype(np.int64)\n",
    "    \n",
    "    num_users = len(u_unique)\n",
    "    num_items = len(i_unique)\n",
    "    \n",
    "    print(f\"Dataset Stats: {num_users} Users, {num_items} Items, {len(df)} Interactions\")\n",
    "    \n",
    "    # Create the Full Exposure Matrix A (Dense)\n",
    "    # Since the dataset is filtered and dense (approx 2000x100), we can handle \n",
    "    # the full matrix in memory easily. This simplifies the math implementation.\n",
    "    A = torch.zeros((num_users, num_items))\n",
    "    A[df['u_idx'].values, df['i_idx'].values] = 1.0\n",
    "    \n",
    "    return A, df, num_users, num_items, u_unique, i_unique\n",
    "\n",
    "# --- 2. The Probabilistic Model (Poisson Factorization) ---\n",
    "class PoissonFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, k=10):\n",
    "        super().__init__()\n",
    "        # Dimensions\n",
    "        self.k = k\n",
    "        \n",
    "        # Latent Factors (Theta and Beta in generic terms, or Pi/Lambda in Wang et al)\n",
    "        # We initialize them to be positive (Poisson parameters must be > 0)\n",
    "        self.user_factors = nn.Parameter(torch.rand(num_users, k) * 0.1)\n",
    "        self.item_factors = nn.Parameter(torch.rand(num_items, k) * 0.1)\n",
    "        \n",
    "    def forward(self):\n",
    "        # Reconstruct the expected count matrix\n",
    "        # A_hat = Theta * Beta^T\n",
    "        return torch.matmul(self.user_factors, self.item_factors.t())\n",
    "\n",
    "    def get_substitute_confounder(self):\n",
    "        # According to Wang et al., the substitute confounder is the \n",
    "        # predicted exposure probability (or rate)\n",
    "        with torch.no_grad():\n",
    "            return self.forward()\n",
    "\n",
    "# --- 3. Training Loop ---\n",
    "def train_baseline(A_matrix, num_users, num_items, epochs=200, lr=0.01, k=20):\n",
    "    print(f\"Initializing Poisson Factorization (K={k})...\")\n",
    "    model = PoissonFactorization(num_users, num_items, k=k)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # We create a simple holdout mask to verify it's actually learning\n",
    "    # (Randomly hide 10% of interactions just for validation monitoring)\n",
    "    mask = torch.rand_like(A_matrix) > 0.1 \n",
    "    A_train = A_matrix * mask\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: Get predicted rates (lambda)\n",
    "        rate_hat = model()\n",
    "        \n",
    "        # Poisson Log-Likelihood Loss\n",
    "        # Loss = sum( rate_hat - A * log(rate_hat) )\n",
    "        # We add a small epsilon to log to prevent NaN\n",
    "        epsilon = 1e-9\n",
    "        loss = torch.sum(rate_hat - A_train * torch.log(rate_hat + epsilon))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Constraint: Factors must be non-negative for Poisson\n",
    "        # We clamp them after every update\n",
    "        with torch.no_grad():\n",
    "            model.user_factors.clamp_(min=epsilon)\n",
    "            model.item_factors.clamp_(min=epsilon)\n",
    "            \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "            \n",
    "    # Visualize convergence\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Poisson Factorization Convergence\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Negative Log Likelihood\")\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --- Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Prepare Data\n",
    "    try:\n",
    "        A, df, n_u, n_i, user_ids, item_ids = load_data()\n",
    "        \n",
    "        # 2. Train Model\n",
    "        pf_model = train_baseline(A, n_u, n_i, epochs=500, k=20)\n",
    "        \n",
    "        # 3. Get Confounders\n",
    "        # This Z_matrix is what we will use in the next step to \"correct\" \n",
    "        # the Matrix Factorization for ratings\n",
    "        Z_hat = pf_model.get_substitute_confounder()\n",
    "        \n",
    "        print(\"\\nTraining Complete.\")\n",
    "        print(f\"Learned Confounder Matrix Shape: {Z_hat.shape}\")\n",
    "        print(\"Example Confounder values for User 0:\", Z_hat[0, :5].numpy())\n",
    "        \n",
    "        # Save the confounders for the next phase (TDFM)\n",
    "        save_obj = {'Z_hat': Z_hat, 'user_ids': [str(x) for x in user_ids], 'item_ids': [str(x) for x in item_ids]}\n",
    "        torch.save(save_obj, 'confounders_baseline.pt')\n",
    "        print(\"Baseline confounders saved to 'confounders_baseline.pt'\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'clean_reviews.csv' not found. Please run the preprocessing script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ea725",
   "metadata": {},
   "source": [
    "### 1. Reproducibility utilities (seed + shared split indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def make_split_indices(n, seed=0, train_frac=0.8, save_path=\"split_idx.pt\"):\n",
    "    \"\"\"Generate and save a single split that all models reuse.\"\"\"\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    perm = torch.randperm(n, generator=g).tolist()\n",
    "    train_size = int(train_frac * n)\n",
    "    split = {\n",
    "        \"train_idx\": perm[:train_size],\n",
    "        \"test_idx\": perm[train_size:],\n",
    "        \"seed\": seed,\n",
    "        \"train_frac\": train_frac,\n",
    "        \"n\": n,\n",
    "    }\n",
    "    assert len(split[\"train_idx\"]) + len(split[\"test_idx\"]) == n\n",
    "    assert set(split[\"train_idx\"]).isdisjoint(set(split[\"test_idx\"]))\n",
    "    assert min(perm) >= 0 and max(perm) < n\n",
    "    torch.save(split, save_path)\n",
    "    return split\n",
    "\n",
    "def load_or_make_split(n, seed=0, train_frac=0.8, save_path=\"split_idx.pt\"):\n",
    "    if os.path.exists(save_path):\n",
    "        split = torch.load(save_path)\n",
    "        if split.get(\"n\", None) != n:\n",
    "            print(f\"[split] Existing {save_path} has n={split.get('n')}, current n={n}. Regenerating.\")\n",
    "            split = make_split_indices(n, seed=seed, train_frac=train_frac, save_path=save_path)\n",
    "        return split\n",
    "    return make_split_indices(n, seed=seed, train_frac=train_frac, save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3dc538",
   "metadata": {},
   "source": [
    "### 2. Shared data preparation (no text leakage)\n",
    "\n",
    "This section builds the **shared tensors** used by both MF and TDFM:\n",
    "\n",
    "- We first create (or load) a **fixed train/test split by row index** (`split_idx.pt`).\n",
    "- We fit the `CountVectorizer` **on training reviews text only**, then transform *all* rows using that train-fit vocabulary.\n",
    "\n",
    "#### Exposure / confounder proxy (optional)\n",
    "\n",
    "Some experiments use an **exposure proxy** $z_{ui}$ (a scalar per user–item pair) to control for *who was likely to see what*.\n",
    "\n",
    "- The file `confounders_baseline.pt` is **optional**. If present, this notebook expects it to contain either:\n",
    "  - a tensor `Z_hat` of shape `[n_users, n_items]`, or\n",
    "  - a dict with key `'Z_hat'` (and optionally saved `user_ids` / `item_ids` for defensive alignment).\n",
    "- We treat `Z_hat[u,i]` as a **fixed, precomputed propensity/exposure score**: **larger values mean the user–item pair is considered more “exposed”** (e.g., more likely to be shown / encountered due to popularity or logging policy).\n",
    "- For strict experimental hygiene, `Z_hat` should be computed **from interaction-only information** and ideally **using the training split** (so evaluation does not indirectly use test rows).\n",
    "- If the file is missing, we set exposure to zeros and TDFM reduces to a text-augmented MF model without exposure adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s: str) -> str:\n",
    "    s = html.unescape(str(s))\n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def prepare_common_tensors(\n",
    "    csv_path=CSV_PATH,\n",
    "    confounder_path=CONFOUNDER_PATH,\n",
    "    max_features=MAX_FEATURES,\n",
    "    stop_words=STOP_WORDS,\n",
    "    seed=SEED,\n",
    "    split_path=SPLIT_PATH,\n",
    "):\n",
    "    set_seed(seed)\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"Missing {csv_path}. Create it first.\")\n",
    "\n",
    "    df = pd.read_csv(csv_path).copy()\n",
    "    # Drop missing/placeholder ratings\n",
    "    df = df[df[\"rating\"] > 0].copy().reset_index(drop=True)\n",
    "    print(\"After dropping zeros:\", len(df), \"rows; rating min/max:\", df[\"rating\"].min(), df[\"rating\"].max())\n",
    "\n",
    "    # Make sure IDs are consistent strings\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str).str.strip()\n",
    "    df[\"item_id\"] = df[\"item_id\"].astype(str).str.strip()\n",
    "\n",
    "    u_unique = np.sort(df[\"user_id\"].unique())\n",
    "    i_unique = np.sort(df[\"item_id\"].unique())\n",
    "    user_map = {uid: idx for idx, uid in enumerate(u_unique)}\n",
    "    item_map = {iid: idx for idx, iid in enumerate(i_unique)}\n",
    "\n",
    "    df[\"u_idx\"] = df[\"user_id\"].map(user_map)\n",
    "    df[\"i_idx\"] = df[\"item_id\"].map(item_map)\n",
    "\n",
    "    # Safety check (this is what prevents the IntCastingNaNError)\n",
    "    if df[\"u_idx\"].isna().any() or df[\"i_idx\"].isna().any():\n",
    "        print(\"Unmapped u:\", df[\"u_idx\"].isna().sum(), \" / \", len(df))\n",
    "        print(\"Unmapped i:\", df[\"i_idx\"].isna().sum(), \" / \", len(df))\n",
    "        bad = df[df[\"u_idx\"].isna() | df[\"i_idx\"].isna()][[\"user_id\",\"item_id\"]].head(10)\n",
    "        raise ValueError(f\"Unmapped ids exist. Examples:\\n{bad}\")\n",
    "\n",
    "    df[\"u_idx\"] = df[\"u_idx\"].astype(\"int64\")\n",
    "    df[\"i_idx\"] = df[\"i_idx\"].astype(\"int64\")\n",
    "\n",
    "    # Shared split indices by row\n",
    "    split = load_or_make_split(len(df), seed=seed, train_frac=0.8, save_path=split_path)\n",
    "    train_idx = split[\"train_idx\"]\n",
    "    test_idx  = split[\"test_idx\"]\n",
    "\n",
    "    df[\"review\"] = df[\"review\"].astype(str).map(clean_text)\n",
    "\n",
    "    # Fit vectorizer on TRAIN only\n",
    "    train_text = df.loc[train_idx, \"review\"].astype(str).fillna(\"\")\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=max_features,\n",
    "        stop_words=stop_words,\n",
    "        lowercase=True,\n",
    "        token_pattern=r\"(?u)\\b[a-zA-Z]{2,}\\b\",   # only alphabetic words, length>=2\n",
    "        min_df=2                                 # drop ultra-rare words\n",
    "    )\n",
    "    vectorizer.fit(train_text)\n",
    "\n",
    "    # Transform all using train-fitted vectorizer\n",
    "    all_text = df[\"review\"].astype(str).fillna(\"\")\n",
    "    X_text_all = vectorizer.transform(all_text).toarray().astype(np.float32)\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    vocab_size = X_text_all.shape[1]\n",
    "\n",
    "    assert vocab_size > 0\n",
    "    assert len(vocab) == vocab_size\n",
    "    assert vocab_size <= max_features, f\"vocab_size={vocab_size} > max_features={max_features}\"\n",
    "\n",
    "    # Core tensors\n",
    "    users_all   = torch.LongTensor(df[\"u_idx\"].values)\n",
    "    items_all   = torch.LongTensor(df[\"i_idx\"].values)\n",
    "    ratings_all = torch.FloatTensor(df[\"rating\"].values)\n",
    "    reviews_all = torch.FloatTensor(X_text_all)\n",
    "\n",
    "    # Exposure per row (optional)\n",
    "    if os.path.exists(confounder_path):\n",
    "        conf_obj = torch.load(confounder_path)\n",
    "        # Support both a raw tensor ([n_users, n_items]) and a dict with saved ID order\n",
    "        if isinstance(conf_obj, dict):\n",
    "            exposure_matrix = conf_obj.get('Z_hat', None)\n",
    "            saved_user_ids = conf_obj.get('user_ids', None)\n",
    "            saved_item_ids = conf_obj.get('item_ids', None)\n",
    "        else:\n",
    "            exposure_matrix = conf_obj\n",
    "            saved_user_ids = None\n",
    "            saved_item_ids = None\n",
    "\n",
    "        if exposure_matrix is None:\n",
    "            raise ValueError(f\"{confounder_path} loaded as dict but missing key 'Z_hat'.\")\n",
    "\n",
    "        # Align indices defensively in case the user/item ID ordering differs between runs\n",
    "        if (saved_user_ids is not None) and (saved_item_ids is not None):\n",
    "            u_map_saved = {str(uid): j for j, uid in enumerate(saved_user_ids)}\n",
    "            i_map_saved = {str(iid): j for j, iid in enumerate(saved_item_ids)}\n",
    "            u_saved_idx = df['user_id'].astype(str).map(u_map_saved).values\n",
    "            i_saved_idx = df['item_id'].astype(str).map(i_map_saved).values\n",
    "            if np.any(pd.isna(u_saved_idx)) or np.any(pd.isna(i_saved_idx)):\n",
    "                raise ValueError('Some user_id/item_id in clean_reviews.csv were not found in the saved confounder mapping.')\n",
    "            u_saved_idx = u_saved_idx.astype(int)\n",
    "            i_saved_idx = i_saved_idx.astype(int)\n",
    "            exposure_all = exposure_matrix[u_saved_idx, i_saved_idx].unsqueeze(1).float()\n",
    "        else:\n",
    "            exposure_all = exposure_matrix[users_all, items_all].unsqueeze(1).float()\n",
    "\n",
    "        print(f\"[confounders] Loaded {confounder_path}: {tuple(exposure_matrix.shape)}\")\n",
    "    else:\n",
    "        exposure_all = torch.zeros(len(df), 1)\n",
    "        print(f\"[confounders] Not found: {confounder_path}. Using zeros.\")\n",
    "\n",
    "    meta = {\n",
    "        \"seed\": seed,\n",
    "        \"train_idx\": train_idx,\n",
    "        \"test_idx\": test_idx,\n",
    "        \"n_users\": len(u_unique),\n",
    "        \"n_items\": len(i_unique),\n",
    "        \"vocab\": vocab,\n",
    "        \"vocab_size\": vocab_size,\n",
    "        \"split_path\": split_path,\n",
    "    }\n",
    "\n",
    "    print(f\"[data] Rows={len(df)} | Users={meta['n_users']} | Items={meta['n_items']} | Vocab={vocab_size}\")\n",
    "    print(f\"[split] Train={len(train_idx)} | Test={len(test_idx)} | Seed={seed}\")\n",
    "    return users_all, items_all, ratings_all, reviews_all, exposure_all, meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a624dd2e",
   "metadata": {},
   "source": [
    "### 3. Dataloaders (MF and TDFM share the exact same split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1c095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders_mf(users_all, items_all, ratings_all, meta, batch_size=BATCH_SIZE):\n",
    "    dataset = TensorDataset(users_all, items_all, ratings_all)\n",
    "    train_ds = Subset(dataset, meta[\"train_idx\"])\n",
    "    test_ds  = Subset(dataset, meta[\"test_idx\"])\n",
    "    g = torch.Generator().manual_seed(meta[\"seed\"])\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, generator=g)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def make_loaders_tdfm(users_all, items_all, reviews_all, exposure_all, ratings_all, meta, batch_size=BATCH_SIZE):\n",
    "    dataset = TensorDataset(users_all, items_all, reviews_all, exposure_all, ratings_all)\n",
    "    train_ds = Subset(dataset, meta[\"train_idx\"])\n",
    "    test_ds  = Subset(dataset, meta[\"test_idx\"])\n",
    "    g = torch.Generator().manual_seed(meta[\"seed\"])\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, generator=g)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4a346",
   "metadata": {},
   "source": [
    "### 4. MF baseline (same split)\n",
    "\n",
    "**Goal:** provide a simple, strong baseline that uses **only user/item IDs** (no text, no exposure terms) while sharing the **exact same fixed train/test split** as TDFM.\n",
    "\n",
    "**Model:** classic matrix factorization with user/item embeddings and a global bias.  \n",
    "**Training objective:** minimize squared error on observed ratings; predictions are clipped to the rating scale (1–5) for reporting.\n",
    "\n",
    "This baseline is the reference point for (i) rating prediction quality (RMSE/MAE) and (ii) downstream ranking metrics (Recall@K / NDCG@K) under the same evaluation protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f19010",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFBaseline(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_dim=EMBEDDING_DIM):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
    "        self.user_b   = nn.Embedding(num_users, 1)\n",
    "        self.item_b   = nn.Embedding(num_items, 1)\n",
    "        self.global_b = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "        self.user_b.weight.data.fill_(0.0)\n",
    "        self.item_b.weight.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        dot = (self.user_emb(u) * self.item_emb(i)).sum(dim=1)\n",
    "        pred = dot + self.user_b(u).squeeze(1) + self.item_b(i).squeeze(1) + self.global_b\n",
    "        pred = torch.sigmoid(pred) * 4.0 + 1.0   # [1.0, 5.0]\n",
    "        return pred\n",
    "\n",
    "def train_mf_from_loaders(train_loader, test_loader, n_users, n_items,\n",
    "                          emb_dim=EMBEDDING_DIM, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY,\n",
    "                          epochs=EPOCHS, device=DEVICE):\n",
    "    set_seed(SEED)\n",
    "    model = MFBaseline(n_users, n_items, emb_dim=emb_dim).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        running, n = 0.0, 0\n",
    "        for u, i, r in train_loader:\n",
    "            u, i, r = u.to(device), i.to(device), r.to(device)\n",
    "            opt.zero_grad()\n",
    "            pred = model(u, i)\n",
    "            loss = F.mse_loss(pred, r)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running += loss.item() * len(r)\n",
    "            n += len(r)\n",
    "        train_losses.append(running / n)\n",
    "        if ep % 5 == 0:\n",
    "            print(f\"[MF] Epoch {ep:02d} | Train MSE: {train_losses[-1]:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    mse_sum, total = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for u, i, r in test_loader:\n",
    "            u, i, r = u.to(device), i.to(device), r.to(device)\n",
    "            pred = model(u, i)\n",
    "            mse_sum += F.mse_loss(pred, r, reduction=\"sum\").item()\n",
    "            total += len(r)\n",
    "    rmse = (mse_sum / total) ** 0.5\n",
    "    print(f\"[MF] Final Test RMSE: {rmse:.4f}\")\n",
    "    return rmse, train_losses, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7263d5b8",
   "metadata": {},
   "source": [
    "### 5. TDFM model + training (same split)\n",
    "\n",
    "**Idea:** augment standard matrix factorization (MF) with a **topic/text component** derived from reviews, and (optionally) an **exposure proxy** to reduce exposure bias.\n",
    "\n",
    "#### Model pieces\n",
    "\n",
    "- **MF backbone (ratings):** user/item embeddings + biases give an MF score\n",
    "\n",
    "  $$s_{ui}^{\\mathrm{MF}}=\\langle p_u,q_i\\rangle+b_u+b_i.$$\n",
    "\n",
    "- **Amortized topic mixture from text:** given a bag-of-words vector $x\\in\\mathbb{R}^{|V|}$ for a review,\n",
    "\n",
    "  $$\\mu=f_{\\mathrm{enc}}(x),\\qquad \\theta=\\mathrm{softmax}(\\mu)\\in\\Delta^{K-1}.$$\n",
    "\n",
    "  Here $\\theta$ is a topic-mixture (simplex) vector for that interaction, computed using the **train-fit vocabulary**.\n",
    "\n",
    "- **Probabilistic word reconstruction (likelihood-style term):** the decoder maps $\\theta$ to a word distribution over the vocabulary,\n",
    "\n",
    "  $$p(w=v\\mid\\theta)=\\mathrm{softmax}(W\\theta)_v.$$\n",
    "\n",
    "  Treating the review as counts $x_v$, the negative log-likelihood (up to a constant) is\n",
    "\n",
    "  $$\\mathcal{L}_{\\text{text}}(x,\\theta)=-\\sum_{v=1}^{|V|} x_v\\log p(w=v\\mid\\theta).$$\n",
    "\n",
    "  In code this is implemented as `recon_loss = -(reviews * recon_log_probs).sum(dim=1).mean()`.\n",
    "\n",
    "- **Exposure adjustment (optional):** if an exposure proxy $z_{ui}$ is available (from `confounders_baseline.pt`), the rating score includes a linear correction\n",
    "\n",
    "  $$s_{ui}=s_{ui}^{\\mathrm{MF}}+a^\\top\\theta+c_z\\,z_{ui}.$$\n",
    "\n",
    "  (If `confounders_baseline.pt` is missing, we set $z_{ui}=0$.)\n",
    "\n",
    "\n",
    "#### Training objective\n",
    "\n",
    "We train on the same fixed train split as MF, minimizing\n",
    "\n",
    "$$\n",
    "\\mathcal{L}\n",
    "=\n",
    "\\underbrace{\\mathrm{MSE}(\\hat r_{ui}, r_{ui})}_{\\text{rating fit}}\n",
    "+\n",
    "\\lambda\\underbrace{\\mathcal{L}_{\\text{text}}(x_{ui},\\theta_{ui})}_{\\text{BoW reconstruction}},\n",
    "$$\n",
    "\n",
    "where $\\lambda$ corresponds to `recon_weight` in the training function.\n",
    "\n",
    "Evaluation is run under `model.eval()` / `torch.no_grad()`, so dropout is **OFF** at inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7daa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDFM(nn.Module):\n",
    "    def __init__(self, num_users, num_items, vocab_size, num_topics=NUM_TOPICS, emb_dim=EMBEDDING_DIM):\n",
    "        super().__init__()\n",
    "\n",
    "        # Topic model\n",
    "        self.encoder_fc1 = nn.Linear(vocab_size, 64)\n",
    "        self.encoder_fc2 = nn.Linear(64, num_topics)\n",
    "        self.encoder_drop = nn.Dropout(0.3)\n",
    "        self.decoder = nn.Linear(num_topics, vocab_size, bias=False)\n",
    "        self.decoder_bn = nn.BatchNorm1d(vocab_size, affine=False)\n",
    "\n",
    "        # MF part\n",
    "        self.user_embedding = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, emb_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.mf_drop = nn.Dropout(0.2)\n",
    "\n",
    "        # Deconfounding adjustments\n",
    "        self.topic_bias = nn.Linear(num_topics, 1, bias=False)\n",
    "        self.exposure_bias = nn.Linear(1, 1, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        self.user_bias.weight.data.fill_(0.0)\n",
    "        self.item_bias.weight.data.fill_(0.0)\n",
    "\n",
    "    def reparameterize(self, mu):\n",
    "        return F.softmax(mu, dim=1)\n",
    "\n",
    "    def forward(self, user_idx, item_idx, bow_input, exposure_val):\n",
    "        # Topic inference\n",
    "        h = F.relu(self.encoder_fc1(bow_input))\n",
    "        h = self.encoder_drop(h)\n",
    "        theta = self.reparameterize(self.encoder_fc2(h))\n",
    "\n",
    "        word_logits = self.decoder(theta)\n",
    "        recon_log_probs = F.log_softmax(self.decoder_bn(word_logits), dim=1)\n",
    "\n",
    "        # Rating prediction\n",
    "        u_emb = self.user_embedding(user_idx)\n",
    "        i_emb = self.item_embedding(item_idx)\n",
    "\n",
    "        interaction = (u_emb * i_emb).sum(dim=1, keepdim=True)\n",
    "        interaction = self.mf_drop(interaction)\n",
    "\n",
    "        u_b = self.user_bias(user_idx)\n",
    "        i_b = self.item_bias(item_idx)\n",
    "\n",
    "        bias_text = self.topic_bias(theta)\n",
    "        bias_exposure = self.exposure_bias(exposure_val)\n",
    "\n",
    "        raw_score = interaction + u_b + i_b + bias_text + bias_exposure\n",
    "        pred = torch.sigmoid(raw_score) * 4.0 + 1.0   # [1.0, 5.0]\n",
    "        return pred.squeeze(1), recon_log_probs\n",
    "\n",
    "def train_tdfm_from_loaders(train_loader, test_loader, n_users, n_items, vocab_size,\n",
    "                            num_topics=NUM_TOPICS, emb_dim=EMBEDDING_DIM,\n",
    "                            epochs=EPOCHS, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY,\n",
    "                            recon_weight=0.002, device=DEVICE, save_path=\"tdfm_model.pt\"):\n",
    "    set_seed(SEED)\n",
    "    model = TDFM(n_users, n_items, vocab_size, num_topics=num_topics, emb_dim=emb_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses = []\n",
    "    print(\"\\nStarting Robust TDFM Training...\")\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss, total_mse, nbatches = 0.0, 0.0, 0\n",
    "        for users, items, reviews, exposure, ratings in train_loader:\n",
    "            users = users.to(device)\n",
    "            items = items.to(device)\n",
    "            reviews = reviews.to(device)\n",
    "            exposure = exposure.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred, recon_log_probs = model(users, items, reviews, exposure)\n",
    "\n",
    "            rating_loss = F.mse_loss(pred, ratings)\n",
    "            recon_loss  = -(reviews * recon_log_probs).sum(dim=1).mean()\n",
    "            loss = rating_loss + (recon_weight * recon_loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_mse += rating_loss.item()\n",
    "            nbatches += 1\n",
    "\n",
    "        avg_loss = total_loss / max(nbatches, 1)\n",
    "        avg_mse  = total_mse / max(nbatches, 1)\n",
    "        train_losses.append(avg_loss)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"[TDFM] Epoch {epoch:02d} | Loss={avg_loss:.4f} | MSE={avg_mse:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    mse_sum, total = 0.0, 0\n",
    "\n",
    "    print(\"\\nSample Predictions vs Actuals:\")\n",
    "    with torch.no_grad():\n",
    "        for i, (users, items, reviews, exposure, ratings) in enumerate(test_loader):\n",
    "            users = users.to(device)\n",
    "            items = items.to(device)\n",
    "            reviews = reviews.to(device)\n",
    "            exposure = exposure.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            pred, _ = model(users, items, reviews, exposure)\n",
    "\n",
    "            if i == 0:\n",
    "                print(\"Pred:\", pred[:5].detach().cpu().numpy())\n",
    "                print(\"True:\", ratings[:5].detach().cpu().numpy())\n",
    "\n",
    "            mse_sum += F.mse_loss(pred, ratings, reduction=\"sum\").item()\n",
    "            total += len(ratings)\n",
    "\n",
    "    rmse = (mse_sum / total) ** 0.5\n",
    "    print(f\"\\n[TDFM] Final Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"[TDFM] Saved model -> {save_path}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses)\n",
    "    plt.title(\"Robust TDFM Training Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    return rmse, train_losses, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f54ce",
   "metadata": {},
   "source": [
    "### 6. Run MF vs TDFM + summary (same split, no leakage)\n",
    "\n",
    "This section runs the end-to-end experiment pipeline:\n",
    "\n",
    "1. **Common preprocessing** (shared tensors + shared split indices).\n",
    "2. **Train MF** and **train TDFM** on the *same* training set.\n",
    "3. **Evaluate on the same test set**:\n",
    "   - Rating metrics: RMSE / MAE\n",
    "   - Uncertainty: paired bootstrap and user-block (cluster) bootstrap (later cells)\n",
    "   - Ranking metrics: Recall@K / NDCG@K with negative sampling sweeps (later cells)\n",
    "\n",
    "**No text leakage:** the vectorizer vocabulary is fit on training reviews only, and any train-only item/topic profiles used for scoring are computed from the training loader only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "914f0aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping zeros: 6085 rows; rating min/max: 1 5\n",
      "[confounders] Loaded confounders_baseline.pt: (2021, 100)\n",
      "[data] Rows=6085 | Users=2021 | Items=100 | Vocab=1000\n",
      "[split] Train=4868 | Test=1217 | Seed=0\n",
      "[MF] Epoch 00 | Train MSE: 1.8995\n",
      "[MF] Epoch 05 | Train MSE: 0.0731\n",
      "[MF] Epoch 10 | Train MSE: 0.0383\n",
      "[MF] Epoch 15 | Train MSE: 0.0320\n",
      "[MF] Final Test RMSE: 0.6236\n",
      "\n",
      "Starting Robust TDFM Training...\n",
      "[TDFM] Epoch 00 | Loss=1.7018 | MSE=1.5005\n",
      "[TDFM] Epoch 05 | Loss=0.3075 | MSE=0.1131\n",
      "[TDFM] Epoch 10 | Loss=0.2847 | MSE=0.0904\n",
      "[TDFM] Epoch 15 | Loss=0.2752 | MSE=0.0806\n",
      "\n",
      "Sample Predictions vs Actuals:\n",
      "Pred: [4.7935104 4.549818  4.8213305 4.8632584 4.7322493]\n",
      "True: [5. 5. 4. 5. 5.]\n",
      "\n",
      "[TDFM] Final Test RMSE: 0.5369\n",
      "[TDFM] Saved model -> tdfm_model.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test RMSE Summary (same split, no text leakage) ===\n",
      "MF baseline: 0.6236\n",
      "TDFM:        0.5369\n",
      "MF - TDFM:   0.0867\n",
      "[TDFM] Saved vocab -> tdfm_vocab.npy\n"
     ]
    }
   ],
   "source": [
    "users_all, items_all, ratings_all, reviews_all, exposure_all, meta = prepare_common_tensors(\n",
    "    csv_path=CSV_PATH,\n",
    "    confounder_path=CONFOUNDER_PATH,\n",
    "    max_features=MAX_FEATURES,\n",
    "    stop_words=STOP_WORDS,\n",
    "    seed=SEED,\n",
    "    split_path=SPLIT_PATH,\n",
    ")\n",
    "\n",
    "mf_train_loader, mf_test_loader = make_loaders_mf(users_all, items_all, ratings_all, meta, batch_size=BATCH_SIZE)\n",
    "td_train_loader, td_test_loader = make_loaders_tdfm(users_all, items_all, reviews_all, exposure_all, ratings_all, meta, batch_size=BATCH_SIZE)\n",
    "\n",
    "mf_rmse, mf_losses, _ = train_mf_from_loaders(\n",
    "    mf_train_loader, mf_test_loader, meta[\"n_users\"], meta[\"n_items\"],\n",
    "    emb_dim=EMBEDDING_DIM, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, epochs=EPOCHS, device=DEVICE\n",
    ")\n",
    "\n",
    "tdfm_rmse, tdfm_losses, _ = train_tdfm_from_loaders(\n",
    "    td_train_loader, td_test_loader, meta[\"n_users\"], meta[\"n_items\"], meta[\"vocab_size\"],\n",
    "    num_topics=NUM_TOPICS, emb_dim=EMBEDDING_DIM, epochs=EPOCHS, lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY, recon_weight=0.002, device=DEVICE, save_path=\"tdfm_model.pt\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Test RMSE Summary (same split, no text leakage) ===\")\n",
    "print(f\"MF baseline: {mf_rmse:.4f}\")\n",
    "print(f\"TDFM:        {tdfm_rmse:.4f}\")\n",
    "print(f\"MF - TDFM:   {mf_rmse - tdfm_rmse:.4f}\")\n",
    "\n",
    "np.save(\"tdfm_vocab.npy\", meta[\"vocab\"])\n",
    "print(\"[TDFM] Saved vocab -> tdfm_vocab.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6370316",
   "metadata": {},
   "source": [
    "### 6A. Evaluation utilities + bootstrap confidence intervals\n",
    "\n",
    "We report RMSE/MAE and quantify uncertainty using **paired bootstrap** (and later, **user-block bootstrap** to account for per-user correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[eval] mf_model not found; retraining MF baseline so we can evaluate.\n",
      "[MF] Epoch 00 | Train MSE: 1.8917\n",
      "[MF] Epoch 05 | Train MSE: 0.0731\n",
      "[MF] Epoch 10 | Train MSE: 0.0400\n",
      "[MF] Epoch 15 | Train MSE: 0.0330\n",
      "[MF] Final Test RMSE: 0.6234\n",
      "[eval] Loaded TDFM from tdfm_model.pt\n",
      "\n",
      "=== Test metrics (same split, no text leakage) ===\n",
      "MF   RMSE: 0.6234 | MAE: 0.4066\n",
      "TDFM RMSE: 0.5369 | MAE: 0.3333\n",
      "ΔRMSE (MF - TDFM): 0.0865\n",
      "ΔMAE  (MF - TDFM): 0.0733\n",
      "\n",
      "Paired bootstrap 95% CI (B=2000)\n",
      "ΔRMSE (MF - TDFM): [0.0613, 0.1131]\n",
      "ΔMAE  (MF - TDFM): [0.0587, 0.0888]\n",
      "% test points with lower SE under TDFM: 67.9%\n",
      "% test points with lower AE under TDFM: 67.9%\n",
      "\n",
      "RMSE by true rating:\n",
      "  y=1: MF 3.2532 | TDFM 2.6845 | n=8\n",
      "  y=2: MF 2.4513 | TDFM 2.3601 | n=18\n",
      "  y=3: MF 1.5644 | TDFM 1.2905 | n=36\n",
      "  y=4: MF 0.6348 | TDFM 0.6746 | n=134\n",
      "  y=5: MF 0.3677 | TDFM 0.2654 | n=1021\n"
     ]
    }
   ],
   "source": [
    "# === Evaluation + stronger stats (paired bootstrap) ===\n",
    "\n",
    "DEVICE = globals().get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def rmse(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.sqrt(np.mean((yhat - y) ** 2)))\n",
    "\n",
    "def mae(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.mean(np.abs(yhat - y)))\n",
    "\n",
    "def _clip_ratings(x, lo=1.0, hi=5.0):\n",
    "    return np.clip(np.asarray(x).reshape(-1), lo, hi)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_mf(model, loader, device=DEVICE):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    for u, i, r in loader:\n",
    "        u, i = u.to(device), i.to(device)\n",
    "        yhat = model(u, i).detach().cpu().numpy()\n",
    "        preds.append(yhat)\n",
    "        trues.append(r.detach().cpu().numpy())\n",
    "    return np.concatenate(preds), np.concatenate(trues)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_tdfm(model, loader, device=DEVICE):\n",
    "    \"\"\"\n",
    "    In THIS notebook, td_* loaders yield: (u, i, bow, exposure, r)\n",
    "    forward(user_idx, item_idx, bow_input, exposure_val) -> (pred, recon_log_probs)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "\n",
    "    expected_vocab = None\n",
    "    if hasattr(model, \"encoder_fc1\") and hasattr(model.encoder_fc1, \"in_features\"):\n",
    "        expected_vocab = int(model.encoder_fc1.in_features)\n",
    "\n",
    "    for batch in loader:\n",
    "        if len(batch) != 5:\n",
    "            raise ValueError(f\"Expected 5-tuple (u,i,bow,exposure,r) from td loader, got {len(batch)}\")\n",
    "        u, i, bow, exposure, r = batch\n",
    "\n",
    "        # Safety: if bow/exposure were accidentally swapped somewhere, auto-fix by shape\n",
    "        if expected_vocab is not None:\n",
    "            if bow.dim() == 1: bow = bow.unsqueeze(1)\n",
    "            if exposure.dim() == 1: exposure = exposure.unsqueeze(1)\n",
    "\n",
    "            if bow.shape[1] != expected_vocab and exposure.shape[1] == expected_vocab:\n",
    "                bow, exposure = exposure, bow  # swap\n",
    "\n",
    "            assert bow.shape[1] == expected_vocab, (\n",
    "                f\"bow shape {tuple(bow.shape)} but expected (*,{expected_vocab}). \"\n",
    "                \"Your td loader order should be (u,i,bow,exposure,r).\"\n",
    "            )\n",
    "            # exposure can be (B,1) or (B,vocab) depending on how you built it\n",
    "            assert exposure.shape[1] in (1, expected_vocab), (\n",
    "                f\"exposure shape {tuple(exposure.shape)}; expected (*,1) or (*,{expected_vocab}).\"\n",
    "            )\n",
    "\n",
    "        u, i = u.to(device), i.to(device)\n",
    "        bow, exposure = bow.to(device), exposure.to(device)\n",
    "\n",
    "        pred, _ = model(u, i, bow, exposure)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        trues.append(r.detach().cpu().numpy())\n",
    "\n",
    "    return np.concatenate(preds), np.concatenate(trues)\n",
    "\n",
    "# ---- grab loaders/meta ----\n",
    "meta = globals().get(\"meta\", None)\n",
    "mf_train_loader = globals().get(\"mf_train_loader\", None)\n",
    "mf_test_loader  = globals().get(\"mf_test_loader\", None)\n",
    "td_train_loader = globals().get(\"td_train_loader\", None)\n",
    "td_test_loader  = globals().get(\"td_test_loader\", None)\n",
    "\n",
    "if meta is None:\n",
    "    raise NameError(\"meta not found. Run the data-prep cell that defines `meta` first.\")\n",
    "if mf_test_loader is None or td_test_loader is None:\n",
    "    raise NameError(\"mf_test_loader / td_test_loader not found. Run the loader-creation cell first.\")\n",
    "\n",
    "# ---- MF model: use if present, else retrain (since we overwrote `_`) ----\n",
    "mf_model = globals().get(\"mf_model\", None)\n",
    "if mf_model is None:\n",
    "    if \"train_mf_from_loaders\" in globals() and mf_train_loader is not None:\n",
    "        print(\"[eval] mf_model not found; retraining MF baseline so we can evaluate.\")\n",
    "        # train_mf_from_loaders signature: (train_loader, test_loader, n_users, n_items, ...)\n",
    "        if \"meta\" in globals() and meta is not None:\n",
    "            n_users = meta.get(\"n_users\", None)\n",
    "            n_items = meta.get(\"n_items\", None)\n",
    "        else:\n",
    "            n_users = globals().get(\"n_users\", None)\n",
    "            n_items = globals().get(\"n_items\", None)\n",
    "        if n_users is None or n_items is None:\n",
    "            raise NameError(\"Need n_users and n_items to retrain MF baseline (expected in meta['n_users'], meta['n_items']).\")\n",
    "        _, _, mf_model = train_mf_from_loaders(\n",
    "            mf_train_loader, mf_test_loader, int(n_users), int(n_items),\n",
    "            epochs=20, lr=0.01, device=DEVICE\n",
    "        )\n",
    "    else:\n",
    "        raise NameError(\"mf_model not found and cannot retrain (missing train_mf_from_loaders or mf_train_loader).\")\n",
    "\n",
    "# ---- TDFM model: use if present, else load from disk (you saved tdfm_model.pt) ----\n",
    "tdfm_model = globals().get(\"tdfm_model\", None)\n",
    "if tdfm_model is None:\n",
    "    tdfm_path = Path(globals().get(\"TDFM_STATE_PATH\", \"tdfm_model.pt\"))\n",
    "    if not tdfm_path.exists():\n",
    "        raise NameError(\"tdfm_model not found in memory and tdfm_model.pt not found. Re-run TDFM training cell.\")\n",
    "    vocab_size = int(meta[\"vocab_size\"])\n",
    "    num_users  = int(meta[\"n_users\"])\n",
    "    num_items  = int(meta[\"n_items\"])\n",
    "    num_topics = int(globals().get(\"NUM_TOPICS\", 10))\n",
    "    emb_dim    = int(globals().get(\"EMBEDDING_DIM\", 32))\n",
    "\n",
    "    tdfm_model = TDFM(num_users, num_items, vocab_size, num_topics=num_topics, emb_dim=emb_dim).to(DEVICE)\n",
    "    tdfm_model.load_state_dict(torch.load(tdfm_path, map_location=DEVICE))\n",
    "    print(f\"[eval] Loaded TDFM from {tdfm_path}\")\n",
    "\n",
    "mf_model = mf_model.to(DEVICE)\n",
    "tdfm_model = tdfm_model.to(DEVICE)\n",
    "\n",
    "# ---- metrics ----\n",
    "mf_pred, y_test = predict_mf(mf_model, mf_test_loader, device=DEVICE)\n",
    "td_pred, y_test2 = predict_tdfm(tdfm_model, td_test_loader, device=DEVICE)\n",
    "\n",
    "# sanity check: same test labels\n",
    "if not np.allclose(y_test, y_test2):\n",
    "    raise RuntimeError(\"MF test labels and TDFM test labels differ — check you used the same split indices.\")\n",
    "\n",
    "mf_pred = _clip_ratings(mf_pred)\n",
    "td_pred = _clip_ratings(td_pred)\n",
    "\n",
    "print(\"\\n=== Test metrics (same split, no text leakage) ===\")\n",
    "print(f\"MF   RMSE: {rmse(mf_pred, y_test):.4f} | MAE: {mae(mf_pred, y_test):.4f}\")\n",
    "print(f\"TDFM RMSE: {rmse(td_pred, y_test):.4f} | MAE: {mae(td_pred, y_test):.4f}\")\n",
    "print(f\"ΔRMSE (MF - TDFM): {rmse(mf_pred, y_test) - rmse(td_pred, y_test):.4f}\")\n",
    "print(f\"ΔMAE  (MF - TDFM): {mae(mf_pred, y_test) - mae(td_pred, y_test):.4f}\")\n",
    "\n",
    "# ---- paired bootstrap CIs (stronger claim) ----\n",
    "B = 2000\n",
    "rng = np.random.default_rng(0)\n",
    "se_mf = (mf_pred - y_test) ** 2\n",
    "se_td = (td_pred - y_test) ** 2\n",
    "ae_mf = np.abs(mf_pred - y_test)\n",
    "ae_td = np.abs(td_pred - y_test)\n",
    "\n",
    "n = len(y_test)\n",
    "impr_rmse = np.empty(B, dtype=float)\n",
    "impr_mae  = np.empty(B, dtype=float)\n",
    "\n",
    "for b in range(B):\n",
    "    idx = rng.integers(0, n, size=n)\n",
    "    impr_rmse[b] = np.sqrt(se_mf[idx].mean()) - np.sqrt(se_td[idx].mean())\n",
    "    impr_mae[b]  = ae_mf[idx].mean() - ae_td[idx].mean()\n",
    "\n",
    "lo_r, hi_r = np.percentile(impr_rmse, [2.5, 97.5])\n",
    "lo_a, hi_a = np.percentile(impr_mae,  [2.5, 97.5])\n",
    "\n",
    "pct_better_se = float((se_td < se_mf).mean()) * 100.0\n",
    "pct_better_ae = float((ae_td < ae_mf).mean()) * 100.0\n",
    "\n",
    "print(f\"\\nPaired bootstrap 95% CI (B={B})\")\n",
    "print(f\"ΔRMSE (MF - TDFM): [{lo_r:.4f}, {hi_r:.4f}]\")\n",
    "print(f\"ΔMAE  (MF - TDFM): [{lo_a:.4f}, {hi_a:.4f}]\")\n",
    "print(f\"% test points with lower SE under TDFM: {pct_better_se:.1f}%\")\n",
    "print(f\"% test points with lower AE under TDFM: {pct_better_ae:.1f}%\")\n",
    "\n",
    "# ---- extra: RMSE by true rating (1..5) ----\n",
    "print(\"\\nRMSE by true rating:\")\n",
    "for val in [1, 2, 3, 4, 5]:\n",
    "    mask = (y_test == val)\n",
    "    if mask.sum() == 0:\n",
    "        continue\n",
    "    print(f\"  y={val}: MF {rmse(mf_pred[mask], y_test[mask]):.4f} | \"\n",
    "          f\"TDFM {rmse(td_pred[mask], y_test[mask]):.4f} | n={mask.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdcd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric utilities and batched prediction functions\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "\n",
    "def weighted_rmse(yhat, y, w):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y    = np.asarray(y).reshape(-1)\n",
    "    w    = np.asarray(w).reshape(-1)\n",
    "    return float(np.sqrt(np.sum(w * (yhat - y) ** 2) / np.sum(w)))\n",
    "\n",
    "def weighted_mae(yhat, y, w):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y    = np.asarray(y).reshape(-1)\n",
    "    w    = np.asarray(w).reshape(-1)\n",
    "    return float(np.sum(w * np.abs(yhat - y)) / np.sum(w))\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_mf_on_indices(model, users_all, items_all, idx, device=DEVICE, batch_size=8192):\n",
    "    model.eval()\n",
    "    idx = np.asarray(idx)\n",
    "    preds = []\n",
    "    for s in range(0, len(idx), batch_size):\n",
    "        b = idx[s:s+batch_size]\n",
    "        u = users_all[b].to(device)\n",
    "        i = items_all[b].to(device)\n",
    "        preds.append(model(u, i).detach().cpu().numpy())\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_tdfm_on_indices(model, users_all, items_all, reviews_all, exposure_all, idx, device=DEVICE, batch_size=4096):\n",
    "    \"\"\"\n",
    "    forward(u, i, bow, exposure) -> (pred, recon_log_probs)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    idx = np.asarray(idx)\n",
    "    preds = []\n",
    "    for s in range(0, len(idx), batch_size):\n",
    "        b = idx[s:s+batch_size]\n",
    "        u = users_all[b].to(device)\n",
    "        i = items_all[b].to(device)\n",
    "        bow = reviews_all[b].to(device)\n",
    "        exp = exposure_all[b].to(device)\n",
    "        yhat, _ = model(u, i, bow, exp)\n",
    "        preds.append(yhat.detach().cpu().numpy())\n",
    "    return np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7989da",
   "metadata": {},
   "source": [
    "### 6B. Additional baseline: MF + train-only LDA residual correction\n",
    "\n",
    "This block fits an LDA-style topic model on **train text only** and tests whether topic residualization improves MF. This is supplementary, and is clearly separated from the main MF vs TDFM comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bedce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LDA baseline] MF+LDA residual correction:\n",
      "  RMSE: 0.6123486161231995\n",
      "  MAE : 0.3348298668861389\n"
     ]
    }
   ],
   "source": [
    "# ===== LDA baseline (train-only fit) =====\n",
    "train_idx = np.asarray(meta[\"train_idx\"])\n",
    "test_idx  = np.asarray(meta[\"test_idx\"])\n",
    "\n",
    "# Use the existing BOW counts (reviews_all) and fit LDA ONLY on train\n",
    "X_bow_all = reviews_all.detach().cpu().numpy()\n",
    "X_bow_tr  = X_bow_all[train_idx]\n",
    "X_bow_te  = X_bow_all[test_idx]\n",
    "\n",
    "NUM_TOPICS_LDA = 10   # you can match NUM_TOPICS in your TDFM\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=NUM_TOPICS_LDA,\n",
    "    learning_method=\"batch\",\n",
    "    random_state=SEED,\n",
    "    max_iter=30\n",
    ")\n",
    "lda.fit(X_bow_tr)\n",
    "\n",
    "theta_tr = lda.transform(X_bow_tr)  # (n_train, K)\n",
    "theta_te = lda.transform(X_bow_te)  # (n_test,  K)\n",
    "\n",
    "# Predictions from MF, aligned to the SAME index order\n",
    "y_tr = ratings_all[train_idx].detach().cpu().numpy()\n",
    "y_te = ratings_all[test_idx].detach().cpu().numpy()\n",
    "\n",
    "yhat_tr_mf = predict_mf_on_indices(mf_model, users_all, items_all, train_idx, device=DEVICE)\n",
    "yhat_te_mf = predict_mf_on_indices(mf_model, users_all, items_all, test_idx,  device=DEVICE)\n",
    "\n",
    "# Fit ridge on MF residuals using LDA topic proportions\n",
    "res_tr = y_tr - yhat_tr_mf\n",
    "ridge = Ridge(alpha=1.0, random_state=SEED)\n",
    "ridge.fit(theta_tr, res_tr)\n",
    "\n",
    "# MF + LDA residual correction\n",
    "yhat_te_mf_lda = yhat_te_mf + ridge.predict(theta_te)\n",
    "yhat_te_mf_lda = np.clip(yhat_te_mf_lda, 1.0, 5.0)\n",
    "\n",
    "print(\"[LDA baseline] MF+LDA residual correction:\")\n",
    "print(\"  RMSE:\", rmse(yhat_te_mf_lda, y_te))\n",
    "print(\"  MAE :\", mae(yhat_te_mf_lda, y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45643935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== USER-level (block) bootstrap over users ===\n",
      "Users in test: 913\n",
      "ΔRMSE (MF - TDFM): [0.0611, 0.1138]   (B=2000)\n",
      "ΔMAE  (MF - TDFM): [0.0586, 0.0891]   (B=2000)\n",
      "% users with lower RMSE under TDFM: 68.6%\n",
      "% users with lower MAE  under TDFM: 69.6%\n"
     ]
    }
   ],
   "source": [
    "# === Stronger stats: USER-level (block) bootstrap + % users improved ===\n",
    "\n",
    "# 1) Reconstruct aligned user ids for the test set (same order as mf_pred / y_test)\n",
    "u_list, r_list = [], []\n",
    "for batch in mf_test_loader:\n",
    "    # mf_test_loader yields (u, i, r)\n",
    "    u, i, r = batch\n",
    "    u_list.append(u.detach().cpu().numpy().reshape(-1))\n",
    "    r_list.append(r.detach().cpu().numpy().reshape(-1))\n",
    "\n",
    "u_test = np.concatenate(u_list)\n",
    "r_test = np.concatenate(r_list)\n",
    "\n",
    "# Sanity check: these should match if the loader order is deterministic (shuffle=False)\n",
    "y_arr = np.asarray(y_test).reshape(-1)\n",
    "mf_arr = np.asarray(mf_pred).reshape(-1)\n",
    "td_arr = np.asarray(td_pred).reshape(-1)\n",
    "\n",
    "assert len(u_test) == len(y_arr) == len(mf_arr) == len(td_arr), \"Length mismatch.\"\n",
    "if not np.allclose(r_test, y_arr):\n",
    "    print(\"[warn] r_test != y_test (likely different ordering). Using r_test as ground truth for this cell.\")\n",
    "    y_arr = r_test\n",
    "\n",
    "# 2) Precompute per-user sufficient statistics\n",
    "users = np.unique(u_test)\n",
    "user_to_pos = {u: j for j, u in enumerate(users)}\n",
    "m = len(users)\n",
    "\n",
    "cnt = np.zeros(m, dtype=np.int64)\n",
    "sse_mf = np.zeros(m, dtype=float)\n",
    "sse_td = np.zeros(m, dtype=float)\n",
    "sae_mf = np.zeros(m, dtype=float)\n",
    "sae_td = np.zeros(m, dtype=float)\n",
    "\n",
    "se_mf_all = (mf_arr - y_arr) ** 2\n",
    "se_td_all = (td_arr - y_arr) ** 2\n",
    "ae_mf_all = np.abs(mf_arr - y_arr)\n",
    "ae_td_all = np.abs(td_arr - y_arr)\n",
    "\n",
    "for idx, u in enumerate(u_test):\n",
    "    j = user_to_pos[int(u)]\n",
    "    cnt[j] += 1\n",
    "    sse_mf[j] += float(se_mf_all[idx])\n",
    "    sse_td[j] += float(se_td_all[idx])\n",
    "    sae_mf[j] += float(ae_mf_all[idx])\n",
    "    sae_td[j] += float(ae_td_all[idx])\n",
    "\n",
    "# 3) User-level \"who wins\" (each user gets one vote)\n",
    "rmse_user_mf = np.sqrt(sse_mf / np.maximum(cnt, 1))\n",
    "rmse_user_td = np.sqrt(sse_td / np.maximum(cnt, 1))\n",
    "pct_users_better_rmse = 100.0 * float((rmse_user_td < rmse_user_mf).mean())\n",
    "\n",
    "mae_user_mf = sae_mf / np.maximum(cnt, 1)\n",
    "mae_user_td = sae_td / np.maximum(cnt, 1)\n",
    "pct_users_better_mae = 100.0 * float((mae_user_td < mae_user_mf).mean())\n",
    "\n",
    "# 4) Block bootstrap over users (more conservative than iid-over-observations bootstrap)\n",
    "B = 2000\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "impr_rmse = np.empty(B, dtype=float)  # RMSE(MF) - RMSE(TDFM)\n",
    "impr_mae  = np.empty(B, dtype=float)  # MAE(MF)  - MAE(TDFM)\n",
    "\n",
    "for b in range(B):\n",
    "    picks = rng.integers(0, m, size=m)  # sample users with replacement\n",
    "    cnt_b = cnt[picks].sum()\n",
    "\n",
    "    # Aggregate back to observation-weighted metrics\n",
    "    rmse_mf_b = np.sqrt(sse_mf[picks].sum() / cnt_b)\n",
    "    rmse_td_b = np.sqrt(sse_td[picks].sum() / cnt_b)\n",
    "    impr_rmse[b] = rmse_mf_b - rmse_td_b\n",
    "\n",
    "    mae_mf_b = sae_mf[picks].sum() / cnt_b\n",
    "    mae_td_b = sae_td[picks].sum() / cnt_b\n",
    "    impr_mae[b] = mae_mf_b - mae_td_b\n",
    "\n",
    "lo_r, hi_r = np.percentile(impr_rmse, [2.5, 97.5])\n",
    "lo_a, hi_a = np.percentile(impr_mae,  [2.5, 97.5])\n",
    "\n",
    "print(\"\\n=== USER-level (block) bootstrap over users ===\")\n",
    "print(f\"Users in test: {m}\")\n",
    "print(f\"ΔRMSE (MF - TDFM): [{lo_r:.4f}, {hi_r:.4f}]   (B={B})\")\n",
    "print(f\"ΔMAE  (MF - TDFM): [{lo_a:.4f}, {hi_a:.4f}]   (B={B})\")\n",
    "print(f\"% users with lower RMSE under TDFM: {pct_users_better_rmse:.1f}%\")\n",
    "print(f\"% users with lower MAE  under TDFM: {pct_users_better_mae:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132330a",
   "metadata": {},
   "source": [
    "RMSE/MAE ablation note (diagnostic vs. fair ablation)\n",
    "\n",
    "Diagnostic only (not a fair ablation): Removing the topic/text term at inference time while keeping a model trained with that term can produce misleading results (the model is not optimized for that architecture).\n",
    "\n",
    "\n",
    "Fair ablation:\n",
    "In Section 8 (Robustness upgrades) we retrain a NoTopic variant and evaluate it on the same aligned test set, with paired and user-block bootstrap deltas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979de0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ΔRMSE vs MF (MF - model)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ΔMAE  vs MF (MF - model)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "603c626c-931e-4e38-b82e-803834c5b669",
       "rows": [
        [
         "0",
         "MF",
         "0.6234142184257507",
         "0.4066319763660431",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "TDFM(full)",
         "0.5368708968162537",
         "0.3333243131637573",
         "0.08654332160949707",
         "0.07330766320228577"
        ],
        [
         "2",
         "TDFM(no-topic)",
         "1.1281847953796387",
         "1.0233566761016846",
         "-0.5047705769538879",
         "-0.6167246997356415"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>ΔRMSE vs MF (MF - model)</th>\n",
       "      <th>ΔMAE  vs MF (MF - model)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MF</td>\n",
       "      <td>0.623414</td>\n",
       "      <td>0.406632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TDFM(full)</td>\n",
       "      <td>0.536871</td>\n",
       "      <td>0.333324</td>\n",
       "      <td>0.086543</td>\n",
       "      <td>0.073308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TDFM(no-topic)</td>\n",
       "      <td>1.128185</td>\n",
       "      <td>1.023357</td>\n",
       "      <td>-0.504771</td>\n",
       "      <td>-0.616725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model      RMSE       MAE  ΔRMSE vs MF (MF - model)  \\\n",
       "0              MF  0.623414  0.406632                  0.000000   \n",
       "1      TDFM(full)  0.536871  0.333324                  0.086543   \n",
       "2  TDFM(no-topic)  1.128185  1.023357                 -0.504771   \n",
       "\n",
       "   ΔMAE  vs MF (MF - model)  \n",
       "0                  0.000000  \n",
       "1                  0.073308  \n",
       "2                 -0.616725  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paired bootstrap 95% CI (B=2000)\n",
      "ΔRMSE (MF - no-topic): [-0.5595, -0.4501]\n",
      "ΔMAE  (MF - no-topic): [-0.6486, -0.5850]\n",
      "ΔRMSE (no-topic - full): [0.5418, 0.6451]  ( >0 means full TDFM better )\n",
      "ΔMAE  (no-topic - full): [0.6589, 0.7215]  ( >0 means full TDFM better )\n",
      "\n",
      "=== USER-level (block) bootstrap over users (MF - no-topic) ===\n",
      "Users in test: 913\n",
      "ΔRMSE (MF - no-topic): [-0.5601, -0.4502]   (B=2000)\n",
      "ΔMAE  (MF - no-topic): [-0.6486, -0.5836]   (B=2000)\n",
      "% users with lower RMSE under no-topic: 12.7%\n",
      "% users with lower MAE  under no-topic: 12.3%\n"
     ]
    }
   ],
   "source": [
    "# DEVICE = globals().get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- helper: clip to rating scale ---\n",
    "def _clip_1_5(x):\n",
    "    x = np.asarray(x).reshape(-1)\n",
    "    return np.clip(x, 1.0, 5.0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_tdfm_no_topic(model, loader, device=DEVICE):\n",
    "    \"\"\"Compute TDFM predictions with topic term removed: MF backbone + exposure bias only.\"\"\"\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        if len(batch) != 5:\n",
    "            raise ValueError(f\"Expected 5-tuple (u,i,bow,exposure,r), got {len(batch)}\")\n",
    "        u, i, bow, exposure, r = batch\n",
    "        u, i = u.to(device), i.to(device)\n",
    "        exposure = exposure.to(device).float()\n",
    "\n",
    "        # MF part\n",
    "        ue = model.user_embedding(u)\n",
    "        ie = model.item_embedding(i)\n",
    "        interaction = (model.mf_drop(ue) * model.mf_drop(ie)).sum(dim=1, keepdim=True)\n",
    "\n",
    "        u_b = model.user_bias(u)\n",
    "        i_b = model.item_bias(i)\n",
    "\n",
    "        # Exposure term (same as in the full model)\n",
    "        exp_term = model.exposure_bias(exposure)\n",
    "\n",
    "        raw = (interaction + u_b + i_b + exp_term).squeeze(1)\n",
    "        pred = torch.sigmoid(raw) * 4.0 + 1.0\n",
    "\n",
    "        preds.append(pred.detach().cpu().numpy().reshape(-1))\n",
    "        trues.append(r.detach().cpu().numpy().reshape(-1))\n",
    "\n",
    "    return np.concatenate(preds), np.concatenate(trues)\n",
    "\n",
    "# --- run ablation prediction on the SAME td_test_loader / y_test order ---\n",
    "td_pred_no_topic, y_test_nt = predict_tdfm_no_topic(tdfm_model.to(DEVICE), td_test_loader, device=DEVICE)\n",
    "\n",
    "# align / sanity-check\n",
    "y_test_nt = np.asarray(y_test_nt).reshape(-1)\n",
    "td_pred_no_topic = _clip_1_5(td_pred_no_topic)\n",
    "\n",
    "y_arr = np.asarray(y_test).reshape(-1)\n",
    "assert len(td_pred_no_topic) == len(y_arr) == len(mf_pred) == len(td_pred), \"Length mismatch among predictions.\"\n",
    "if not np.allclose(y_test_nt, y_arr):\n",
    "    raise RuntimeError(\"TDFM-no-topic test labels differ from y_test — check split alignment.\")\n",
    "\n",
    "# --- metrics ---\n",
    "def rmse_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.sqrt(np.mean((yhat - y) ** 2)))\n",
    "\n",
    "def mae_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.mean(np.abs(yhat - y)))\n",
    "\n",
    "rmse_mf = rmse_np(mf_pred, y_arr)\n",
    "rmse_td = rmse_np(td_pred, y_arr)\n",
    "rmse_nt = rmse_np(td_pred_no_topic, y_arr)\n",
    "\n",
    "mae_mf = mae_np(mf_pred, y_arr)\n",
    "mae_td = mae_np(td_pred, y_arr)\n",
    "mae_nt = mae_np(td_pred_no_topic, y_arr)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"model\": [\"MF\", \"TDFM(full)\", \"TDFM(no-topic)\"],\n",
    "    \"RMSE\":  [rmse_mf, rmse_td, rmse_nt],\n",
    "    \"MAE\":   [mae_mf,  mae_td,  mae_nt],\n",
    "    \"ΔRMSE vs MF (MF - model)\": [0.0, rmse_mf - rmse_td, rmse_mf - rmse_nt],\n",
    "    \"ΔMAE  vs MF (MF - model)\": [0.0, mae_mf  - mae_td,  mae_mf  - mae_nt],\n",
    "})\n",
    "display(summary)\n",
    "\n",
    "# --- paired bootstrap CIs (iid over observations) for MF - no-topic AND no-topic - full ---\n",
    "B = 2000\n",
    "rng = np.random.default_rng(0)\n",
    "n = len(y_arr)\n",
    "\n",
    "se_mf = (np.asarray(mf_pred) - y_arr) ** 2\n",
    "se_td = (np.asarray(td_pred) - y_arr) ** 2\n",
    "se_nt = (np.asarray(td_pred_no_topic) - y_arr) ** 2\n",
    "\n",
    "ae_mf = np.abs(np.asarray(mf_pred) - y_arr)\n",
    "ae_td = np.abs(np.asarray(td_pred) - y_arr)\n",
    "ae_nt = np.abs(np.asarray(td_pred_no_topic) - y_arr)\n",
    "\n",
    "impr_mf_nt_rmse = np.empty(B)\n",
    "impr_mf_nt_mae  = np.empty(B)\n",
    "impr_nt_td_rmse = np.empty(B)\n",
    "impr_nt_td_mae  = np.empty(B)\n",
    "\n",
    "for b in range(B):\n",
    "    idx = rng.integers(0, n, size=n)\n",
    "\n",
    "    # MF - no-topic\n",
    "    impr_mf_nt_rmse[b] = np.sqrt(se_mf[idx].mean()) - np.sqrt(se_nt[idx].mean())\n",
    "    impr_mf_nt_mae[b]  = ae_mf[idx].mean() - ae_nt[idx].mean()\n",
    "\n",
    "    # no-topic - full TDFM (positive means full TDFM better)\n",
    "    impr_nt_td_rmse[b] = np.sqrt(se_nt[idx].mean()) - np.sqrt(se_td[idx].mean())\n",
    "    impr_nt_td_mae[b]  = ae_nt[idx].mean() - ae_td[idx].mean()\n",
    "\n",
    "lo1, hi1 = np.percentile(impr_mf_nt_rmse, [2.5, 97.5])\n",
    "lo2, hi2 = np.percentile(impr_mf_nt_mae,  [2.5, 97.5])\n",
    "lo3, hi3 = np.percentile(impr_nt_td_rmse, [2.5, 97.5])\n",
    "lo4, hi4 = np.percentile(impr_nt_td_mae,  [2.5, 97.5])\n",
    "\n",
    "print(f\"\\nPaired bootstrap 95% CI (B={B})\")\n",
    "print(f\"ΔRMSE (MF - no-topic): [{lo1:.4f}, {hi1:.4f}]\")\n",
    "print(f\"ΔMAE  (MF - no-topic): [{lo2:.4f}, {hi2:.4f}]\")\n",
    "print(f\"ΔRMSE (no-topic - full): [{lo3:.4f}, {hi3:.4f}]  ( >0 means full TDFM better )\")\n",
    "print(f\"ΔMAE  (no-topic - full): [{lo4:.4f}, {hi4:.4f}]  ( >0 means full TDFM better )\")\n",
    "\n",
    "# --- USER-level (block) bootstrap for MF - no-topic (uses u_test from prior cell) ---\n",
    "if \"u_test\" in globals():\n",
    "    u_test_arr = np.asarray(u_test).reshape(-1).astype(int)\n",
    "    users = np.unique(u_test_arr)\n",
    "    user_to_pos = {u: j for j, u in enumerate(users)}\n",
    "    m = len(users)\n",
    "\n",
    "    cnt = np.zeros(m, dtype=np.int64)\n",
    "    sse_mf_u = np.zeros(m, dtype=float)\n",
    "    sse_nt_u = np.zeros(m, dtype=float)\n",
    "    sae_mf_u = np.zeros(m, dtype=float)\n",
    "    sae_nt_u = np.zeros(m, dtype=float)\n",
    "\n",
    "    se_mf_all = (np.asarray(mf_pred) - y_arr) ** 2\n",
    "    se_nt_all = (np.asarray(td_pred_no_topic) - y_arr) ** 2\n",
    "    ae_mf_all = np.abs(np.asarray(mf_pred) - y_arr)\n",
    "    ae_nt_all = np.abs(np.asarray(td_pred_no_topic) - y_arr)\n",
    "\n",
    "    for idx, u in enumerate(u_test_arr):\n",
    "        j = user_to_pos[int(u)]\n",
    "        cnt[j] += 1\n",
    "        sse_mf_u[j] += float(se_mf_all[idx])\n",
    "        sse_nt_u[j] += float(se_nt_all[idx])\n",
    "        sae_mf_u[j] += float(ae_mf_all[idx])\n",
    "        sae_nt_u[j] += float(ae_nt_all[idx])\n",
    "\n",
    "    rmse_user_mf = np.sqrt(sse_mf_u / np.maximum(cnt, 1))\n",
    "    rmse_user_nt = np.sqrt(sse_nt_u / np.maximum(cnt, 1))\n",
    "    pct_users_better_rmse = 100.0 * float((rmse_user_nt < rmse_user_mf).mean())\n",
    "\n",
    "    mae_user_mf = sae_mf_u / np.maximum(cnt, 1)\n",
    "    mae_user_nt = sae_nt_u / np.maximum(cnt, 1)\n",
    "    pct_users_better_mae = 100.0 * float((mae_user_nt < mae_user_mf).mean())\n",
    "\n",
    "    B = 2000\n",
    "    rng = np.random.default_rng(0)\n",
    "    impr_rmse = np.empty(B, dtype=float)\n",
    "    impr_mae  = np.empty(B, dtype=float)\n",
    "\n",
    "    for b in range(B):\n",
    "        picks = rng.integers(0, m, size=m)\n",
    "        cnt_b = cnt[picks].sum()\n",
    "        if cnt_b <= 0:\n",
    "            impr_rmse[b] = np.nan\n",
    "            impr_mae[b] = np.nan\n",
    "            continue\n",
    "        rmse_mf_b = np.sqrt(sse_mf_u[picks].sum() / cnt_b)\n",
    "        rmse_nt_b = np.sqrt(sse_nt_u[picks].sum() / cnt_b)\n",
    "        impr_rmse[b] = rmse_mf_b - rmse_nt_b\n",
    "\n",
    "        mae_mf_b = sae_mf_u[picks].sum() / cnt_b\n",
    "        mae_nt_b = sae_nt_u[picks].sum() / cnt_b\n",
    "        impr_mae[b] = mae_mf_b - mae_nt_b\n",
    "\n",
    "    lo_r, hi_r = np.nanpercentile(impr_rmse, [2.5, 97.5])\n",
    "    lo_a, hi_a = np.nanpercentile(impr_mae,  [2.5, 97.5])\n",
    "\n",
    "    print(\"\\n=== USER-level (block) bootstrap over users (MF - no-topic) ===\")\n",
    "    print(f\"Users in test: {m}\")\n",
    "    print(f\"ΔRMSE (MF - no-topic): [{lo_r:.4f}, {hi_r:.4f}]   (B={B})\")\n",
    "    print(f\"ΔMAE  (MF - no-topic): [{lo_a:.4f}, {hi_a:.4f}]   (B={B})\")\n",
    "    print(f\"% users with lower RMSE under no-topic: {pct_users_better_rmse:.1f}%\")\n",
    "    print(f\"% users with lower MAE  under no-topic: {pct_users_better_mae:.1f}%\")\n",
    "else:\n",
    "    print(\"[info] u_test not found (run the USER-level bootstrap cell above to enable block bootstrap here).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e64ec",
   "metadata": {},
   "source": [
    "Here we add:\n",
    "\n",
    "- Ranking metrics: Recall@K and NDCG@K with negative sampling (sweep over N_neg and K)\n",
    "- Slice evaluations: item popularity bins + user history length bins\n",
    "\n",
    "Ablations for ranking:\n",
    "- NoTopic_trained (fair): retrain a model without the topic/text term, same split and training setup\n",
    "- TDFM_obs_no_topic (diagnostic, drop-at-inference): use the full trained TDFM model but omit the topic term at scoring time (keep MF backbone + exposure term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0704346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df: (1217, 7) | unique users: 913 | unique items: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "item_id",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mf_pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "td_pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "item_pop_bin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_hist_bin",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2c413c35-abf1-424c-92c8-0304dd50b6f7",
       "rows": [
        [
         "0",
         "1405",
         "7",
         "5.0",
         "4.857407569885254",
         "4.793510437011719",
         "pop_bin_1",
         "hist_bin_1"
        ],
        [
         "1",
         "100",
         "51",
         "5.0",
         "4.841020584106445",
         "4.54981803894043",
         "pop_bin_0",
         "hist_bin_3"
        ],
        [
         "2",
         "700",
         "46",
         "4.0",
         "4.790133953094482",
         "4.821330547332764",
         "pop_bin_3",
         "hist_bin_1"
        ],
        [
         "3",
         "1552",
         "22",
         "5.0",
         "4.794485092163086",
         "4.863258361816406",
         "pop_bin_1",
         "hist_bin_2"
        ],
        [
         "4",
         "143",
         "57",
         "5.0",
         "4.833172798156738",
         "4.7322492599487305",
         "pop_bin_1",
         "hist_bin_3"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>mf_pred</th>\n",
       "      <th>td_pred</th>\n",
       "      <th>item_pop_bin</th>\n",
       "      <th>user_hist_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.857408</td>\n",
       "      <td>4.793510</td>\n",
       "      <td>pop_bin_1</td>\n",
       "      <td>hist_bin_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.841021</td>\n",
       "      <td>4.549818</td>\n",
       "      <td>pop_bin_0</td>\n",
       "      <td>hist_bin_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700</td>\n",
       "      <td>46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.790134</td>\n",
       "      <td>4.821331</td>\n",
       "      <td>pop_bin_3</td>\n",
       "      <td>hist_bin_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1552</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.794485</td>\n",
       "      <td>4.863258</td>\n",
       "      <td>pop_bin_1</td>\n",
       "      <td>hist_bin_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143</td>\n",
       "      <td>57</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.833173</td>\n",
       "      <td>4.732249</td>\n",
       "      <td>pop_bin_1</td>\n",
       "      <td>hist_bin_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating   mf_pred   td_pred item_pop_bin user_hist_bin\n",
       "0     1405        7     5.0  4.857408  4.793510    pop_bin_1    hist_bin_1\n",
       "1      100       51     5.0  4.841021  4.549818    pop_bin_0    hist_bin_3\n",
       "2      700       46     4.0  4.790134  4.821331    pop_bin_3    hist_bin_1\n",
       "3     1552       22     5.0  4.794485  4.863258    pop_bin_1    hist_bin_2\n",
       "4      143       57     5.0  4.833173  4.732249    pop_bin_1    hist_bin_3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# ===== 0) checks =====\n",
    "_required = [\"mf_train_loader\", \"mf_test_loader\", \"td_train_loader\", \"mf_pred\", \"td_pred\", \"y_test\", \"mf_model\", \"tdfm_model\", \"meta\"]\n",
    "_missing = [k for k in _required if k not in globals()]\n",
    "if _missing:\n",
    "    raise NameError(f\"Missing variables needed for ranking/slice eval: {_missing}\")\n",
    "\n",
    "# ===== 1) reconstruct aligned (user,item,rating) for the MF test loader order =====\n",
    "u_list, i_list, r_list = [], [], []\n",
    "for (u, it, r) in mf_test_loader:  # yields (u, i, r)\n",
    "    u_list.append(u.detach().cpu().numpy().reshape(-1))\n",
    "    i_list.append(it.detach().cpu().numpy().reshape(-1))\n",
    "    r_list.append(r.detach().cpu().numpy().reshape(-1))\n",
    "\n",
    "u_test = np.concatenate(u_list)\n",
    "i_test = np.concatenate(i_list)\n",
    "r_test = np.concatenate(r_list)\n",
    "\n",
    "y_arr = np.asarray(y_test).reshape(-1)\n",
    "mf_arr = np.asarray(mf_pred).reshape(-1)\n",
    "td_arr = np.asarray(td_pred).reshape(-1)\n",
    "\n",
    "assert len(y_arr) == len(u_test) == len(i_test) == len(mf_arr) == len(td_arr), \"Misaligned test arrays.\"\n",
    "if not np.allclose(r_test, y_arr):\n",
    "    print(\"[warn] mf_test_loader ratings != y_test order. Using r_test as ground truth in this section.\")\n",
    "    y_arr = r_test\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"user_id\": u_test.astype(int),\n",
    "    \"item_id\": i_test.astype(int),\n",
    "    \"rating\":  y_arr.astype(float),\n",
    "    \"mf_pred\": mf_arr.astype(float),\n",
    "    \"td_pred\": td_arr.astype(float),\n",
    "})\n",
    "\n",
    "# ===== 2) train interaction sets + popularity/history counts =====\n",
    "n_users = int(meta[\"n_users\"])\n",
    "n_items = int(meta[\"n_items\"])\n",
    "\n",
    "train_user_items = defaultdict(set)\n",
    "item_pop = np.zeros(n_items, dtype=np.int64)\n",
    "user_hist = np.zeros(n_users, dtype=np.int64)\n",
    "\n",
    "for (u, it, r) in mf_train_loader:\n",
    "    uu = u.detach().cpu().numpy().astype(int).reshape(-1)\n",
    "    ii = it.detach().cpu().numpy().astype(int).reshape(-1)\n",
    "    for a, b in zip(uu, ii):\n",
    "        train_user_items[a].add(b)\n",
    "    item_pop[ii] += 1\n",
    "    user_hist[uu] += 1\n",
    "\n",
    "# ===== 3) define bins (0 + quantiles among nonzero) =====\n",
    "def _make_quantile_edges(x_nonneg, qs):\n",
    "    x = np.asarray(x_nonneg)\n",
    "    x_nz = x[x > 0]\n",
    "    if len(x_nz) == 0:\n",
    "        return np.array([0.0, 1.0], dtype=float)\n",
    "    edges = np.unique(np.quantile(x_nz, qs))\n",
    "    edges = np.concatenate(([0.0], edges))\n",
    "    return edges\n",
    "\n",
    "pop_edges  = _make_quantile_edges(item_pop,  qs=[0.2, 0.6, 0.9, 1.0])\n",
    "hist_edges = _make_quantile_edges(user_hist, qs=[0.2, 0.6, 0.9, 1.0])\n",
    "\n",
    "pop_labels  = [f\"pop_bin_{k}\"  for k in range(len(pop_edges) - 1)]\n",
    "hist_labels = [f\"hist_bin_{k}\" for k in range(len(hist_edges) - 1)]\n",
    "\n",
    "def assign_bin(x, edges, labels):\n",
    "    j = np.searchsorted(edges, x, side=\"right\") - 1\n",
    "    j = np.clip(j, 0, len(labels) - 1)\n",
    "    return labels[j]\n",
    "\n",
    "item_pop_bin  = np.array([assign_bin(c, pop_edges,  pop_labels)  for c in item_pop], dtype=object)\n",
    "user_hist_bin = np.array([assign_bin(c, hist_edges, hist_labels) for c in user_hist], dtype=object)\n",
    "\n",
    "test_df[\"item_pop_bin\"]  = item_pop_bin[test_df[\"item_id\"].values]\n",
    "test_df[\"user_hist_bin\"] = user_hist_bin[test_df[\"user_id\"].values]\n",
    "\n",
    "print(\"test_df:\", test_df.shape, \"| unique users:\", test_df.user_id.nunique(), \"| unique items:\", test_df.item_id.nunique())\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520627fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_topic_term computed: (100,) | unseen items: 0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = globals().get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mf_model.eval()\n",
    "tdfm_model.eval()\n",
    "mf_model.to(DEVICE)\n",
    "tdfm_model.to(DEVICE)\n",
    "\n",
    "# ===== 4) TRAIN-only item-topic profiles (avoid test text leakage) =====\n",
    "K_topics = int(tdfm_model.topic_bias.weight.shape[1])  # num_topics\n",
    "theta_sum = np.zeros((n_items, K_topics), dtype=np.float64)\n",
    "theta_cnt = np.zeros(n_items, dtype=np.int64)\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_theta_from_bow(bow_batch: torch.Tensor) -> torch.Tensor:\n",
    "    # matches TDFM encoder path; dropout disabled because model.eval()\n",
    "    h = F.relu(tdfm_model.encoder_fc1(bow_batch))\n",
    "    h = tdfm_model.encoder_drop(h)\n",
    "    mu = tdfm_model.encoder_fc2(h)\n",
    "    theta = F.softmax(mu, dim=1)\n",
    "    return theta\n",
    "\n",
    "for batch in td_train_loader:\n",
    "    # expected: (u, i, bow, exposure, r)\n",
    "    u, it, bow, exposure, r = batch\n",
    "    it  = it.to(DEVICE)\n",
    "    bow = bow.to(DEVICE).float()\n",
    "\n",
    "    theta = infer_theta_from_bow(bow)  # (B, K)\n",
    "    it_np = it.detach().cpu().numpy().astype(int).reshape(-1)\n",
    "    th_np = theta.detach().cpu().numpy()\n",
    "\n",
    "    for idx, item_id in enumerate(it_np):\n",
    "        theta_sum[item_id] += th_np[idx]\n",
    "        theta_cnt[item_id] += 1\n",
    "\n",
    "item_theta = theta_sum / np.maximum(theta_cnt[:, None], 1)\n",
    "unif = np.ones(K_topics, dtype=np.float64) / K_topics\n",
    "item_theta[theta_cnt == 0] = unif\n",
    "\n",
    "w_topic = tdfm_model.topic_bias.weight.detach().cpu().numpy().reshape(-1)  # (K,)\n",
    "item_topic_term = item_theta @ w_topic  # (n_items,)\n",
    "\n",
    "print(\"item_topic_term computed:\", item_topic_term.shape, \"| unseen items:\", int((theta_cnt == 0).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566d3f3",
   "metadata": {},
   "source": [
    "### 6C. Ranking evaluation (Recall@K / NDCG@K) with negative sampling\n",
    "\n",
    "We evaluate top-K recommendation quality using negative sampling. We sweep `N_NEG` and `K`, and compute bootstrap CIs. Scoring uses the same trained models and (when available) the same exposure proxy used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposure_matrix: (2021, 100) min/max: 8.098121478949949e-11 2.194410800933838\n",
      "Users with >=1 positive in test: 875\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NDCG@10",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "52cacd40-abc6-4966-a718-8569a912fd1c",
       "rows": [
        [
         "0",
         "MF",
         "0.3705006802721088",
         "0.2512596444697476"
        ],
        [
         "1",
         "TDFM_pref(deconfounded)",
         "0.2756517006802721",
         "0.15288926319992613"
        ],
        [
         "2",
         "TDFM_observed",
         "0.373091156462585",
         "0.24047704066436465"
        ],
        [
         "3",
         "TDFM_observed(no-topic)",
         "0.43832925170068027",
         "0.27800983638924975"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MF</td>\n",
       "      <td>0.370501</td>\n",
       "      <td>0.251260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TDFM_pref(deconfounded)</td>\n",
       "      <td>0.275652</td>\n",
       "      <td>0.152889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TDFM_observed</td>\n",
       "      <td>0.373091</td>\n",
       "      <td>0.240477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TDFM_observed(no-topic)</td>\n",
       "      <td>0.438329</td>\n",
       "      <td>0.278010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  Recall@10   NDCG@10\n",
       "0                       MF   0.370501  0.251260\n",
       "1  TDFM_pref(deconfounded)   0.275652  0.152889\n",
       "2            TDFM_observed   0.373091  0.240477\n",
       "3  TDFM_observed(no-topic)   0.438329  0.278010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pop_bin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_pos",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MF_Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pref_Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Obs_Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ObsNoTopic_Recall@10",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "fac2a59e-d288-45fd-a2b2-58ded1b2f735",
       "rows": [
        [
         "0",
         "pop_bin_0",
         "105",
         "0.17142857142857143",
         "0.1619047619047619",
         "0.19047619047619047",
         "0.18095238095238095"
        ],
        [
         "1",
         "pop_bin_1",
         "275",
         "0.1709090909090909",
         "0.16363636363636364",
         "0.19272727272727272",
         "0.24727272727272728"
        ],
        [
         "2",
         "pop_bin_2",
         "403",
         "0.2506203473945409",
         "0.21339950372208435",
         "0.32754342431761785",
         "0.38957816377171217"
        ],
        [
         "3",
         "pop_bin_3",
         "372",
         "0.6290322580645161",
         "0.4112903225806452",
         "0.5618279569892473",
         "0.6370967741935484"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_bin</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>MF_Recall@10</th>\n",
       "      <th>Pref_Recall@10</th>\n",
       "      <th>Obs_Recall@10</th>\n",
       "      <th>ObsNoTopic_Recall@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pop_bin_0</td>\n",
       "      <td>105</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.180952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pop_bin_1</td>\n",
       "      <td>275</td>\n",
       "      <td>0.170909</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.192727</td>\n",
       "      <td>0.247273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pop_bin_2</td>\n",
       "      <td>403</td>\n",
       "      <td>0.250620</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.327543</td>\n",
       "      <td>0.389578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pop_bin_3</td>\n",
       "      <td>372</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.561828</td>\n",
       "      <td>0.637097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pop_bin  n_pos  MF_Recall@10  Pref_Recall@10  Obs_Recall@10  \\\n",
       "0  pop_bin_0    105      0.171429        0.161905       0.190476   \n",
       "1  pop_bin_1    275      0.170909        0.163636       0.192727   \n",
       "2  pop_bin_2    403      0.250620        0.213400       0.327543   \n",
       "3  pop_bin_3    372      0.629032        0.411290       0.561828   \n",
       "\n",
       "   ObsNoTopic_Recall@10  \n",
       "0              0.180952  \n",
       "1              0.247273  \n",
       "2              0.389578  \n",
       "3              0.637097  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from typing import List\n",
    "\n",
    "# ===== 5) Ranking metrics with negative sampling (fixed: deconfounded ranking + true exposure) =====\n",
    "SEED = int(globals().get(\"SEED\", 0))\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "def recall_at_k(ranked_items: List[int], pos_set: set, k: int) -> float:\n",
    "    if len(pos_set) == 0:\n",
    "        return np.nan\n",
    "    topk = set(ranked_items[:k])\n",
    "    return len(topk & pos_set) / len(pos_set)\n",
    "\n",
    "def ndcg_at_k(ranked_items: List[int], pos_set: set, k: int) -> float:\n",
    "    if len(pos_set) == 0:\n",
    "        return np.nan\n",
    "    dcg = 0.0\n",
    "    for rank, it in enumerate(ranked_items[:k], start=1):\n",
    "        if it in pos_set:\n",
    "            dcg += 1.0 / math.log2(rank + 1)\n",
    "    ideal_hits = min(len(pos_set), k)\n",
    "    idcg = sum((1.0 / math.log2(r + 1) for r in range(1, ideal_hits + 1)))\n",
    "    return dcg / idcg if idcg > 0 else np.nan\n",
    "\n",
    "DEVICE = globals().get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mf_model.eval(); mf_model.to(DEVICE)\n",
    "tdfm_model.eval(); tdfm_model.to(DEVICE)\n",
    "\n",
    "# ---- Load exposure matrix Z_hat (same object used in TDFM training) ----\n",
    "_exposure_matrix = globals().get(\"exposure_matrix\", None)\n",
    "if _exposure_matrix is None:\n",
    "    _path = None\n",
    "    if \"CONFOUNDER_PATH\" in globals():\n",
    "        _path = CONFOUNDER_PATH\n",
    "    elif \"confounder_path\" in globals():\n",
    "        _path = confounder_path\n",
    "    if _path is None:\n",
    "        raise RuntimeError(\"Cannot find CONFOUNDER_PATH / confounder_path to load exposure_matrix for ranking eval.\")\n",
    "    _conf_obj = torch.load(_path, map_location=\"cpu\")\n",
    "    if isinstance(_conf_obj, dict) and (\"Z_hat\" in _conf_obj):\n",
    "        _exposure_matrix = _conf_obj[\"Z_hat\"]\n",
    "    else:\n",
    "        _exposure_matrix = _conf_obj\n",
    "    if not torch.is_tensor(_exposure_matrix):\n",
    "        _exposure_matrix = torch.tensor(_exposure_matrix)\n",
    "    exposure_matrix = _exposure_matrix.float().cpu()\n",
    "else:\n",
    "    exposure_matrix = _exposure_matrix.float().cpu()\n",
    "\n",
    "print(\"exposure_matrix:\", tuple(exposure_matrix.shape), \"min/max:\", float(exposure_matrix.min()), float(exposure_matrix.max()))\n",
    "\n",
    "def get_exposure_vec(user_id: int, item_ids: np.ndarray) -> np.ndarray:\n",
    "    u = int(user_id)\n",
    "    it = torch.tensor(item_ids, dtype=torch.long)\n",
    "    return exposure_matrix[u, it].numpy().reshape(-1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def score_mf(user_id: int, item_ids: np.ndarray) -> np.ndarray:\n",
    "    u = torch.full((len(item_ids),), int(user_id), device=DEVICE, dtype=torch.long)\n",
    "    it = torch.tensor(item_ids, device=DEVICE, dtype=torch.long)\n",
    "    return mf_model(u, it).detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def score_tdfm_pref(user_id: int, item_ids: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Deconfounded preference score for ranking: user/item MF + biases only.\"\"\"\n",
    "    u = torch.full((len(item_ids),), int(user_id), device=DEVICE, dtype=torch.long)\n",
    "    it = torch.tensor(item_ids, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "    ue = tdfm_model.user_embedding(u)\n",
    "    ie = tdfm_model.item_embedding(it)\n",
    "\n",
    "    # IMPORTANT: for ranking, do NOT include exposure/topic (confounding) terms\n",
    "    interaction = (ue * ie).sum(dim=1, keepdim=True)\n",
    "\n",
    "    u_b = tdfm_model.user_bias(u)\n",
    "    i_b = tdfm_model.item_bias(it)\n",
    "\n",
    "    raw = (interaction + u_b + i_b).squeeze(1)\n",
    "    pred = torch.sigmoid(raw) * 4.0 + 1.0\n",
    "    return pred.detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def score_tdfm_observed(user_id: int, item_ids: np.ndarray, exposure_vec: np.ndarray, *, use_topic: bool = True) -> np.ndarray:\n",
    "    \"\"\"Observed-rating predictor for ranking: preference + exposure (+ optional topic term).\"\"\"\n",
    "    u = torch.full((len(item_ids),), int(user_id), device=DEVICE, dtype=torch.long)\n",
    "    it = torch.tensor(item_ids, device=DEVICE, dtype=torch.long)\n",
    "\n",
    "    ue = tdfm_model.user_embedding(u)\n",
    "    ie = tdfm_model.item_embedding(it)\n",
    "    interaction = (ue * ie).sum(dim=1, keepdim=True)\n",
    "\n",
    "    u_b = tdfm_model.user_bias(u)\n",
    "    i_b = tdfm_model.item_bias(it)\n",
    "\n",
    "    exp = torch.tensor(exposure_vec, device=DEVICE, dtype=torch.float32).view(-1, 1)\n",
    "    exp_term = tdfm_model.exposure_bias(exp)\n",
    "\n",
    "    if use_topic:\n",
    "        topic_term = torch.tensor(item_topic_term[item_ids], device=DEVICE, dtype=torch.float32).view(-1, 1)\n",
    "    else:\n",
    "        topic_term = torch.zeros((len(item_ids), 1), device=DEVICE, dtype=torch.float32)\n",
    "\n",
    "    raw = (interaction + u_b + i_b + exp_term + topic_term).squeeze(1)\n",
    "    pred = torch.sigmoid(raw) * 4.0 + 1.0\n",
    "    return pred.detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "def sample_negatives_for_user(user_id: int, pos_items: np.ndarray, n_neg: int) -> np.ndarray:\n",
    "    banned = set(train_user_items.get(int(user_id), set()))\n",
    "    banned |= set(map(int, pos_items.tolist()))\n",
    "    pool = np.setdiff1d(np.arange(n_items, dtype=int), np.fromiter(banned, dtype=int), assume_unique=False)\n",
    "\n",
    "    if len(pool) == 0:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    if len(pool) >= n_neg:\n",
    "        return rng.choice(pool, size=n_neg, replace=False)\n",
    "    return rng.choice(pool, size=n_neg, replace=True)\n",
    "\n",
    "# ---- define positives from explicit ratings ----\n",
    "POS_THRESH = 4.0\n",
    "K = 10\n",
    "N_NEG = 100\n",
    "\n",
    "pos_df = test_df[test_df[\"rating\"] >= POS_THRESH]\n",
    "user_to_pos = pos_df.groupby(\"user_id\")[\"item_id\"].apply(lambda x: x.values.astype(int)).to_dict()\n",
    "users_eval = sorted(user_to_pos.keys())\n",
    "print(\"Users with >=1 positive in test:\", len(users_eval))\n",
    "\n",
    "mf_recalls, mf_ndcgs = [], []\n",
    "td_pref_recalls, td_pref_ndcgs = [], []\n",
    "td_obs_recalls, td_obs_ndcgs = [], []\n",
    "td_obs_notopic_recalls, td_obs_notopic_ndcgs = [], []\n",
    "\n",
    "# slice bookkeeping by item popularity bins (count per-positive hit)\n",
    "bin_total_pos = {b: 0 for b in pop_labels}\n",
    "bin_hit_mf = {b: 0 for b in pop_labels}\n",
    "bin_hit_pref = {b: 0 for b in pop_labels}\n",
    "bin_hit_obs = {b: 0 for b in pop_labels}\n",
    "bin_hit_obs_notopic = {b: 0 for b in pop_labels}\n",
    "\n",
    "for u in users_eval:\n",
    "    pos_items = user_to_pos[u]\n",
    "    neg_items = sample_negatives_for_user(u, pos_items, N_NEG)\n",
    "    cand = np.unique(np.concatenate([pos_items, neg_items])).astype(int)\n",
    "\n",
    "    exp_vec = get_exposure_vec(u, cand)\n",
    "\n",
    "    # scores\n",
    "    s_mf = score_mf(u, cand)\n",
    "    s_pref = score_tdfm_pref(u, cand)\n",
    "    s_obs = score_tdfm_observed(u, cand, exp_vec, use_topic=True)\n",
    "    s_obs_nt = score_tdfm_observed(u, cand, exp_vec, use_topic=False)  # ablation: remove topic term only\n",
    "\n",
    "    # ranks (desc)\n",
    "    rank_mf = cand[np.argsort(-s_mf)]\n",
    "    rank_pref = cand[np.argsort(-s_pref)]\n",
    "    rank_obs = cand[np.argsort(-s_obs)]\n",
    "    rank_obs_nt = cand[np.argsort(-s_obs_nt)]\n",
    "\n",
    "    pos_set = set(map(int, pos_items.tolist()))\n",
    "\n",
    "    mf_recalls.append(recall_at_k(rank_mf.tolist(), pos_set, K))\n",
    "    mf_ndcgs.append(ndcg_at_k(rank_mf.tolist(), pos_set, K))\n",
    "\n",
    "    td_pref_recalls.append(recall_at_k(rank_pref.tolist(), pos_set, K))\n",
    "    td_pref_ndcgs.append(ndcg_at_k(rank_pref.tolist(), pos_set, K))\n",
    "\n",
    "    td_obs_recalls.append(recall_at_k(rank_obs.tolist(), pos_set, K))\n",
    "    td_obs_ndcgs.append(ndcg_at_k(rank_obs.tolist(), pos_set, K))\n",
    "\n",
    "    td_obs_notopic_recalls.append(recall_at_k(rank_obs_nt.tolist(), pos_set, K))\n",
    "    td_obs_notopic_ndcgs.append(ndcg_at_k(rank_obs_nt.tolist(), pos_set, K))\n",
    "\n",
    "    # item popularity bin hit counting (per positive)\n",
    "    top_mf = set(rank_mf[:K].tolist())\n",
    "    top_pref = set(rank_pref[:K].tolist())\n",
    "    top_obs = set(rank_obs[:K].tolist())\n",
    "    top_obs_nt = set(rank_obs_nt[:K].tolist())\n",
    "\n",
    "    for it in pos_items:\n",
    "        b = item_pop_bin[int(it)]\n",
    "        bin_total_pos[b] += 1\n",
    "        if int(it) in top_mf: bin_hit_mf[b] += 1\n",
    "        if int(it) in top_pref: bin_hit_pref[b] += 1\n",
    "        if int(it) in top_obs: bin_hit_obs[b] += 1\n",
    "        if int(it) in top_obs_nt: bin_hit_obs_notopic[b] += 1\n",
    "\n",
    "def _mean(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return float(np.nanmean(x)) if np.isfinite(x).any() else np.nan\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"model\": [\"MF\", \"TDFM_pref(deconfounded)\", \"TDFM_observed\", \"TDFM_observed(no-topic)\"],\n",
    "    f\"Recall@{K}\": [\n",
    "        _mean(mf_recalls),\n",
    "        _mean(td_pref_recalls),\n",
    "        _mean(td_obs_recalls),\n",
    "        _mean(td_obs_notopic_recalls),\n",
    "    ],\n",
    "    f\"NDCG@{K}\": [\n",
    "        _mean(mf_ndcgs),\n",
    "        _mean(td_pref_ndcgs),\n",
    "        _mean(td_obs_ndcgs),\n",
    "        _mean(td_obs_notopic_ndcgs),\n",
    "    ],\n",
    "})\n",
    "display(results)\n",
    "\n",
    "pop_table = pd.DataFrame({\n",
    "    \"pop_bin\": pop_labels,\n",
    "    \"n_pos\":   [bin_total_pos[b] for b in pop_labels],\n",
    "    f\"MF_Recall@{K}\": [bin_hit_mf[b] / bin_total_pos[b] if bin_total_pos[b] > 0 else np.nan for b in pop_labels],\n",
    "    f\"Pref_Recall@{K}\": [bin_hit_pref[b] / bin_total_pos[b] if bin_total_pos[b] > 0 else np.nan for b in pop_labels],\n",
    "    f\"Obs_Recall@{K}\": [bin_hit_obs[b] / bin_total_pos[b] if bin_total_pos[b] > 0 else np.nan for b in pop_labels],\n",
    "    f\"ObsNoTopic_Recall@{K}\": [bin_hit_obs_notopic[b] / bin_total_pos[b] if bin_total_pos[b] > 0 else np.nan for b in pop_labels],\n",
    "})\n",
    "display(pop_table)\n",
    "\n",
    "# ---- Quick sanity check ----\n",
    "DEBUG = False\n",
    "if DEBUG and len(users_eval) > 0:\n",
    "    u0 = users_eval[0]\n",
    "    pos_items0 = user_to_pos[u0]\n",
    "    neg_items0 = sample_negatives_for_user(u0, pos_items0, 50)\n",
    "    cand0 = np.unique(np.concatenate([pos_items0, neg_items0])).astype(int)\n",
    "    exp0 = get_exposure_vec(u0, cand0)\n",
    "\n",
    "    s0_mf = score_mf(u0, cand0)\n",
    "    s0_pref = score_tdfm_pref(u0, cand0)\n",
    "    s0_obs = score_tdfm_observed(u0, cand0, exp0, use_topic=True)\n",
    "\n",
    "    print(\"MF std/min/max:\", float(np.std(s0_mf)), float(np.min(s0_mf)), float(np.max(s0_mf)))\n",
    "    print(\"TDFM_pref std/min/max:\", float(np.std(s0_pref)), float(np.min(s0_pref)), float(np.max(s0_pref)))\n",
    "    print(\"TDFM_obs std/min/max:\", float(np.std(s0_obs)), float(np.min(s0_obs)), float(np.max(s0_obs)))\n",
    "    print(\"Exposure min/max/mean:\", float(np.min(exp0)), float(np.max(exp0)), float(np.mean(exp0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862710c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_hist_bin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_users",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MF_Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pref_Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Obs_Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ObsNoTopic_Recall@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MF_NDCG@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Pref_NDCG@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Obs_NDCG@10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ObsNoTopic_NDCG@10",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6d4e3147-30f5-45b9-baf6-f192fbfa3c35",
       "rows": [
        [
         "0",
         "hist_bin_0",
         "62",
         "0.24193548387096775",
         "0.14784946236559138",
         "0.293010752688172",
         "0.3655913978494623",
         "0.13045936697263916",
         "0.07645387589788506",
         "0.17916744713797406",
         "0.21080510998821173"
        ],
        [
         "1",
         "hist_bin_1",
         "396",
         "0.41266835016835013",
         "0.2986111111111111",
         "0.3916245791245791",
         "0.47327441077441074",
         "0.2981000855141432",
         "0.16737840296629028",
         "0.25207150888090196",
         "0.3005290259469394"
        ],
        [
         "2",
         "hist_bin_2",
         "243",
         "0.3689986282578875",
         "0.3275034293552812",
         "0.38854595336076814",
         "0.45027434842249653",
         "0.2378187806557368",
         "0.18402395561600993",
         "0.2624356731614717",
         "0.30241650346941773"
        ],
        [
         "3",
         "hist_bin_3",
         "174",
         "0.32244116037219483",
         "0.19652435686918446",
         "0.33786261631089215",
         "0.36803503010399563",
         "0.2064718999757517",
         "0.1036683689938225",
         "0.20526921128557407",
         "0.21662060576590736"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_hist_bin</th>\n",
       "      <th>n_users</th>\n",
       "      <th>MF_Recall@10</th>\n",
       "      <th>Pref_Recall@10</th>\n",
       "      <th>Obs_Recall@10</th>\n",
       "      <th>ObsNoTopic_Recall@10</th>\n",
       "      <th>MF_NDCG@10</th>\n",
       "      <th>Pref_NDCG@10</th>\n",
       "      <th>Obs_NDCG@10</th>\n",
       "      <th>ObsNoTopic_NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hist_bin_0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.147849</td>\n",
       "      <td>0.293011</td>\n",
       "      <td>0.365591</td>\n",
       "      <td>0.130459</td>\n",
       "      <td>0.076454</td>\n",
       "      <td>0.179167</td>\n",
       "      <td>0.210805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hist_bin_1</td>\n",
       "      <td>396</td>\n",
       "      <td>0.412668</td>\n",
       "      <td>0.298611</td>\n",
       "      <td>0.391625</td>\n",
       "      <td>0.473274</td>\n",
       "      <td>0.298100</td>\n",
       "      <td>0.167378</td>\n",
       "      <td>0.252072</td>\n",
       "      <td>0.300529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hist_bin_2</td>\n",
       "      <td>243</td>\n",
       "      <td>0.368999</td>\n",
       "      <td>0.327503</td>\n",
       "      <td>0.388546</td>\n",
       "      <td>0.450274</td>\n",
       "      <td>0.237819</td>\n",
       "      <td>0.184024</td>\n",
       "      <td>0.262436</td>\n",
       "      <td>0.302417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hist_bin_3</td>\n",
       "      <td>174</td>\n",
       "      <td>0.322441</td>\n",
       "      <td>0.196524</td>\n",
       "      <td>0.337863</td>\n",
       "      <td>0.368035</td>\n",
       "      <td>0.206472</td>\n",
       "      <td>0.103668</td>\n",
       "      <td>0.205269</td>\n",
       "      <td>0.216621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_hist_bin  n_users  MF_Recall@10  Pref_Recall@10  Obs_Recall@10  \\\n",
       "0    hist_bin_0       62      0.241935        0.147849       0.293011   \n",
       "1    hist_bin_1      396      0.412668        0.298611       0.391625   \n",
       "2    hist_bin_2      243      0.368999        0.327503       0.388546   \n",
       "3    hist_bin_3      174      0.322441        0.196524       0.337863   \n",
       "\n",
       "   ObsNoTopic_Recall@10  MF_NDCG@10  Pref_NDCG@10  Obs_NDCG@10  \\\n",
       "0              0.365591    0.130459      0.076454     0.179167   \n",
       "1              0.473274    0.298100      0.167378     0.252072   \n",
       "2              0.450274    0.237819      0.184024     0.262436   \n",
       "3              0.368035    0.206472      0.103668     0.205269   \n",
       "\n",
       "   ObsNoTopic_NDCG@10  \n",
       "0            0.210805  \n",
       "1            0.300529  \n",
       "2            0.302417  \n",
       "3            0.216621  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== 6) User-history slices for ranking metrics (aligned with fixed ranking eval) =====\n",
    "user_bin = {u: user_hist_bin[int(u)] for u in users_eval}\n",
    "\n",
    "slice_rows = []\n",
    "for b in hist_labels:\n",
    "    idx = [j for j, u in enumerate(users_eval) if user_bin[u] == b]\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "    slice_rows.append({\n",
    "        \"user_hist_bin\": b,\n",
    "        \"n_users\": len(idx),\n",
    "\n",
    "        f\"MF_Recall@{K}\": float(np.nanmean(np.asarray(mf_recalls)[idx])),\n",
    "        f\"Pref_Recall@{K}\": float(np.nanmean(np.asarray(td_pref_recalls)[idx])),\n",
    "        f\"Obs_Recall@{K}\": float(np.nanmean(np.asarray(td_obs_recalls)[idx])),\n",
    "        f\"ObsNoTopic_Recall@{K}\": float(np.nanmean(np.asarray(td_obs_notopic_recalls)[idx])),\n",
    "\n",
    "        f\"MF_NDCG@{K}\": float(np.nanmean(np.asarray(mf_ndcgs)[idx])),\n",
    "        f\"Pref_NDCG@{K}\": float(np.nanmean(np.asarray(td_pref_ndcgs)[idx])),\n",
    "        f\"Obs_NDCG@{K}\": float(np.nanmean(np.asarray(td_obs_ndcgs)[idx])),\n",
    "        f\"ObsNoTopic_NDCG@{K}\": float(np.nanmean(np.asarray(td_obs_notopic_ndcgs)[idx])),\n",
    "    })\n",
    "\n",
    "slice_df = pd.DataFrame(slice_rows)\n",
    "display(slice_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24770dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "item_pop_bin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MF_RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TDFM_RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ΔRMSE(MF-TDFM)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MF_MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TDFM_MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ΔMAE(MF-TDFM)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9b16ea0b-7b89-4272-97ae-1138088438ba",
       "rows": [
        [
         "2",
         "pop_bin_2",
         "426",
         "0.6391447349304689",
         "0.5291988920288002",
         "0.10994584290166864",
         "0.44710590553955293",
         "0.34951246064593533",
         "0.0975934448936176"
        ],
        [
         "3",
         "pop_bin_3",
         "387",
         "0.5205724105931726",
         "0.4847532692385528",
         "0.03581914135461983",
         "0.2956832838304899",
         "0.2551101196643918",
         "0.04057316416609813"
        ],
        [
         "1",
         "pop_bin_1",
         "289",
         "0.6572674781224339",
         "0.5505501671599202",
         "0.10671731096251369",
         "0.4473268144270953",
         "0.3688425778517674",
         "0.07848423657532794"
        ],
        [
         "0",
         "pop_bin_0",
         "115",
         "0.7759106925154177",
         "0.6784732487447046",
         "0.09743744377071306",
         "0.5278014203776484",
         "0.4473068092180335",
         "0.08049461115961493"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_pop_bin</th>\n",
       "      <th>n</th>\n",
       "      <th>MF_RMSE</th>\n",
       "      <th>TDFM_RMSE</th>\n",
       "      <th>ΔRMSE(MF-TDFM)</th>\n",
       "      <th>MF_MAE</th>\n",
       "      <th>TDFM_MAE</th>\n",
       "      <th>ΔMAE(MF-TDFM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pop_bin_2</td>\n",
       "      <td>426</td>\n",
       "      <td>0.639145</td>\n",
       "      <td>0.529199</td>\n",
       "      <td>0.109946</td>\n",
       "      <td>0.447106</td>\n",
       "      <td>0.349512</td>\n",
       "      <td>0.097593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pop_bin_3</td>\n",
       "      <td>387</td>\n",
       "      <td>0.520572</td>\n",
       "      <td>0.484753</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>0.295683</td>\n",
       "      <td>0.255110</td>\n",
       "      <td>0.040573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pop_bin_1</td>\n",
       "      <td>289</td>\n",
       "      <td>0.657267</td>\n",
       "      <td>0.550550</td>\n",
       "      <td>0.106717</td>\n",
       "      <td>0.447327</td>\n",
       "      <td>0.368843</td>\n",
       "      <td>0.078484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pop_bin_0</td>\n",
       "      <td>115</td>\n",
       "      <td>0.775911</td>\n",
       "      <td>0.678473</td>\n",
       "      <td>0.097437</td>\n",
       "      <td>0.527801</td>\n",
       "      <td>0.447307</td>\n",
       "      <td>0.080495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_pop_bin    n   MF_RMSE  TDFM_RMSE  ΔRMSE(MF-TDFM)    MF_MAE  TDFM_MAE  \\\n",
       "2    pop_bin_2  426  0.639145   0.529199        0.109946  0.447106  0.349512   \n",
       "3    pop_bin_3  387  0.520572   0.484753        0.035819  0.295683  0.255110   \n",
       "1    pop_bin_1  289  0.657267   0.550550        0.106717  0.447327  0.368843   \n",
       "0    pop_bin_0  115  0.775911   0.678473        0.097437  0.527801  0.447307   \n",
       "\n",
       "   ΔMAE(MF-TDFM)  \n",
       "2       0.097593  \n",
       "3       0.040573  \n",
       "1       0.078484  \n",
       "0       0.080495  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_hist_bin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MF_RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TDFM_RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ΔRMSE(MF-TDFM)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MF_MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TDFM_MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ΔMAE(MF-TDFM)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8d524071-e402-4402-a850-36cf3598fbda",
       "rows": [
        [
         "1",
         "hist_bin_1",
         "444",
         "0.4981562627968981",
         "0.46209722082189253",
         "0.03605904197500559",
         "0.3522319817865217",
         "0.3044182153435441",
         "0.047813766442977634"
        ],
        [
         "3",
         "hist_bin_3",
         "338",
         "0.5799232806384133",
         "0.445928111068675",
         "0.13399516956973823",
         "0.37985356107971374",
         "0.3004401745880849",
         "0.07941338649162882"
        ],
        [
         "2",
         "hist_bin_2",
         "317",
         "0.7036585019257726",
         "0.5702927587360815",
         "0.13336574318969108",
         "0.4479503056228349",
         "0.3542423315980833",
         "0.09370797402475156"
        ],
        [
         "0",
         "hist_bin_0",
         "118",
         "0.8837872188305765",
         "0.8519980887153509",
         "0.03178913011522566",
         "0.5770288887670485",
         "0.48008836325952564",
         "0.09694052550752286"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_hist_bin</th>\n",
       "      <th>n</th>\n",
       "      <th>MF_RMSE</th>\n",
       "      <th>TDFM_RMSE</th>\n",
       "      <th>ΔRMSE(MF-TDFM)</th>\n",
       "      <th>MF_MAE</th>\n",
       "      <th>TDFM_MAE</th>\n",
       "      <th>ΔMAE(MF-TDFM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hist_bin_1</td>\n",
       "      <td>444</td>\n",
       "      <td>0.498156</td>\n",
       "      <td>0.462097</td>\n",
       "      <td>0.036059</td>\n",
       "      <td>0.352232</td>\n",
       "      <td>0.304418</td>\n",
       "      <td>0.047814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hist_bin_3</td>\n",
       "      <td>338</td>\n",
       "      <td>0.579923</td>\n",
       "      <td>0.445928</td>\n",
       "      <td>0.133995</td>\n",
       "      <td>0.379854</td>\n",
       "      <td>0.300440</td>\n",
       "      <td>0.079413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hist_bin_2</td>\n",
       "      <td>317</td>\n",
       "      <td>0.703659</td>\n",
       "      <td>0.570293</td>\n",
       "      <td>0.133366</td>\n",
       "      <td>0.447950</td>\n",
       "      <td>0.354242</td>\n",
       "      <td>0.093708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hist_bin_0</td>\n",
       "      <td>118</td>\n",
       "      <td>0.883787</td>\n",
       "      <td>0.851998</td>\n",
       "      <td>0.031789</td>\n",
       "      <td>0.577029</td>\n",
       "      <td>0.480088</td>\n",
       "      <td>0.096941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_hist_bin    n   MF_RMSE  TDFM_RMSE  ΔRMSE(MF-TDFM)    MF_MAE  TDFM_MAE  \\\n",
       "1    hist_bin_1  444  0.498156   0.462097        0.036059  0.352232  0.304418   \n",
       "3    hist_bin_3  338  0.579923   0.445928        0.133995  0.379854  0.300440   \n",
       "2    hist_bin_2  317  0.703659   0.570293        0.133366  0.447950  0.354242   \n",
       "0    hist_bin_0  118  0.883787   0.851998        0.031789  0.577029  0.480088   \n",
       "\n",
       "   ΔMAE(MF-TDFM)  \n",
       "1       0.047814  \n",
       "3       0.079413  \n",
       "2       0.093708  \n",
       "0       0.096941  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== 7) Rating-metric slices (RMSE/MAE by bins) =====\n",
    "def rmse_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.sqrt(np.mean((yhat - y) ** 2)))\n",
    "\n",
    "def mae_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.mean(np.abs(yhat - y)))\n",
    "\n",
    "def slice_rating_metrics(df, slice_col):\n",
    "    rows = []\n",
    "    for key, g in df.groupby(slice_col):\n",
    "        rows.append({\n",
    "            slice_col: key,\n",
    "            \"n\": len(g),\n",
    "            \"MF_RMSE\": rmse_np(g[\"mf_pred\"], g[\"rating\"]),\n",
    "            \"TDFM_RMSE\": rmse_np(g[\"td_pred\"], g[\"rating\"]),\n",
    "            \"ΔRMSE(MF-TDFM)\": rmse_np(g[\"mf_pred\"], g[\"rating\"]) - rmse_np(g[\"td_pred\"], g[\"rating\"]),\n",
    "            \"MF_MAE\": mae_np(g[\"mf_pred\"], g[\"rating\"]),\n",
    "            \"TDFM_MAE\": mae_np(g[\"td_pred\"], g[\"rating\"]),\n",
    "            \"ΔMAE(MF-TDFM)\": mae_np(g[\"mf_pred\"], g[\"rating\"]) - mae_np(g[\"td_pred\"], g[\"rating\"]),\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"n\", ascending=False)\n",
    "\n",
    "display(slice_rating_metrics(test_df, \"item_pop_bin\"))\n",
    "display(slice_rating_metrics(test_df, \"user_hist_bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943502ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SEED 0 =====\n",
      "[MF] Epoch 00 | Train MSE: 1.9027\n",
      "[MF] Epoch 05 | Train MSE: 0.0749\n",
      "[MF] Epoch 10 | Train MSE: 0.0403\n",
      "[MF] Epoch 15 | Train MSE: 0.0314\n",
      "[MF] Final Test RMSE: 0.6260\n",
      "\n",
      "Starting Robust TDFM Training...\n",
      "[TDFM] Epoch 00 | Loss=1.7168 | MSE=1.5157\n",
      "[TDFM] Epoch 05 | Loss=0.3076 | MSE=0.1119\n",
      "[TDFM] Epoch 10 | Loss=0.2674 | MSE=0.0733\n",
      "[TDFM] Epoch 15 | Loss=0.2696 | MSE=0.0749\n",
      "\n",
      "Sample Predictions vs Actuals:\n",
      "Pred: [4.8626003 4.6299314 4.8177    4.86901   4.7620544]\n",
      "True: [5. 5. 4. 5. 5.]\n",
      "\n",
      "[TDFM] Final Test RMSE: 0.5289\n",
      "[TDFM] Saved model -> .\\tdfm_model_seed0.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF   RMSE=0.6260  MAE=0.4071\n",
      "TDFM RMSE=0.5289  MAE=0.3360\n",
      "ΔRMSE (MF-TDFM)=0.0972   ΔMAE (MF-TDFM)=0.0711   time=19.3s\n",
      "Saved TDFM -> .\\tdfm_model_seed0.pt\n",
      "\n",
      "===== SEED 1 =====\n",
      "[MF] Epoch 00 | Train MSE: 1.9002\n",
      "[MF] Epoch 05 | Train MSE: 0.0745\n",
      "[MF] Epoch 10 | Train MSE: 0.0376\n",
      "[MF] Epoch 15 | Train MSE: 0.0316\n",
      "[MF] Final Test RMSE: 0.6393\n",
      "\n",
      "Starting Robust TDFM Training...\n",
      "[TDFM] Epoch 00 | Loss=1.7014 | MSE=1.5012\n",
      "[TDFM] Epoch 05 | Loss=0.3028 | MSE=0.1054\n",
      "[TDFM] Epoch 10 | Loss=0.2801 | MSE=0.0865\n",
      "[TDFM] Epoch 15 | Loss=0.2691 | MSE=0.0761\n",
      "\n",
      "Sample Predictions vs Actuals:\n",
      "Pred: [4.820733  4.7357273 4.829178  4.8427706 4.86367  ]\n",
      "True: [5. 5. 4. 5. 5.]\n",
      "\n",
      "[TDFM] Final Test RMSE: 0.5499\n",
      "[TDFM] Saved model -> .\\tdfm_model_seed1.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF   RMSE=0.6393  MAE=0.4140\n",
      "TDFM RMSE=0.5499  MAE=0.3430\n",
      "ΔRMSE (MF-TDFM)=0.0894   ΔMAE (MF-TDFM)=0.0709   time=20.4s\n",
      "Saved TDFM -> .\\tdfm_model_seed1.pt\n",
      "\n",
      "===== SEED 2 =====\n",
      "[MF] Epoch 00 | Train MSE: 1.8939\n",
      "[MF] Epoch 05 | Train MSE: 0.0749\n",
      "[MF] Epoch 10 | Train MSE: 0.0414\n",
      "[MF] Epoch 15 | Train MSE: 0.0337\n",
      "[MF] Final Test RMSE: 0.6225\n",
      "\n",
      "Starting Robust TDFM Training...\n",
      "[TDFM] Epoch 00 | Loss=1.7062 | MSE=1.5050\n",
      "[TDFM] Epoch 05 | Loss=0.3123 | MSE=0.1157\n",
      "[TDFM] Epoch 10 | Loss=0.2782 | MSE=0.0843\n",
      "[TDFM] Epoch 15 | Loss=0.2709 | MSE=0.0767\n",
      "\n",
      "Sample Predictions vs Actuals:\n",
      "Pred: [4.818203  4.7376757 4.8155804 4.893303  4.7631426]\n",
      "True: [5. 5. 4. 5. 5.]\n",
      "\n",
      "[TDFM] Final Test RMSE: 0.5274\n",
      "[TDFM] Saved model -> .\\tdfm_model_seed2.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF   RMSE=0.6225  MAE=0.4067\n",
      "TDFM RMSE=0.5274  MAE=0.3330\n",
      "ΔRMSE (MF-TDFM)=0.0950   ΔMAE (MF-TDFM)=0.0737   time=20.7s\n",
      "Saved TDFM -> .\\tdfm_model_seed2.pt\n",
      "\n",
      "===== SEED 3 =====\n",
      "[MF] Epoch 00 | Train MSE: 1.9039\n",
      "[MF] Epoch 05 | Train MSE: 0.0735\n",
      "[MF] Epoch 10 | Train MSE: 0.0374\n",
      "[MF] Epoch 15 | Train MSE: 0.0325\n",
      "[MF] Final Test RMSE: 0.6222\n",
      "\n",
      "Starting Robust TDFM Training...\n",
      "[TDFM] Epoch 00 | Loss=1.6992 | MSE=1.4979\n",
      "[TDFM] Epoch 05 | Loss=0.3124 | MSE=0.1162\n",
      "[TDFM] Epoch 10 | Loss=0.2794 | MSE=0.0855\n",
      "[TDFM] Epoch 15 | Loss=0.2673 | MSE=0.0744\n",
      "\n",
      "Sample Predictions vs Actuals:\n",
      "Pred: [4.833742  4.7418146 4.802458  4.8686695 4.8394127]\n",
      "True: [5. 5. 4. 5. 5.]\n",
      "\n",
      "[TDFM] Final Test RMSE: 0.5305\n",
      "[TDFM] Saved model -> .\\tdfm_model_seed3.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF   RMSE=0.6222  MAE=0.4075\n",
      "TDFM RMSE=0.5305  MAE=0.3417\n",
      "ΔRMSE (MF-TDFM)=0.0917   ΔMAE (MF-TDFM)=0.0659   time=21.8s\n",
      "Saved TDFM -> .\\tdfm_model_seed3.pt\n",
      "\n",
      "===== SEED 4 =====\n",
      "[MF] Epoch 00 | Train MSE: 1.9031\n",
      "[MF] Epoch 05 | Train MSE: 0.0742\n",
      "[MF] Epoch 10 | Train MSE: 0.0393\n",
      "[MF] Epoch 15 | Train MSE: 0.0314\n",
      "[MF] Final Test RMSE: 0.6107\n",
      "\n",
      "Starting Robust TDFM Training...\n",
      "[TDFM] Epoch 00 | Loss=1.7081 | MSE=1.5087\n",
      "[TDFM] Epoch 05 | Loss=0.3046 | MSE=0.1090\n",
      "[TDFM] Epoch 10 | Loss=0.2845 | MSE=0.0896\n",
      "[TDFM] Epoch 15 | Loss=0.2774 | MSE=0.0804\n",
      "\n",
      "Sample Predictions vs Actuals:\n",
      "Pred: [4.8087792 4.828246  4.8605156 4.881712  4.767796 ]\n",
      "True: [5. 5. 4. 5. 5.]\n",
      "\n",
      "[TDFM] Final Test RMSE: 0.5404\n",
      "[TDFM] Saved model -> .\\tdfm_model_seed4.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF   RMSE=0.6107  MAE=0.4013\n",
      "TDFM RMSE=0.5404  MAE=0.3407\n",
      "ΔRMSE (MF-TDFM)=0.0703   ΔMAE (MF-TDFM)=0.0605   time=18.8s\n",
      "Saved TDFM -> .\\tdfm_model_seed4.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "seed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mf_rmse",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mf_mae",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tdfm_rmse",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tdfm_mae",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_rmse",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "d_mae",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tdfm_ckpt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "seconds",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0ce5b63f-0eda-4c68-80af-4bdb7c5094f1",
       "rows": [
        [
         "0",
         "2",
         "0.6224786639213562",
         "0.40667280554771423",
         "0.5274466872215271",
         "0.33298590779304504",
         "0.0950319766998291",
         "0.07368689775466919",
         ".\\tdfm_model_seed2.pt",
         "20.651071310043335"
        ],
        [
         "1",
         "0",
         "0.626041054725647",
         "0.40705227851867676",
         "0.5288625359535217",
         "0.3359823226928711",
         "0.09717851877212524",
         "0.07106995582580566",
         ".\\tdfm_model_seed0.pt",
         "19.340503931045532"
        ],
        [
         "2",
         "3",
         "0.6221990585327148",
         "0.40754538774490356",
         "0.5304690003395081",
         "0.34165874123573303",
         "0.09173005819320679",
         "0.06588664650917053",
         ".\\tdfm_model_seed3.pt",
         "21.75550127029419"
        ],
        [
         "3",
         "4",
         "0.6107321977615356",
         "0.4012520909309387",
         "0.5403971076011658",
         "0.3407047688961029",
         "0.07033509016036987",
         "0.060547322034835815",
         ".\\tdfm_model_seed4.pt",
         "18.81427025794983"
        ],
        [
         "4",
         "1",
         "0.639284610748291",
         "0.413964182138443",
         "0.5498554706573486",
         "0.34304866194725037",
         "0.08942914009094238",
         "0.07091552019119263",
         ".\\tdfm_model_seed1.pt",
         "20.40252685546875"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>mf_rmse</th>\n",
       "      <th>mf_mae</th>\n",
       "      <th>tdfm_rmse</th>\n",
       "      <th>tdfm_mae</th>\n",
       "      <th>d_rmse</th>\n",
       "      <th>d_mae</th>\n",
       "      <th>tdfm_ckpt</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.622479</td>\n",
       "      <td>0.406673</td>\n",
       "      <td>0.527447</td>\n",
       "      <td>0.332986</td>\n",
       "      <td>0.095032</td>\n",
       "      <td>0.073687</td>\n",
       "      <td>.\\tdfm_model_seed2.pt</td>\n",
       "      <td>20.651071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.626041</td>\n",
       "      <td>0.407052</td>\n",
       "      <td>0.528863</td>\n",
       "      <td>0.335982</td>\n",
       "      <td>0.097179</td>\n",
       "      <td>0.071070</td>\n",
       "      <td>.\\tdfm_model_seed0.pt</td>\n",
       "      <td>19.340504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.622199</td>\n",
       "      <td>0.407545</td>\n",
       "      <td>0.530469</td>\n",
       "      <td>0.341659</td>\n",
       "      <td>0.091730</td>\n",
       "      <td>0.065887</td>\n",
       "      <td>.\\tdfm_model_seed3.pt</td>\n",
       "      <td>21.755501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.610732</td>\n",
       "      <td>0.401252</td>\n",
       "      <td>0.540397</td>\n",
       "      <td>0.340705</td>\n",
       "      <td>0.070335</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>.\\tdfm_model_seed4.pt</td>\n",
       "      <td>18.814270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.639285</td>\n",
       "      <td>0.413964</td>\n",
       "      <td>0.549855</td>\n",
       "      <td>0.343049</td>\n",
       "      <td>0.089429</td>\n",
       "      <td>0.070916</td>\n",
       "      <td>.\\tdfm_model_seed1.pt</td>\n",
       "      <td>20.402527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed   mf_rmse    mf_mae  tdfm_rmse  tdfm_mae    d_rmse     d_mae  \\\n",
       "0     2  0.622479  0.406673   0.527447  0.332986  0.095032  0.073687   \n",
       "1     0  0.626041  0.407052   0.528863  0.335982  0.097179  0.071070   \n",
       "2     3  0.622199  0.407545   0.530469  0.341659  0.091730  0.065887   \n",
       "3     4  0.610732  0.401252   0.540397  0.340705  0.070335  0.060547   \n",
       "4     1  0.639285  0.413964   0.549855  0.343049  0.089429  0.070916   \n",
       "\n",
       "               tdfm_ckpt    seconds  \n",
       "0  .\\tdfm_model_seed2.pt  20.651071  \n",
       "1  .\\tdfm_model_seed0.pt  19.340504  \n",
       "2  .\\tdfm_model_seed3.pt  21.755501  \n",
       "3  .\\tdfm_model_seed4.pt  18.814270  \n",
       "4  .\\tdfm_model_seed1.pt  20.402527  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ΔRMSE (MF-TDFM): mean=0.0887, std=0.0107 over 5 seeds\n",
      "ΔMAE  (MF-TDFM): mean=0.0684,  std=0.0052 over 5 seeds\n",
      "\n",
      "Best TDFM seed by RMSE: seed=2  TDFM_RMSE=0.5274  ckpt=.\\tdfm_model_seed2.pt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# ---- sanity checks (fail fast with clear messages) ----\n",
    "required = [\"meta\", \"set_seed\", \"train_mf_from_loaders\", \"train_tdfm_from_loaders\",\n",
    "            \"predict_mf\", \"predict_tdfm\", \"rmse\", \"mae\",\n",
    "            \"mf_train_loader\", \"mf_test_loader\", \"td_train_loader\", \"td_test_loader\", \"DEVICE\"]\n",
    "missing = [k for k in required if k not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Missing required variables/functions: {missing}\")\n",
    "\n",
    "n_users = int(meta[\"n_users\"])\n",
    "n_items = int(meta[\"n_items\"])\n",
    "vocab_size = int(meta.get(\"vocab_size\", globals().get(\"vocab_size\", None)))\n",
    "if vocab_size is None:\n",
    "    raise NameError(\"Could not find vocab_size (expected meta['vocab_size'] or global vocab_size).\")\n",
    "\n",
    "SAVE_DIR = globals().get(\"SAVE_DIR\", \".\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# choose seeds (edit as you like)\n",
    "SEEDS = globals().get(\"SEEDS\", [0, 1, 2, 3, 4])\n",
    "\n",
    "rows = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n===== SEED {seed} =====\")\n",
    "    set_seed(seed)\n",
    "    t0 = time.time()\n",
    "\n",
    "    # ---- MF ----\n",
    "    mf_test_rmse_trainfn, mf_losses, mf_model = train_mf_from_loaders(\n",
    "        mf_train_loader, mf_test_loader,\n",
    "        n_users=n_users, n_items=n_items,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    mf_pred, y_test = predict_mf(mf_model, mf_test_loader, device=DEVICE)\n",
    "    mf_rmse = rmse(mf_pred, y_test)\n",
    "    mf_mae  = mae(mf_pred, y_test)\n",
    "\n",
    "    # ---- TDFM ----\n",
    "    tdfm_path = os.path.join(SAVE_DIR, f\"tdfm_model_seed{seed}.pt\")\n",
    "    td_test_rmse_trainfn, td_losses, tdfm_model = train_tdfm_from_loaders(\n",
    "        td_train_loader, td_test_loader,\n",
    "        n_users=n_users, n_items=n_items, vocab_size=vocab_size,\n",
    "        device=DEVICE,\n",
    "        save_path=tdfm_path\n",
    "    )\n",
    "    td_pred, y_test2 = predict_tdfm(tdfm_model, td_test_loader, device=DEVICE)\n",
    "\n",
    "    # ensure we are comparing on the exact same targets\n",
    "    if len(y_test2) != len(y_test) or (not np.allclose(y_test2, y_test)):\n",
    "        raise ValueError(\"y_test mismatch between MF and TDFM loaders. They must be the same split/order.\")\n",
    "\n",
    "    td_rmse = rmse(td_pred, y_test)\n",
    "    td_mae  = mae(td_pred, y_test)\n",
    "\n",
    "    d_rmse = mf_rmse - td_rmse\n",
    "    d_mae  = mf_mae  - td_mae\n",
    "    secs = time.time() - t0\n",
    "\n",
    "    print(f\"MF   RMSE={mf_rmse:.4f}  MAE={mf_mae:.4f}\")\n",
    "    print(f\"TDFM RMSE={td_rmse:.4f}  MAE={td_mae:.4f}\")\n",
    "    print(f\"ΔRMSE (MF-TDFM)={d_rmse:.4f}   ΔMAE (MF-TDFM)={d_mae:.4f}   time={secs:.1f}s\")\n",
    "    print(f\"Saved TDFM -> {tdfm_path}\")\n",
    "\n",
    "    rows.append(dict(\n",
    "        seed=int(seed),\n",
    "        mf_rmse=float(mf_rmse), mf_mae=float(mf_mae),\n",
    "        tdfm_rmse=float(td_rmse), tdfm_mae=float(td_mae),\n",
    "        d_rmse=float(d_rmse), d_mae=float(d_mae),\n",
    "        tdfm_ckpt=tdfm_path,\n",
    "        seconds=float(secs)\n",
    "    ))\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"tdfm_rmse\").reset_index(drop=True)\n",
    "display(df)\n",
    "\n",
    "def _summ(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return float(x.mean()), float(x.std(ddof=1)) if len(x) > 1 else 0.0\n",
    "\n",
    "m_rmse, s_rmse = _summ(df[\"d_rmse\"])\n",
    "m_mae,  s_mae  = _summ(df[\"d_mae\"])\n",
    "print(f\"\\nΔRMSE (MF-TDFM): mean={m_rmse:.4f}, std={s_rmse:.4f} over {len(df)} seeds\")\n",
    "print(f\"ΔMAE  (MF-TDFM): mean={m_mae:.4f},  std={s_mae:.4f} over {len(df)} seeds\")\n",
    "\n",
    "best = df.iloc[int(df[\"tdfm_rmse\"].argmin())]\n",
    "print(f\"\\nBest TDFM seed by RMSE: seed={int(best.seed)}  TDFM_RMSE={best.tdfm_rmse:.4f}  ckpt={best.tdfm_ckpt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a1664",
   "metadata": {},
   "source": [
    "### 7. Topic inspection (uses saved vocab; no vectorizer rebuild)\n",
    "\n",
    "This block inspects the learned topics by reading the decoder weights from a trained TDFM checkpoint and mapping them back to tokens using the saved vocabulary (tdfm_vocab.npy).\n",
    "\n",
    "If we ran the multi-seed training/evaluation above, the code will automatically use the best seed checkpoint (lowest test RMSE) for topic inspection.\n",
    "\n",
    "If no multi-seed summary exists, it falls back to the checkpoint we pass via model_path (or the default behavior inside analyze_model_topics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b815984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[topic] Using best checkpoint: .\\tdfm_model_seed2.pt\n",
      "=== Loaded checkpoint ===\n",
      "ckpt: .\\tdfm_model_seed2.pt\n",
      "detected keys: user=user_embedding.weight, item=item_embedding.weight, decoder=decoder.weight\n",
      "ckpt: .\\tdfm_model_seed2.pt\n",
      "vocab: tdfm_vocab.npy  (|V|=1000)\n",
      "inferred config: {'num_users': 2021, 'num_items': 100, 'emb_dim': 8, 'vocab_size': 1000, 'num_topics': 10, 'user_key': 'user_embedding.weight', 'item_key': 'item_embedding.weight', 'decoder_key': 'decoder.weight'}\n",
      "checkpoint contains 14 tensors; showing a few hybrid-related keys:\n",
      "  - decoder.weight\n",
      "  - decoder_bn.num_batches_tracked\n",
      "  - decoder_bn.running_mean\n",
      "  - decoder_bn.running_var\n",
      "  - encoder_fc1.bias\n",
      "  - encoder_fc1.weight\n",
      "  - encoder_fc2.bias\n",
      "  - encoder_fc2.weight\n",
      "  - item_embedding.weight\n",
      "  - user_embedding.weight\n",
      "\n",
      "=== Top words per topic (by decoder weights) ===\n",
      "Topic 00: completely, thighs, celery, care, did, breasts, breast, don, really, soy\n",
      "Topic 01: try, cups, dish, cheesecake, fudge, follow, leave, served, recipe, mushroom\n",
      "Topic 02: follow, cups, cheesecake, served, try, powder, don, soy, recipes, completely\n",
      "Topic 03: cups, try, dish, fudge, follow, cheesecake, leave, recipe, mushroom, served\n",
      "Topic 04: dish, cheesecake, try, fudge, better, leave, served, mushroom, follow, cups\n",
      "Topic 05: did, time, make, recipe, definitely, like, half, little, fat, end\n",
      "Topic 06: try, cheesecake, better, dish, fudge, leave, served, follow, mushroom, felt\n",
      "Topic 07: coffee, good, pie, key, simple, lime, zucchini, soups, follow, cupcakes\n",
      "Topic 08: completely, celery, thighs, don, soy, powder, follow, breasts, breast, cheesecake\n",
      "Topic 09: glaze, excellent, favorite, cake, fresh, turkey, hand, loved, great, potatoes\n",
      "\n",
      "=== Topic prevalence (avg theta on sampled BOW rows) ===\n",
      "01. Topic 09: prevalence=0.8607 | words: glaze, excellent, favorite, cake, fresh, turkey, hand, loved, great, potatoes\n",
      "02. Topic 07: prevalence=0.0634 | words: coffee, good, pie, key, simple, lime, zucchini, soups, follow, cupcakes\n",
      "03. Topic 00: prevalence=0.0148 | words: completely, thighs, celery, care, did, breasts, breast, don, really, soy\n",
      "04. Topic 08: prevalence=0.0134 | words: completely, celery, thighs, don, soy, powder, follow, breasts, breast, cheesecake\n",
      "05. Topic 02: prevalence=0.0121 | words: follow, cups, cheesecake, served, try, powder, don, soy, recipes, completely\n",
      "06. Topic 05: prevalence=0.0093 | words: did, time, make, recipe, definitely, like, half, little, fat, end\n",
      "07. Topic 01: prevalence=0.0077 | words: try, cups, dish, cheesecake, fudge, follow, leave, served, recipe, mushroom\n",
      "08. Topic 03: prevalence=0.0073 | words: cups, try, dish, fudge, follow, cheesecake, leave, recipe, mushroom, served\n",
      "09. Topic 04: prevalence=0.0056 | words: dish, cheesecake, try, fudge, better, leave, served, mushroom, follow, cups\n",
      "10. Topic 06: prevalence=0.0056 | words: try, cheesecake, better, dish, fudge, leave, served, follow, mushroom, felt\n"
     ]
    }
   ],
   "source": [
    "# Topic inspection: here we load the full hybrid TDFM checkpoint + saved vocab\n",
    "# - Confirms the checkpoint contains the hybrid model components (user/item embeddings + encoder/decoder)\n",
    "# - Shows top words per topic\n",
    "# - Estimates topic prevalence by averaging theta on a sample of bag-of-words inputs\n",
    "\n",
    "def _pick_default_ckpt():\n",
    "    # Prefer the best checkpoint from the multi-seed sweep (if present)\n",
    "    if \"best\" in globals():\n",
    "        try:\n",
    "            if isinstance(best, dict) and \"tdfm_ckpt\" in best:\n",
    "                return str(best[\"tdfm_ckpt\"])\n",
    "            # pandas Series row\n",
    "            if hasattr(best, \"tdfm_ckpt\"):\n",
    "                return str(best.tdfm_ckpt)\n",
    "            if hasattr(best, \"__getitem__\") and \"tdfm_ckpt\" in best:\n",
    "                return str(best[\"tdfm_ckpt\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Fall back to the single-run checkpoint\n",
    "    if os.path.exists(\"tdfm_model.pt\"):\n",
    "        return \"tdfm_model.pt\"\n",
    "\n",
    "    # Otherwise try seed_runs/\n",
    "    if os.path.isdir(\"seed_runs\"):\n",
    "        pts = [os.path.join(\"seed_runs\", f) for f in os.listdir(\"seed_runs\") if f.endswith(\".pt\")]\n",
    "        if len(pts) > 0:\n",
    "            pts.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n",
    "            return pts[0]\n",
    "\n",
    "    raise FileNotFoundError(\"No TDFM checkpoint found. Expected tdfm_model.pt or seed_runs/*.pt\")\n",
    "\n",
    "def _load_state_dict(path, device=\"cpu\"):\n",
    "    obj = torch.load(path, map_location=device)\n",
    "    # Support either raw state_dict or a bundle {\"state_dict\": ..., \"config\": ...}\n",
    "    if isinstance(obj, dict) and \"state_dict\" in obj and isinstance(obj[\"state_dict\"], dict):\n",
    "        return obj[\"state_dict\"], obj.get(\"config\", {})\n",
    "    if isinstance(obj, dict):\n",
    "        return obj, {}\n",
    "    raise TypeError(f\"Unexpected checkpoint format: {type(obj)}\")\n",
    "\n",
    "def _infer_config_from_state_dict(sd):\n",
    "    \"\"\"Infer key dimensions from a saved checkpoint.\n",
    "\n",
    "    This notebook's TDFM class uses `user_embedding` / `item_embedding` by default,\n",
    "    but older variants may use `user_emb` / `item_emb`. We detect both.\n",
    "    \"\"\"\n",
    "\n",
    "    def _pick(candidates, regex=None):\n",
    "        for k in candidates:\n",
    "            if k in sd:\n",
    "                return k\n",
    "        if regex is not None:\n",
    "            for k in sd.keys():\n",
    "                if re.search(regex, k):\n",
    "                    return k\n",
    "        return None\n",
    "\n",
    "    # Possible embedding key names across variants\n",
    "    user_k = _pick(\n",
    "        [\"user_embedding.weight\", \"user_emb.weight\", \"user_factors.weight\", \"user_latent.weight\"],\n",
    "        regex=r\"user.*emb.*\\.weight$|user.*factor.*\\.weight$|user.*latent.*\\.weight$\",\n",
    "    )\n",
    "    item_k = _pick(\n",
    "        [\"item_embedding.weight\", \"item_emb.weight\", \"item_factors.weight\", \"item_latent.weight\"],\n",
    "        regex=r\"item.*emb.*\\.weight$|item.*factor.*\\.weight$|item.*latent.*\\.weight$\",\n",
    "    )\n",
    "\n",
    "    # Decoder key (topic-word weights)\n",
    "    dec_k = _pick([\"decoder.weight\"], regex=r\"decoder.*\\.weight$\")\n",
    "\n",
    "    missing = []\n",
    "    if dec_k is None:\n",
    "        missing.append(\"decoder.weight (or compatible decoder key)\")\n",
    "    if user_k is None:\n",
    "        missing.append(\"user embedding weight key\")\n",
    "    if item_k is None:\n",
    "        missing.append(\"item embedding weight key\")\n",
    "    if missing:\n",
    "        # Show a few keys to help debug without flooding output\n",
    "        preview = list(sd.keys())[:25]\n",
    "        raise KeyError(f\"Checkpoint is missing keys needed to reconstruct TDFM: {missing}. Example keys: {preview}\")\n",
    "\n",
    "    num_users = sd[user_k].shape[0]\n",
    "    num_items = sd[item_k].shape[0]\n",
    "    emb_dim   = sd[user_k].shape[1]\n",
    "    vocab_size = sd[dec_k].shape[0]   # Linear(out=vocab_size, in=num_topics)\n",
    "    num_topics = sd[dec_k].shape[1]\n",
    "\n",
    "    return {\n",
    "        \"num_users\": int(num_users),\n",
    "        \"num_items\": int(num_items),\n",
    "        \"emb_dim\": int(emb_dim),\n",
    "        \"vocab_size\": int(vocab_size),\n",
    "        \"num_topics\": int(num_topics),\n",
    "        \"user_key\": user_k,\n",
    "        \"item_key\": item_k,\n",
    "        \"decoder_key\": dec_k,\n",
    "    }\n",
    "\n",
    "\n",
    "def _top_words_by_topic(W, vocab, top_k=10):\n",
    "    \"\"\"Return top_k vocab words for each topic column in W.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : torch.Tensor or np.ndarray, shape (V, K)\n",
    "        Decoder weight matrix where rows correspond to vocab terms and columns to topics.\n",
    "    vocab : array-like of length V\n",
    "        Vocabulary tokens aligned with rows of W.\n",
    "    top_k : int\n",
    "        Number of top words per topic.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[list[str]]\n",
    "        topic_words[k] is a list of top_k tokens for topic k.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(W, torch.Tensor):\n",
    "            Wn = W.detach().cpu().numpy()\n",
    "        else:\n",
    "            Wn = np.asarray(W)\n",
    "    except Exception:\n",
    "        Wn = np.asarray(W)\n",
    "\n",
    "    # normalize vocab to list[str]\n",
    "    if hasattr(vocab, \"tolist\"):\n",
    "        v = vocab.tolist()\n",
    "    else:\n",
    "        v = list(vocab)\n",
    "    v = [str(t) for t in v]\n",
    "\n",
    "    V, K = Wn.shape\n",
    "    topic_words = []\n",
    "    for k in range(K):\n",
    "        idx = np.argsort(-Wn[:, k])[:top_k]\n",
    "        topic_words.append([v[int(i)] for i in idx])\n",
    "    return topic_words\n",
    "\n",
    "def analyze_model_topics(model_path=None, vocab_path=\"tdfm_vocab.npy\", top_k=10, device=\"cpu\",\n",
    "                         bow_matrix=None, bow_sample_size=5000, seed=0):\n",
    "    if model_path is None:\n",
    "        model_path = _pick_default_ckpt()\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Missing checkpoint: {model_path}\")\n",
    "    if not os.path.exists(vocab_path):\n",
    "        raise FileNotFoundError(f\"Missing vocab file: {vocab_path} (run the training cell that saves vocab first)\")\n",
    "\n",
    "    vocab = np.load(vocab_path, allow_pickle=True)\n",
    "    sd, cfg0 = _load_state_dict(model_path, device=device)\n",
    "    cfg = _infer_config_from_state_dict(sd)\n",
    "\n",
    "    print(\"=== Loaded checkpoint ===\")\n",
    "    print(f\"ckpt: {model_path}\")\n",
    "    print(f\"detected keys: user={cfg['user_key']}, item={cfg['item_key']}, decoder={cfg['decoder_key']}\")\n",
    "    print(f\"ckpt: {model_path}\")\n",
    "    print(f\"vocab: {vocab_path}  (|V|={len(vocab)})\")\n",
    "    print(\"inferred config:\", cfg)\n",
    "\n",
    "    # Sanity: confirm hybrid components exist\n",
    "    key_snippets = [k for k in sd.keys() if any(s in k for s in [\"user_emb\", \"item_emb\", \"encoder\", \"decoder\", \"rating\"])]\n",
    "    print(f\"checkpoint contains {len(sd)} tensors; showing a few hybrid-related keys:\")\n",
    "    for k in sorted(key_snippets)[:20]:\n",
    "        print(\"  -\", k)\n",
    "\n",
    "    # Reconstruct full model and load weights\n",
    "    model = TDFM(cfg[\"num_users\"], cfg[\"num_items\"], cfg[\"vocab_size\"],\n",
    "                 num_topics=cfg[\"num_topics\"], emb_dim=cfg[\"emb_dim\"])\n",
    "    # Normalize common key-name variants (older notebooks used user_emb/item_emb)\n",
    "    if \"user_emb.weight\" in sd and \"user_embedding.weight\" not in sd:\n",
    "        sd[\"user_embedding.weight\"] = sd.pop(\"user_emb.weight\")\n",
    "    if \"item_emb.weight\" in sd and \"item_embedding.weight\" not in sd:\n",
    "        sd[\"item_embedding.weight\"] = sd.pop(\"item_emb.weight\")\n",
    "\n",
    "    incompatible = model.load_state_dict(sd, strict=False)\n",
    "    if getattr(incompatible, \"missing_keys\", None):\n",
    "        if len(incompatible.missing_keys) > 0:\n",
    "            print(f\"[topic] Warning: missing keys when loading checkpoint: {incompatible.missing_keys[:10]}{' ...' if len(incompatible.missing_keys)>10 else ''}\")\n",
    "    if getattr(incompatible, \"unexpected_keys\", None):\n",
    "        if len(incompatible.unexpected_keys) > 0:\n",
    "            print(f\"[topic] Warning: unexpected keys in checkpoint: {incompatible.unexpected_keys[:10]}{' ...' if len(incompatible.unexpected_keys)>10 else ''}\")\n",
    "    model.eval()\n",
    "\n",
    "    # Topics from decoder weights\n",
    "    W = model.decoder.weight.detach()  # [V, K]\n",
    "    topic_words = _top_words_by_topic(W, vocab, top_k=top_k)\n",
    "\n",
    "    print(\"\\n=== Top words per topic (by decoder weights) ===\")\n",
    "    for k, words in enumerate(topic_words):\n",
    "        print(f\"Topic {k:02d}: \" + \", \".join(words))\n",
    "\n",
    "    # Estimate prevalence by averaging theta on a bow matrix (if provided)\n",
    "    if bow_matrix is not None:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        X = bow_matrix\n",
    "        if hasattr(X, \"toarray\"):\n",
    "            # sparse -> dense sample only\n",
    "            n = X.shape[0]\n",
    "            idx = rng.choice(n, size=min(bow_sample_size, n), replace=False)\n",
    "            Xs = X[idx].toarray()\n",
    "        else:\n",
    "            X = np.asarray(X)\n",
    "            n = X.shape[0]\n",
    "            idx = rng.choice(n, size=min(bow_sample_size, n), replace=False)\n",
    "            Xs = X[idx]\n",
    "\n",
    "        Xs = torch.tensor(Xs, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            h = F.relu(model.encoder_fc1(Xs))\n",
    "            h = model.encoder_drop(h)\n",
    "            theta_logits = model.encoder_fc2(h)\n",
    "            theta = F.softmax(theta_logits, dim=1)  # [N, K]\n",
    "            prev = theta.mean(dim=0).cpu().numpy()\n",
    "\n",
    "        order = np.argsort(-prev)\n",
    "        print(\"\\n=== Topic prevalence (avg theta on sampled BOW rows) ===\")\n",
    "        for rank, k in enumerate(order[:min(10, len(order))], start=1):\n",
    "            print(f\"{rank:02d}. Topic {int(k):02d}: prevalence={prev[k]:.4f} | words: \" + \", \".join(topic_words[int(k)]))\n",
    "    else:\n",
    "        print(\"\\n(prevalence not computed) Tip: pass bow_matrix=reviews_all (or the BOW matrix you built) to estimate topic prevalence.\")\n",
    "\n",
    "# Use the in-memory bag-of-words if available (no rebuild)\n",
    "bow_for_prev = None\n",
    "if \"reviews_all\" in globals():\n",
    "    bow_for_prev = reviews_all\n",
    "\n",
    "# --- Pick checkpoint for topic inspection (best-seed if multi-seed summary exists) ---\n",
    "best_ckpt_path = None\n",
    "if 'best' in globals():\n",
    "    try:\n",
    "        best_ckpt_path = str(best.tdfm_ckpt)\n",
    "    except Exception:\n",
    "        try:\n",
    "            best_ckpt_path = str(best['tdfm_ckpt'])\n",
    "        except Exception:\n",
    "            best_ckpt_path = None\n",
    "if best_ckpt_path is None and 'df' in globals():\n",
    "    try:\n",
    "        if 'tdfm_rmse' in df.columns and 'tdfm_ckpt' in df.columns:\n",
    "            _idx = df['tdfm_rmse'].astype(float).idxmin()\n",
    "            best_ckpt_path = str(df.loc[_idx, 'tdfm_ckpt'])\n",
    "    except Exception:\n",
    "        pass\n",
    "if best_ckpt_path is not None and str(best_ckpt_path).lower() not in ['none', 'nan', '']:\n",
    "    print(f\"[topic] Using best checkpoint: {best_ckpt_path}\")\n",
    "else:\n",
    "    best_ckpt_path = None\n",
    "    print(\"[topic] No best-seed checkpoint found; using default model_path=None.\")\n",
    "\n",
    "analyze_model_topics(model_path=best_ckpt_path, vocab_path=\"tdfm_vocab.npy\", top_k=10, device=\"cpu\", bow_matrix=bow_for_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a55f8",
   "metadata": {},
   "source": [
    "### 8. Robustness upgrades (trained ablation + topic-collapse diagnostics + ranking sweep)\n",
    "\n",
    "We add three high-ROI upgrades in this section:\n",
    "\n",
    "- Trained no-topic ablation (fair): retrain a model without the topic/text term (not just dropping it at inference).\n",
    "- Topic-collapse diagnostics (entropy/effective-topics + concentration checks on θ).\n",
    "- Ranking robustness sweep over (N_neg, K) plus slice evaluations and user-level bootstrap CIs.\n",
    "\n",
    "Note: In the ranking sweep we report both:\n",
    "- NoTopic_trained (fair retrained ablation), and\n",
    "- TDFM_obs_no_topic (diagnostic drop-at-inference: omit the topic term at scoring time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2c8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NoTopic] Epoch 00 | MSE=2.4887\n",
      "[NoTopic] Epoch 05 | MSE=0.1959\n",
      "[NoTopic] Epoch 10 | MSE=0.1309\n",
      "[NoTopic] Epoch 15 | MSE=0.1191\n",
      "Saved trained no-topic model -> tdfm_no_topic.pt (time: 6.5s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TDFMNoTopic(\n",
       "  (user_embedding): Embedding(2021, 8)\n",
       "  (item_embedding): Embedding(100, 8)\n",
       "  (user_bias): Embedding(2021, 1)\n",
       "  (item_bias): Embedding(100, 1)\n",
       "  (mf_drop): Dropout(p=0.2, inplace=False)\n",
       "  (exposure_bias): Linear(in_features=1, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 8.1 Trained no-topic ablation (retrain) =====\n",
    "\n",
    "# DEVICE = globals().get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = int(globals().get(\"SEED\", 0))\n",
    "\n",
    "def _set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "def rmse_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.sqrt(np.mean((yhat - y) ** 2)))\n",
    "\n",
    "def mae_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.mean(np.abs(yhat - y)))\n",
    "\n",
    "# Ensure exposure_matrix exists (same logic as earlier cell)\n",
    "if \"exposure_matrix\" not in globals():\n",
    "    conf_obj = torch.load(CONFOUNDER_PATH, map_location=\"cpu\")\n",
    "    if isinstance(conf_obj, dict) and (\"Z_hat\" in conf_obj):\n",
    "        exposure_matrix = conf_obj[\"Z_hat\"]\n",
    "    else:\n",
    "        exposure_matrix = conf_obj\n",
    "    if not torch.is_tensor(exposure_matrix):\n",
    "        exposure_matrix = torch.tensor(exposure_matrix)\n",
    "    exposure_matrix = exposure_matrix.float()\n",
    "    print(\"exposure_matrix:\", tuple(exposure_matrix.shape), exposure_matrix.min().item(), exposure_matrix.max().item())\n",
    "\n",
    "def get_exposure_vec(user_id: int, item_ids: np.ndarray) -> np.ndarray:\n",
    "    u = int(user_id)\n",
    "    it = torch.tensor(item_ids, dtype=torch.long)\n",
    "    return exposure_matrix[u, it].numpy().reshape(-1)\n",
    "\n",
    "# A trained ablation: remove topic encoder/decoder + topic_bias, keep MF + exposure\n",
    "class TDFMNoTopic(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_dim=EMBEDDING_DIM):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, emb_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.mf_drop = nn.Dropout(0.2)\n",
    "        self.exposure_bias = nn.Linear(1, 1, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        self.user_bias.weight.data.fill_(0.0)\n",
    "        self.item_bias.weight.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, user_idx, item_idx, exposure_val):\n",
    "        u_emb = self.user_embedding(user_idx)\n",
    "        i_emb = self.item_embedding(item_idx)\n",
    "        interaction = (u_emb * i_emb).sum(dim=1, keepdim=True)\n",
    "        interaction = self.mf_drop(interaction)\n",
    "        u_b = self.user_bias(user_idx)\n",
    "        i_b = self.item_bias(item_idx)\n",
    "        bias_exposure = self.exposure_bias(exposure_val)\n",
    "        raw_score = interaction + u_b + i_b + bias_exposure\n",
    "        pred = torch.sigmoid(raw_score) * 4.0 + 1.0\n",
    "        return pred.squeeze(1)\n",
    "\n",
    "def train_notopic_from_td_loaders(train_loader, test_loader, n_users, n_items,\n",
    "                                 emb_dim=EMBEDDING_DIM, epochs=None, lr=LEARNING_RATE,\n",
    "                                 weight_decay=WEIGHT_DECAY, device=DEVICE, save_path=\"tdfm_no_topic.pt\"):\n",
    "    _set_seed(SEED)\n",
    "    if epochs is None:\n",
    "        epochs = int(globals().get(\"EPOCHS\", 30))\n",
    "    model = TDFMNoTopic(n_users, n_items, emb_dim=emb_dim).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    for ep in range(epochs):\n",
    "        total_mse, nb = 0.0, 0\n",
    "        for users, items, reviews, exposure, ratings in train_loader:\n",
    "            users = users.to(device)\n",
    "            items = items.to(device)\n",
    "            exposure = exposure.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            pred = model(users, items, exposure)\n",
    "            loss = F.mse_loss(pred, ratings)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_mse += loss.item()\n",
    "            nb += 1\n",
    "\n",
    "        if ep % 5 == 0:\n",
    "            print(f\"[NoTopic] Epoch {ep:02d} | MSE={total_mse/max(nb,1):.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Saved trained no-topic model -> {save_path} (time: {time.time()-t0:.1f}s)\")\n",
    "    return model\n",
    "\n",
    "# Train (only if not already trained in this session)\n",
    "if \"tdfm_no_topic_model\" not in globals():\n",
    "    tdfm_no_topic_model = train_notopic_from_td_loaders(\n",
    "        td_train_loader, td_test_loader,\n",
    "        n_users=meta[\"n_users\"], n_items=meta[\"n_items\"],\n",
    "        epochs=int(globals().get(\"EPOCHS_NOTOPIC\", min(int(globals().get(\"EPOCHS\", 30)), 30))),\n",
    "        save_path=\"tdfm_no_topic.pt\"\n",
    "    )\n",
    "else:\n",
    "    print(\"tdfm_no_topic_model already exists; skipping retrain.\")\n",
    "\n",
    "tdfm_no_topic_model.eval()\n",
    "tdfm_no_topic_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da7dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained NoTopic RMSE/MAE: 0.6465311646461487 0.46096909046173096\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "item_id",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mf_pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "td_pred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "item_pop_bin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_hist_bin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "notopic_trained_pred",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "1d3c4765-d70c-465c-9525-ae030911309f",
       "rows": [
        [
         "0",
         "1405",
         "7",
         "5.0",
         "4.857407569885254",
         "4.793510437011719",
         "pop_bin_1",
         "hist_bin_1",
         "4.7643666"
        ],
        [
         "1",
         "100",
         "51",
         "5.0",
         "4.841020584106445",
         "4.54981803894043",
         "pop_bin_0",
         "hist_bin_3",
         "4.6782885"
        ],
        [
         "2",
         "700",
         "46",
         "4.0",
         "4.790133953094482",
         "4.821330547332764",
         "pop_bin_3",
         "hist_bin_1",
         "4.6916857"
        ],
        [
         "3",
         "1552",
         "22",
         "5.0",
         "4.794485092163086",
         "4.863258361816406",
         "pop_bin_1",
         "hist_bin_2",
         "4.9016085"
        ],
        [
         "4",
         "143",
         "57",
         "5.0",
         "4.833172798156738",
         "4.7322492599487305",
         "pop_bin_1",
         "hist_bin_3",
         "4.808285"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>mf_pred</th>\n",
       "      <th>td_pred</th>\n",
       "      <th>item_pop_bin</th>\n",
       "      <th>user_hist_bin</th>\n",
       "      <th>notopic_trained_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.857408</td>\n",
       "      <td>4.793510</td>\n",
       "      <td>pop_bin_1</td>\n",
       "      <td>hist_bin_1</td>\n",
       "      <td>4.764367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.841021</td>\n",
       "      <td>4.549818</td>\n",
       "      <td>pop_bin_0</td>\n",
       "      <td>hist_bin_3</td>\n",
       "      <td>4.678288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700</td>\n",
       "      <td>46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.790134</td>\n",
       "      <td>4.821331</td>\n",
       "      <td>pop_bin_3</td>\n",
       "      <td>hist_bin_1</td>\n",
       "      <td>4.691686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1552</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.794485</td>\n",
       "      <td>4.863258</td>\n",
       "      <td>pop_bin_1</td>\n",
       "      <td>hist_bin_2</td>\n",
       "      <td>4.901608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143</td>\n",
       "      <td>57</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.833173</td>\n",
       "      <td>4.732249</td>\n",
       "      <td>pop_bin_1</td>\n",
       "      <td>hist_bin_3</td>\n",
       "      <td>4.808285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating   mf_pred   td_pred item_pop_bin user_hist_bin  \\\n",
       "0     1405        7     5.0  4.857408  4.793510    pop_bin_1    hist_bin_1   \n",
       "1      100       51     5.0  4.841021  4.549818    pop_bin_0    hist_bin_3   \n",
       "2      700       46     4.0  4.790134  4.821331    pop_bin_3    hist_bin_1   \n",
       "3     1552       22     5.0  4.794485  4.863258    pop_bin_1    hist_bin_2   \n",
       "4      143       57     5.0  4.833173  4.732249    pop_bin_1    hist_bin_3   \n",
       "\n",
       "   notopic_trained_pred  \n",
       "0              4.764367  \n",
       "1              4.678288  \n",
       "2              4.691686  \n",
       "3              4.901608  \n",
       "4              4.808285  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== 8.2 Evaluate trained no-topic ablation on the SAME aligned test set (u_test, i_test, y_test) =====\n",
    "@torch.no_grad()\n",
    "def predict_notopic_on_aligned_test(model, u_test, i_test, batch_size=2048):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    n = len(u_test)\n",
    "    for s in range(0, n, batch_size):\n",
    "        uu = torch.tensor(u_test[s:s+batch_size], device=DEVICE, dtype=torch.long)\n",
    "        ii = torch.tensor(i_test[s:s+batch_size], device=DEVICE, dtype=torch.long)\n",
    "        exp = torch.tensor(get_exposure_vec_batch(u_test[s:s+batch_size], i_test[s:s+batch_size]),\n",
    "                           device=DEVICE, dtype=torch.float32).view(-1,1)\n",
    "        p = model(uu, ii, exp)\n",
    "        preds.append(p.detach().cpu().numpy().reshape(-1))\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "def get_exposure_vec_batch(u_batch, i_batch):\n",
    "    # vectorized exposure lookup for aligned pairs\n",
    "    u_batch = np.asarray(u_batch, dtype=int).reshape(-1)\n",
    "    i_batch = np.asarray(i_batch, dtype=int).reshape(-1)\n",
    "    exp = exposure_matrix[u_batch, i_batch].numpy().reshape(-1)\n",
    "    return exp\n",
    "\n",
    "# ensure aligned arrays exist from earlier section\n",
    "assert \"u_test\" in globals() and \"i_test\" in globals() and \"y_test\" in globals(), \"Need u_test/i_test/y_test from earlier evaluation section.\"\n",
    "\n",
    "no_topic_pred_trained = predict_notopic_on_aligned_test(tdfm_no_topic_model, u_test, i_test)\n",
    "print(\"Trained NoTopic RMSE/MAE:\", rmse_np(no_topic_pred_trained, y_test), mae_np(no_topic_pred_trained, y_test))\n",
    "\n",
    "# add to test_df if present\n",
    "if \"test_df\" in globals():\n",
    "    test_df[\"notopic_trained_pred\"] = no_topic_pred_trained\n",
    "    display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d104c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "comparison",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ci_low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ci_high",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "121f1683-8b38-4c84-bf8f-28d166848893",
       "rows": [
        [
         "0",
         "MF - TDFM(full)",
         "ΔRMSE",
         "0.06993570694327354",
         "0.04401466399431229",
         "0.09665355384349822"
        ],
        [
         "1",
         "MF - TDFM(full)",
         "ΔMAE",
         "0.06025354778766632",
         "0.045059050619602206",
         "0.07568487673997877"
        ],
        [
         "2",
         "MF - NoTopic(trained)",
         "ΔRMSE",
         "-0.03617605748772621",
         "-0.05431181639432907",
         "-0.017545934021472958"
        ],
        [
         "3",
         "MF - NoTopic(trained)",
         "ΔMAE",
         "-0.05969381156563759",
         "-0.07204479351639748",
         "-0.04742570146918298"
        ],
        [
         "4",
         "NoTopic(trained) - TDFM(full)",
         "ΔRMSE",
         "0.10618741953372955",
         "0.08013214617967605",
         "0.1342363953590393"
        ],
        [
         "5",
         "NoTopic(trained) - TDFM(full)",
         "ΔMAE",
         "0.12035908797383309",
         "0.10371813103556633",
         "0.13727424442768096"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparison</th>\n",
       "      <th>metric</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MF - TDFM(full)</td>\n",
       "      <td>ΔRMSE</td>\n",
       "      <td>0.069936</td>\n",
       "      <td>0.044015</td>\n",
       "      <td>0.096654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MF - TDFM(full)</td>\n",
       "      <td>ΔMAE</td>\n",
       "      <td>0.060254</td>\n",
       "      <td>0.045059</td>\n",
       "      <td>0.075685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MF - NoTopic(trained)</td>\n",
       "      <td>ΔRMSE</td>\n",
       "      <td>-0.036176</td>\n",
       "      <td>-0.054312</td>\n",
       "      <td>-0.017546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MF - NoTopic(trained)</td>\n",
       "      <td>ΔMAE</td>\n",
       "      <td>-0.059694</td>\n",
       "      <td>-0.072045</td>\n",
       "      <td>-0.047426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoTopic(trained) - TDFM(full)</td>\n",
       "      <td>ΔRMSE</td>\n",
       "      <td>0.106187</td>\n",
       "      <td>0.080132</td>\n",
       "      <td>0.134236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoTopic(trained) - TDFM(full)</td>\n",
       "      <td>ΔMAE</td>\n",
       "      <td>0.120359</td>\n",
       "      <td>0.103718</td>\n",
       "      <td>0.137274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      comparison metric      mean    ci_low   ci_high\n",
       "0                MF - TDFM(full)  ΔRMSE  0.069936  0.044015  0.096654\n",
       "1                MF - TDFM(full)   ΔMAE  0.060254  0.045059  0.075685\n",
       "2          MF - NoTopic(trained)  ΔRMSE -0.036176 -0.054312 -0.017546\n",
       "3          MF - NoTopic(trained)   ΔMAE -0.059694 -0.072045 -0.047426\n",
       "4  NoTopic(trained) - TDFM(full)  ΔRMSE  0.106187  0.080132  0.134236\n",
       "5  NoTopic(trained) - TDFM(full)   ΔMAE  0.120359  0.103718  0.137274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[User-block] ΔRMSE (MF - NoTopic(trained)) mean=-0.0361 95%CI=[-0.0556,-0.0172]\n",
      "[User-block] ΔMAE  (MF - NoTopic(trained)) mean=-0.0594 95%CI=[-0.0723,-0.0462]\n"
     ]
    }
   ],
   "source": [
    "# ===== 8.3 Bootstrap deltas: MF vs full TDFM vs trained no-topic =====\n",
    "# Uses paired bootstrap over test points AND block bootstrap over users\n",
    "\n",
    "B = int(globals().get(\"BOOTSTRAP_B\", 2000))\n",
    "rng = np.random.default_rng(int(globals().get(\"SEED\", 0)))\n",
    "\n",
    "mf_p = np.asarray(mf_pred).reshape(-1)\n",
    "td_p = np.asarray(td_pred).reshape(-1)\n",
    "nt_p = np.asarray(no_topic_pred_trained).reshape(-1)\n",
    "y   = np.asarray(y_test).reshape(-1)\n",
    "\n",
    "def paired_bootstrap_ci(delta_fn, B=B):\n",
    "    n = len(y)\n",
    "    stats = []\n",
    "    for _ in range(B):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        stats.append(delta_fn(idx))\n",
    "    lo, hi = np.percentile(stats, [2.5, 97.5])\n",
    "    return float(np.mean(stats)), float(lo), float(hi)\n",
    "\n",
    "# paired: MF - model (positive means model better)\n",
    "def delta_rmse(m1, m2, idx):\n",
    "    return rmse_np(m1[idx], y[idx]) - rmse_np(m2[idx], y[idx])\n",
    "\n",
    "def delta_mae(m1, m2, idx):\n",
    "    return mae_np(m1[idx], y[idx]) - mae_np(m2[idx], y[idx])\n",
    "\n",
    "pairs = [\n",
    "    (\"MF\", \"TDFM(full)\", mf_p, td_p),\n",
    "    (\"MF\", \"NoTopic(trained)\", mf_p, nt_p),\n",
    "    (\"NoTopic(trained)\", \"TDFM(full)\", nt_p, td_p),\n",
    "]\n",
    "\n",
    "rows=[]\n",
    "for a_name, b_name, a_pred, b_pred in pairs:\n",
    "    m, lo, hi = paired_bootstrap_ci(lambda idx, ap=a_pred, bp=b_pred: delta_rmse(ap, bp, idx))\n",
    "    rows.append({\"comparison\": f\"{a_name} - {b_name}\", \"metric\": \"ΔRMSE\", \"mean\": m, \"ci_low\": lo, \"ci_high\": hi})\n",
    "    m, lo, hi = paired_bootstrap_ci(lambda idx, ap=a_pred, bp=b_pred: delta_mae(ap, bp, idx))\n",
    "    rows.append({\"comparison\": f\"{a_name} - {b_name}\", \"metric\": \"ΔMAE\", \"mean\": m, \"ci_low\": lo, \"ci_high\": hi})\n",
    "\n",
    "display(pd.DataFrame(rows))\n",
    "\n",
    "# User-block bootstrap for MF - NoTopic(trained)\n",
    "u_arr = np.asarray(u_test).reshape(-1)\n",
    "unique_users = np.unique(u_arr)\n",
    "user_to_idx = {u: np.where(u_arr == u)[0] for u in unique_users}\n",
    "\n",
    "def user_block_bootstrap_delta(pred_a, pred_b, metric=\"rmse\", B=B):\n",
    "    stats=[]\n",
    "    U = len(unique_users)\n",
    "    for _ in range(B):\n",
    "        sampled_users = rng.choice(unique_users, size=U, replace=True)\n",
    "        idx = np.concatenate([user_to_idx[u] for u in sampled_users])\n",
    "        if metric == \"rmse\":\n",
    "            stats.append(rmse_np(pred_a[idx], y[idx]) - rmse_np(pred_b[idx], y[idx]))\n",
    "        else:\n",
    "            stats.append(mae_np(pred_a[idx], y[idx]) - mae_np(pred_b[idx], y[idx]))\n",
    "    lo, hi = np.percentile(stats, [2.5, 97.5])\n",
    "    return float(np.mean(stats)), float(lo), float(hi)\n",
    "\n",
    "m, lo, hi = user_block_bootstrap_delta(mf_p, nt_p, metric=\"rmse\")\n",
    "print(f\"[User-block] ΔRMSE (MF - NoTopic(trained)) mean={m:.4f} 95%CI=[{lo:.4f},{hi:.4f}]\")\n",
    "m, lo, hi = user_block_bootstrap_delta(mf_p, nt_p, metric=\"mae\")\n",
    "print(f\"[User-block] ΔMAE  (MF - NoTopic(trained)) mean={m:.4f} 95%CI=[{lo:.4f},{hi:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd80be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "entropy_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "entropy_p10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "entropy_p50",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "entropy_p90",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eff_topics_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eff_topics_p10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eff_topics_p50",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eff_topics_p90",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "frac_max_gt_0.9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "frac_max_gt_0.8",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c9423ac8-c35d-40fb-80ba-3fc954b13e5d",
       "rows": [
        [
         "0",
         "0.39318904280662537",
         "0.00024006596941035247",
         "0.0705665573477745",
         "1.4362424731254577",
         "1.942004919052124",
         "1.0002400517463683",
         "1.0731159448623657",
         "4.204866075515747",
         "0.7226787181594084",
         "0.7943714050944947"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy_mean</th>\n",
       "      <th>entropy_p10</th>\n",
       "      <th>entropy_p50</th>\n",
       "      <th>entropy_p90</th>\n",
       "      <th>eff_topics_mean</th>\n",
       "      <th>eff_topics_p10</th>\n",
       "      <th>eff_topics_p50</th>\n",
       "      <th>eff_topics_p90</th>\n",
       "      <th>frac_max_gt_0.9</th>\n",
       "      <th>frac_max_gt_0.8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.393189</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.070567</td>\n",
       "      <td>1.436242</td>\n",
       "      <td>1.942005</td>\n",
       "      <td>1.00024</td>\n",
       "      <td>1.073116</td>\n",
       "      <td>4.204866</td>\n",
       "      <td>0.722679</td>\n",
       "      <td>0.794371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entropy_mean  entropy_p10  entropy_p50  entropy_p90  eff_topics_mean  \\\n",
       "0      0.393189      0.00024     0.070567     1.436242         1.942005   \n",
       "\n",
       "   eff_topics_p10  eff_topics_p50  eff_topics_p90  frac_max_gt_0.9  \\\n",
       "0         1.00024        1.073116        4.204866         0.722679   \n",
       "\n",
       "   frac_max_gt_0.8  \n",
       "0         0.794371  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "topic",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "prevalence",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "f1408398-9f96-40ce-b923-b4928199d0d7",
       "rows": [
        [
         "9",
         "9",
         "0.8546219"
        ],
        [
         "7",
         "7",
         "0.06974859"
        ],
        [
         "8",
         "8",
         "0.011292724"
        ],
        [
         "2",
         "2",
         "0.01020056"
        ],
        [
         "0",
         "0",
         "0.01009675"
        ],
        [
         "1",
         "1",
         "0.009538791"
        ],
        [
         "3",
         "3",
         "0.009230591"
        ],
        [
         "5",
         "5",
         "0.008710645"
        ],
        [
         "6",
         "6",
         "0.008353873"
        ],
        [
         "4",
         "4",
         "0.008207803"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.854622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.069749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.011293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.010201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.009231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.008711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.008208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  prevalence\n",
       "9      9    0.854622\n",
       "7      7    0.069749\n",
       "8      8    0.011293\n",
       "2      2    0.010201\n",
       "0      0    0.010097\n",
       "1      1    0.009539\n",
       "3      3    0.009231\n",
       "5      5    0.008711\n",
       "6      6    0.008354\n",
       "4      4    0.008208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== 8.4 Topic-collapse diagnostics (entropy / effective topics / concentration) =====\n",
    "# Uses TRAIN thetas inferred from the TDFM encoder, without touching test text.\n",
    "\n",
    "assert \"tdfm_model\" in globals(), \"Need trained tdfm_model.\"\n",
    "tdfm_model.eval()\n",
    "tdfm_model.to(DEVICE)\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_theta(bow_batch: torch.Tensor) -> np.ndarray:\n",
    "    bow_batch = bow_batch.to(DEVICE).float()\n",
    "    h = F.relu(tdfm_model.encoder_fc1(bow_batch))\n",
    "    h = tdfm_model.encoder_drop(h)  # in eval() this is disabled\n",
    "    mu = tdfm_model.encoder_fc2(h)\n",
    "    theta = F.softmax(mu, dim=1)\n",
    "    return theta.detach().cpu().numpy()\n",
    "\n",
    "thetas=[]\n",
    "max_batches = int(globals().get(\"THETA_DIAG_MAX_BATCHES\", 200))  # keep it fast\n",
    "for b, batch in enumerate(td_train_loader):\n",
    "    if b >= max_batches: break\n",
    "    u, it, bow, exposure, r = batch\n",
    "    th = infer_theta(bow)\n",
    "    thetas.append(th)\n",
    "\n",
    "theta_all = np.concatenate(thetas, axis=0)\n",
    "eps = 1e-12\n",
    "entropy = -(theta_all * np.log(theta_all + eps)).sum(axis=1)                 # H(theta)\n",
    "eff_topics = np.exp(entropy)                                                # effective number of topics\n",
    "max_prob = theta_all.max(axis=1)\n",
    "\n",
    "diag = pd.DataFrame({\n",
    "    \"entropy_mean\": [float(entropy.mean())],\n",
    "    \"entropy_p10\":  [float(np.percentile(entropy, 10))],\n",
    "    \"entropy_p50\":  [float(np.percentile(entropy, 50))],\n",
    "    \"entropy_p90\":  [float(np.percentile(entropy, 90))],\n",
    "    \"eff_topics_mean\": [float(eff_topics.mean())],\n",
    "    \"eff_topics_p10\":  [float(np.percentile(eff_topics, 10))],\n",
    "    \"eff_topics_p50\":  [float(np.percentile(eff_topics, 50))],\n",
    "    \"eff_topics_p90\":  [float(np.percentile(eff_topics, 90))],\n",
    "    \"frac_max_gt_0.9\": [float((max_prob > 0.9).mean())],\n",
    "    \"frac_max_gt_0.8\": [float((max_prob > 0.8).mean())],\n",
    "})\n",
    "display(diag)\n",
    "\n",
    "# Topic prevalence on sampled train points\n",
    "topic_prev = theta_all.mean(axis=0)\n",
    "prev_df = pd.DataFrame({\"topic\": np.arange(len(topic_prev)), \"prevalence\": topic_prev}).sort_values(\"prevalence\", ascending=False)\n",
    "display(prev_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe439ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MF': (875, 100), 'TDFM_pref': (875, 100), 'TDFM_obs': (875, 100), 'TDFM_obs_no_topic': (875, 100), 'NoTopic_trained_obs': (875, 100)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "N_NEG",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "K",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Recall@K",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NDCG@K",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4cb62a44-301c-445b-8755-e58faefd27dc",
       "rows": [
        [
         "0",
         "20",
         "5",
         "MF",
         "0.43506394557823125",
         "0.34084168624578526"
        ],
        [
         "4",
         "20",
         "5",
         "NoTopic_trained_obs",
         "0.6890557823129252",
         "0.5824086593366649"
        ],
        [
         "2",
         "20",
         "5",
         "TDFM_obs",
         "0.47283265306122446",
         "0.3341298408369024"
        ],
        [
         "3",
         "20",
         "5",
         "TDFM_obs_no_topic",
         "0.5020136054421768",
         "0.3690246917447151"
        ],
        [
         "1",
         "20",
         "5",
         "TDFM_pref",
         "0.3450802721088435",
         "0.21582427763957632"
        ],
        [
         "5",
         "20",
         "10",
         "MF",
         "0.6224761904761905",
         "0.400901933366632"
        ],
        [
         "9",
         "20",
         "10",
         "NoTopic_trained_obs",
         "0.8241931972789116",
         "0.6284333864147177"
        ],
        [
         "7",
         "20",
         "10",
         "TDFM_obs",
         "0.667891156462585",
         "0.3957141710735672"
        ],
        [
         "8",
         "20",
         "10",
         "TDFM_obs_no_topic",
         "0.6842448979591838",
         "0.4249235399042029"
        ],
        [
         "6",
         "20",
         "10",
         "TDFM_pref",
         "0.5846721088435375",
         "0.29793940011218456"
        ],
        [
         "10",
         "20",
         "20",
         "MF",
         "0.9535210884353741",
         "0.4906284682859798"
        ],
        [
         "14",
         "20",
         "20",
         "NoTopic_trained_obs",
         "0.9851020408163265",
         "0.6747519852430035"
        ],
        [
         "12",
         "20",
         "20",
         "TDFM_obs",
         "0.9730340136054422",
         "0.4740952324054627"
        ],
        [
         "13",
         "20",
         "20",
         "TDFM_obs_no_topic",
         "0.969651700680272",
         "0.5037132754633188"
        ],
        [
         "11",
         "20",
         "20",
         "TDFM_pref",
         "0.9531374149659864",
         "0.39552027561403663"
        ],
        [
         "15",
         "50",
         "5",
         "MF",
         "0.309934693877551",
         "0.24209537906363107"
        ],
        [
         "19",
         "50",
         "5",
         "NoTopic_trained_obs",
         "0.5552625850340136",
         "0.4734667353615301"
        ],
        [
         "17",
         "50",
         "5",
         "TDFM_obs",
         "0.2759836734693878",
         "0.2010891278893964"
        ],
        [
         "18",
         "50",
         "5",
         "TDFM_obs_no_topic",
         "0.32592653061224486",
         "0.23519844842803422"
        ],
        [
         "16",
         "50",
         "5",
         "TDFM_pref",
         "0.1577823129251701",
         "0.10147704628956332"
        ],
        [
         "20",
         "50",
         "10",
         "MF",
         "0.40583401360544213",
         "0.2763671463292849"
        ],
        [
         "24",
         "50",
         "10",
         "NoTopic_trained_obs",
         "0.6619319727891156",
         "0.5089617370700253"
        ],
        [
         "22",
         "50",
         "10",
         "TDFM_obs",
         "0.4127183673469388",
         "0.25202606508711534"
        ],
        [
         "23",
         "50",
         "10",
         "TDFM_obs_no_topic",
         "0.4636707482993197",
         "0.29187469342954375"
        ],
        [
         "21",
         "50",
         "10",
         "TDFM_pref",
         "0.289556462585034",
         "0.14632473752989997"
        ],
        [
         "25",
         "50",
         "20",
         "MF",
         "0.5444",
         "0.3195535080187757"
        ],
        [
         "29",
         "50",
         "20",
         "NoTopic_trained_obs",
         "0.7909278911564626",
         "0.5414663362795076"
        ],
        [
         "27",
         "50",
         "20",
         "TDFM_obs",
         "0.6121877551020408",
         "0.3027313218452676"
        ],
        [
         "28",
         "50",
         "20",
         "TDFM_obs_no_topic",
         "0.6473605442176871",
         "0.3326049522038419"
        ],
        [
         "26",
         "50",
         "20",
         "TDFM_pref",
         "0.5177197278911565",
         "0.2059005606430029"
        ],
        [
         "30",
         "100",
         "5",
         "MF",
         "0.28610068027210883",
         "0.22724549191938317"
        ],
        [
         "34",
         "100",
         "5",
         "NoTopic_trained_obs",
         "0.5445414965986395",
         "0.45716330690054224"
        ],
        [
         "32",
         "100",
         "5",
         "TDFM_obs",
         "0.2433278911564626",
         "0.1859070965347129"
        ],
        [
         "33",
         "100",
         "5",
         "TDFM_obs_no_topic",
         "0.30479455782312925",
         "0.21726694219134066"
        ],
        [
         "31",
         "100",
         "5",
         "TDFM_pref",
         "0.13819319727891155",
         "0.09111365884885672"
        ],
        [
         "35",
         "100",
         "10",
         "MF",
         "0.3745006802721088",
         "0.25881881132942613"
        ],
        [
         "39",
         "100",
         "10",
         "NoTopic_trained_obs",
         "0.6367510204081632",
         "0.4830535729251042"
        ],
        [
         "37",
         "100",
         "10",
         "TDFM_obs",
         "0.35877551020408166",
         "0.22277738750923703"
        ],
        [
         "38",
         "100",
         "10",
         "TDFM_obs_no_topic",
         "0.41829931972789114",
         "0.25932506226026375"
        ],
        [
         "36",
         "100",
         "10",
         "TDFM_pref",
         "0.24361360544217686",
         "0.12523861809406867"
        ],
        [
         "40",
         "100",
         "20",
         "MF",
         "0.494087074829932",
         "0.2906634538603846"
        ],
        [
         "44",
         "100",
         "20",
         "NoTopic_trained_obs",
         "0.7625768707482993",
         "0.5174508488740911"
        ],
        [
         "42",
         "100",
         "20",
         "TDFM_obs",
         "0.5563782312925171",
         "0.27346088081624026"
        ],
        [
         "43",
         "100",
         "20",
         "TDFM_obs_no_topic",
         "0.5786938775510204",
         "0.29648292166623547"
        ],
        [
         "41",
         "100",
         "20",
         "TDFM_pref",
         "0.42641632653061223",
         "0.1722201672254965"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 45
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_NEG</th>\n",
       "      <th>K</th>\n",
       "      <th>model</th>\n",
       "      <th>Recall@K</th>\n",
       "      <th>NDCG@K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>MF</td>\n",
       "      <td>0.435064</td>\n",
       "      <td>0.340842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>NoTopic_trained_obs</td>\n",
       "      <td>0.689056</td>\n",
       "      <td>0.582409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>TDFM_obs</td>\n",
       "      <td>0.472833</td>\n",
       "      <td>0.334130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>TDFM_obs_no_topic</td>\n",
       "      <td>0.502014</td>\n",
       "      <td>0.369025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>TDFM_pref</td>\n",
       "      <td>0.345080</td>\n",
       "      <td>0.215824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>MF</td>\n",
       "      <td>0.622476</td>\n",
       "      <td>0.400902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NoTopic_trained_obs</td>\n",
       "      <td>0.824193</td>\n",
       "      <td>0.628433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>TDFM_obs</td>\n",
       "      <td>0.667891</td>\n",
       "      <td>0.395714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>TDFM_obs_no_topic</td>\n",
       "      <td>0.684245</td>\n",
       "      <td>0.424924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>TDFM_pref</td>\n",
       "      <td>0.584672</td>\n",
       "      <td>0.297939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>MF</td>\n",
       "      <td>0.953521</td>\n",
       "      <td>0.490628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NoTopic_trained_obs</td>\n",
       "      <td>0.985102</td>\n",
       "      <td>0.674752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>TDFM_obs</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.474095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>TDFM_obs_no_topic</td>\n",
       "      <td>0.969652</td>\n",
       "      <td>0.503713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>TDFM_pref</td>\n",
       "      <td>0.953137</td>\n",
       "      <td>0.395520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>MF</td>\n",
       "      <td>0.309935</td>\n",
       "      <td>0.242095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>NoTopic_trained_obs</td>\n",
       "      <td>0.555263</td>\n",
       "      <td>0.473467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>TDFM_obs</td>\n",
       "      <td>0.275984</td>\n",
       "      <td>0.201089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>TDFM_obs_no_topic</td>\n",
       "      <td>0.325927</td>\n",
       "      <td>0.235198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>TDFM_pref</td>\n",
       "      <td>0.157782</td>\n",
       "      <td>0.101477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>MF</td>\n",
       "      <td>0.405834</td>\n",
       "      <td>0.276367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>NoTopic_trained_obs</td>\n",
       "      <td>0.661932</td>\n",
       "      <td>0.508962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>TDFM_obs</td>\n",
       "      <td>0.412718</td>\n",
       "      <td>0.252026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>TDFM_obs_no_topic</td>\n",
       "      <td>0.463671</td>\n",
       "      <td>0.291875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>TDFM_pref</td>\n",
       "      <td>0.289556</td>\n",
       "      <td>0.146325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>MF</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>0.319554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>NoTopic_trained_obs</td>\n",
       "      <td>0.790928</td>\n",
       "      <td>0.541466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>TDFM_obs</td>\n",
       "      <td>0.612188</td>\n",
       "      <td>0.302731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>TDFM_obs_no_topic</td>\n",
       "      <td>0.647361</td>\n",
       "      <td>0.332605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>TDFM_pref</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.205901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>MF</td>\n",
       "      <td>0.286101</td>\n",
       "      <td>0.227245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>NoTopic_trained_obs</td>\n",
       "      <td>0.544541</td>\n",
       "      <td>0.457163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>TDFM_obs</td>\n",
       "      <td>0.243328</td>\n",
       "      <td>0.185907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>TDFM_obs_no_topic</td>\n",
       "      <td>0.304795</td>\n",
       "      <td>0.217267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>TDFM_pref</td>\n",
       "      <td>0.138193</td>\n",
       "      <td>0.091114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>MF</td>\n",
       "      <td>0.374501</td>\n",
       "      <td>0.258819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>NoTopic_trained_obs</td>\n",
       "      <td>0.636751</td>\n",
       "      <td>0.483054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>TDFM_obs</td>\n",
       "      <td>0.358776</td>\n",
       "      <td>0.222777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>TDFM_obs_no_topic</td>\n",
       "      <td>0.418299</td>\n",
       "      <td>0.259325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>TDFM_pref</td>\n",
       "      <td>0.243614</td>\n",
       "      <td>0.125239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>MF</td>\n",
       "      <td>0.494087</td>\n",
       "      <td>0.290663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>NoTopic_trained_obs</td>\n",
       "      <td>0.762577</td>\n",
       "      <td>0.517451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>TDFM_obs</td>\n",
       "      <td>0.556378</td>\n",
       "      <td>0.273461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>TDFM_obs_no_topic</td>\n",
       "      <td>0.578694</td>\n",
       "      <td>0.296483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>TDFM_pref</td>\n",
       "      <td>0.426416</td>\n",
       "      <td>0.172220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N_NEG   K                model  Recall@K    NDCG@K\n",
       "0      20   5                   MF  0.435064  0.340842\n",
       "4      20   5  NoTopic_trained_obs  0.689056  0.582409\n",
       "2      20   5             TDFM_obs  0.472833  0.334130\n",
       "3      20   5    TDFM_obs_no_topic  0.502014  0.369025\n",
       "1      20   5            TDFM_pref  0.345080  0.215824\n",
       "5      20  10                   MF  0.622476  0.400902\n",
       "9      20  10  NoTopic_trained_obs  0.824193  0.628433\n",
       "7      20  10             TDFM_obs  0.667891  0.395714\n",
       "8      20  10    TDFM_obs_no_topic  0.684245  0.424924\n",
       "6      20  10            TDFM_pref  0.584672  0.297939\n",
       "10     20  20                   MF  0.953521  0.490628\n",
       "14     20  20  NoTopic_trained_obs  0.985102  0.674752\n",
       "12     20  20             TDFM_obs  0.973034  0.474095\n",
       "13     20  20    TDFM_obs_no_topic  0.969652  0.503713\n",
       "11     20  20            TDFM_pref  0.953137  0.395520\n",
       "15     50   5                   MF  0.309935  0.242095\n",
       "19     50   5  NoTopic_trained_obs  0.555263  0.473467\n",
       "17     50   5             TDFM_obs  0.275984  0.201089\n",
       "18     50   5    TDFM_obs_no_topic  0.325927  0.235198\n",
       "16     50   5            TDFM_pref  0.157782  0.101477\n",
       "20     50  10                   MF  0.405834  0.276367\n",
       "24     50  10  NoTopic_trained_obs  0.661932  0.508962\n",
       "22     50  10             TDFM_obs  0.412718  0.252026\n",
       "23     50  10    TDFM_obs_no_topic  0.463671  0.291875\n",
       "21     50  10            TDFM_pref  0.289556  0.146325\n",
       "25     50  20                   MF  0.544400  0.319554\n",
       "29     50  20  NoTopic_trained_obs  0.790928  0.541466\n",
       "27     50  20             TDFM_obs  0.612188  0.302731\n",
       "28     50  20    TDFM_obs_no_topic  0.647361  0.332605\n",
       "26     50  20            TDFM_pref  0.517720  0.205901\n",
       "30    100   5                   MF  0.286101  0.227245\n",
       "34    100   5  NoTopic_trained_obs  0.544541  0.457163\n",
       "32    100   5             TDFM_obs  0.243328  0.185907\n",
       "33    100   5    TDFM_obs_no_topic  0.304795  0.217267\n",
       "31    100   5            TDFM_pref  0.138193  0.091114\n",
       "35    100  10                   MF  0.374501  0.258819\n",
       "39    100  10  NoTopic_trained_obs  0.636751  0.483054\n",
       "37    100  10             TDFM_obs  0.358776  0.222777\n",
       "38    100  10    TDFM_obs_no_topic  0.418299  0.259325\n",
       "36    100  10            TDFM_pref  0.243614  0.125239\n",
       "40    100  20                   MF  0.494087  0.290663\n",
       "44    100  20  NoTopic_trained_obs  0.762577  0.517451\n",
       "42    100  20             TDFM_obs  0.556378  0.273461\n",
       "43    100  20    TDFM_obs_no_topic  0.578694  0.296483\n",
       "41    100  20            TDFM_pref  0.426416  0.172220"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "N_NEG",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "K",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ci_low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ci_high",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "74207669-ca55-4fa2-b24e-27d81b4fa848",
       "rows": [
        [
         "5",
         "20",
         "5",
         "ΔNDCG@5 (NoTopic_trained_obs-MF)",
         "0.24156697309087966",
         "0.21861871854307752",
         "0.2649293145324929"
        ],
        [
         "1",
         "20",
         "5",
         "ΔNDCG@5 (TDFM_obs-MF)",
         "-0.006711845408882847",
         "-0.03131115495468333",
         "0.017045399687911047"
        ],
        [
         "3",
         "20",
         "5",
         "ΔNDCG@5 (TDFM_obs_no_topic-MF)",
         "0.028183005498929797",
         "0.004756311584636359",
         "0.05327753209481821"
        ],
        [
         "7",
         "20",
         "5",
         "ΔNDCG@5 (TDFM_pref-MF)",
         "-0.1250174086062089",
         "-0.14932178384175535",
         "-0.0996971084306286"
        ],
        [
         "4",
         "20",
         "5",
         "ΔRecall@5 (NoTopic_trained_obs-MF)",
         "0.2539918367346939",
         "0.22251870748299318",
         "0.2842863945578231"
        ],
        [
         "0",
         "20",
         "5",
         "ΔRecall@5 (TDFM_obs-MF)",
         "0.03776870748299319",
         "0.00596687074829932",
         "0.06838523809523807"
        ],
        [
         "2",
         "20",
         "5",
         "ΔRecall@5 (TDFM_obs_no_topic-MF)",
         "0.06694965986394558",
         "0.03502673469387755",
         "0.10037795918367344"
        ],
        [
         "6",
         "20",
         "5",
         "ΔRecall@5 (TDFM_pref-MF)",
         "-0.08998367346938776",
         "-0.12467238095238095",
         "-0.05550414965986396"
        ],
        [
         "13",
         "20",
         "10",
         "ΔNDCG@10 (NoTopic_trained_obs-MF)",
         "0.2275314530480856",
         "0.20710693569603406",
         "0.24854142319121905"
        ],
        [
         "9",
         "20",
         "10",
         "ΔNDCG@10 (TDFM_obs-MF)",
         "-0.0051877622930647386",
         "-0.0267794336121217",
         "0.01636652186927506"
        ],
        [
         "11",
         "20",
         "10",
         "ΔNDCG@10 (TDFM_obs_no_topic-MF)",
         "0.02402160653757091",
         "0.0009009715468607232",
         "0.04618269425914923"
        ],
        [
         "15",
         "20",
         "10",
         "ΔNDCG@10 (TDFM_pref-MF)",
         "-0.1029625332544475",
         "-0.1257530313979587",
         "-0.08038982057577111"
        ],
        [
         "12",
         "20",
         "10",
         "ΔRecall@10 (NoTopic_trained_obs-MF)",
         "0.20171700680272112",
         "0.17393224489795917",
         "0.2293092517006802"
        ],
        [
         "8",
         "20",
         "10",
         "ΔRecall@10 (TDFM_obs-MF)",
         "0.04541496598639456",
         "0.01416578231292517",
         "0.07508619047619047"
        ],
        [
         "10",
         "20",
         "10",
         "ΔRecall@10 (TDFM_obs_no_topic-MF)",
         "0.0617687074829932",
         "0.02979047619047619",
         "0.09435680272108844"
        ],
        [
         "14",
         "20",
         "10",
         "ΔRecall@10 (TDFM_pref-MF)",
         "-0.037804081632653065",
         "-0.0704595238095238",
         "-0.00383108843537415"
        ],
        [
         "21",
         "20",
         "20",
         "ΔNDCG@20 (NoTopic_trained_obs-MF)",
         "0.1841235169570237",
         "0.16690633614422817",
         "0.20067578770078412"
        ],
        [
         "17",
         "20",
         "20",
         "ΔNDCG@20 (TDFM_obs-MF)",
         "-0.01653323588051711",
         "-0.033926327720501866",
         "0.001284766192686349"
        ],
        [
         "19",
         "20",
         "20",
         "ΔNDCG@20 (TDFM_obs_no_topic-MF)",
         "0.013084807177339038",
         "-0.0039033629853100203",
         "0.030464570510075114"
        ],
        [
         "23",
         "20",
         "20",
         "ΔNDCG@20 (TDFM_pref-MF)",
         "-0.09510819267194304",
         "-0.11420610415064837",
         "-0.07714126973875723"
        ],
        [
         "20",
         "20",
         "20",
         "ΔRecall@20 (NoTopic_trained_obs-MF)",
         "0.03158095238095238",
         "0.02039857142857143",
         "0.04342904761904762"
        ],
        [
         "16",
         "20",
         "20",
         "ΔRecall@20 (TDFM_obs-MF)",
         "0.019512925170068026",
         "0.0058825850340136045",
         "0.03379619047619047"
        ],
        [
         "18",
         "20",
         "20",
         "ΔRecall@20 (TDFM_obs_no_topic-MF)",
         "0.01613061224489796",
         "0.0024314965986394557",
         "0.030873877551020404"
        ],
        [
         "22",
         "20",
         "20",
         "ΔRecall@20 (TDFM_pref-MF)",
         "-0.00038367346938775426",
         "-0.015301224489795918",
         "0.015125170068027206"
        ],
        [
         "29",
         "50",
         "5",
         "ΔNDCG@5 (NoTopic_trained_obs-MF)",
         "0.23137135629789907",
         "0.2089365870225712",
         "0.25641607180963616"
        ],
        [
         "25",
         "50",
         "5",
         "ΔNDCG@5 (TDFM_obs-MF)",
         "-0.04100625117423468",
         "-0.06557933220180383",
         "-0.017264445554159957"
        ],
        [
         "27",
         "50",
         "5",
         "ΔNDCG@5 (TDFM_obs_no_topic-MF)",
         "-0.006896930635596837",
         "-0.02807401093501013",
         "0.014836606002932882"
        ],
        [
         "31",
         "50",
         "5",
         "ΔNDCG@5 (TDFM_pref-MF)",
         "-0.14061833277406777",
         "-0.16548033437980478",
         "-0.11623978125544193"
        ],
        [
         "28",
         "50",
         "5",
         "ΔRecall@5 (NoTopic_trained_obs-MF)",
         "0.24532789115646259",
         "0.21716224489795916",
         "0.2742040816326531"
        ],
        [
         "24",
         "50",
         "5",
         "ΔRecall@5 (TDFM_obs-MF)",
         "-0.033951020408163265",
         "-0.06374727891156463",
         "-0.003376054421768729"
        ],
        [
         "26",
         "50",
         "5",
         "ΔRecall@5 (TDFM_obs_no_topic-MF)",
         "0.015991836734693878",
         "-0.012643809523809528",
         "0.04382544217687071"
        ],
        [
         "30",
         "50",
         "5",
         "ΔRecall@5 (TDFM_pref-MF)",
         "-0.15215238095238096",
         "-0.18407904761904761",
         "-0.12009047619047622"
        ],
        [
         "37",
         "50",
         "10",
         "ΔNDCG@10 (NoTopic_trained_obs-MF)",
         "0.23259459074074051",
         "0.21225489784754198",
         "0.2539578698581867"
        ],
        [
         "33",
         "50",
         "10",
         "ΔNDCG@10 (TDFM_obs-MF)",
         "-0.024341081242169563",
         "-0.04705163107998434",
         "-0.0010835782710761702"
        ],
        [
         "35",
         "50",
         "10",
         "ΔNDCG@10 (TDFM_obs_no_topic-MF)",
         "0.0155075471002589",
         "-0.005359093566677403",
         "0.03606176141919173"
        ],
        [
         "39",
         "50",
         "10",
         "ΔNDCG@10 (TDFM_pref-MF)",
         "-0.1300424087993849",
         "-0.15195050632906823",
         "-0.10812268633685193"
        ],
        [
         "36",
         "50",
         "10",
         "ΔRecall@10 (NoTopic_trained_obs-MF)",
         "0.25609795918367345",
         "0.22594074829931973",
         "0.2876442176870748"
        ],
        [
         "32",
         "50",
         "10",
         "ΔRecall@10 (TDFM_obs-MF)",
         "0.006884353741496597",
         "-0.024303265306122444",
         "0.03771299319727889"
        ],
        [
         "34",
         "50",
         "10",
         "ΔRecall@10 (TDFM_obs_no_topic-MF)",
         "0.05783673469387754",
         "0.02518836734693878",
         "0.09114292517006796"
        ],
        [
         "38",
         "50",
         "10",
         "ΔRecall@10 (TDFM_pref-MF)",
         "-0.11627755102040815",
         "-0.14793829931972788",
         "-0.08334353741496599"
        ],
        [
         "45",
         "50",
         "20",
         "ΔNDCG@20 (NoTopic_trained_obs-MF)",
         "0.22191282826073191",
         "0.20358162152916442",
         "0.24135886608611437"
        ],
        [
         "41",
         "50",
         "20",
         "ΔNDCG@20 (TDFM_obs-MF)",
         "-0.016822186173508197",
         "-0.037955740950161194",
         "0.0029729057958553825"
        ],
        [
         "43",
         "50",
         "20",
         "ΔNDCG@20 (TDFM_obs_no_topic-MF)",
         "0.013051444185066178",
         "-0.006739727916127542",
         "0.03223418686649202"
        ],
        [
         "47",
         "50",
         "20",
         "ΔNDCG@20 (TDFM_pref-MF)",
         "-0.11365294737577278",
         "-0.13514596460509126",
         "-0.09289377120325502"
        ],
        [
         "44",
         "50",
         "20",
         "ΔRecall@20 (NoTopic_trained_obs-MF)",
         "0.2465278911564626",
         "0.21754721088435375",
         "0.27455244897959186"
        ],
        [
         "40",
         "50",
         "20",
         "ΔRecall@20 (TDFM_obs-MF)",
         "0.06778775510204083",
         "0.03578156462585034",
         "0.09840809523809523"
        ],
        [
         "42",
         "50",
         "20",
         "ΔRecall@20 (TDFM_obs_no_topic-MF)",
         "0.10296054421768706",
         "0.0709878231292517",
         "0.13474122448979586"
        ],
        [
         "46",
         "50",
         "20",
         "ΔRecall@20 (TDFM_pref-MF)",
         "-0.026680272108843536",
         "-0.056752244897959186",
         "0.005897414965986345"
        ],
        [
         "53",
         "100",
         "5",
         "ΔNDCG@5 (NoTopic_trained_obs-MF)",
         "0.2299178149811591",
         "0.2072162454348204",
         "0.25376109751825404"
        ],
        [
         "49",
         "100",
         "5",
         "ΔNDCG@5 (TDFM_obs-MF)",
         "-0.04133839538467028",
         "-0.06546871353868637",
         "-0.016949249828243088"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 72
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_NEG</th>\n",
       "      <th>K</th>\n",
       "      <th>metric</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>ΔNDCG@5 (NoTopic_trained_obs-MF)</td>\n",
       "      <td>0.241567</td>\n",
       "      <td>0.218619</td>\n",
       "      <td>0.264929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>ΔNDCG@5 (TDFM_obs-MF)</td>\n",
       "      <td>-0.006712</td>\n",
       "      <td>-0.031311</td>\n",
       "      <td>0.017045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>ΔNDCG@5 (TDFM_obs_no_topic-MF)</td>\n",
       "      <td>0.028183</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.053278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>ΔNDCG@5 (TDFM_pref-MF)</td>\n",
       "      <td>-0.125017</td>\n",
       "      <td>-0.149322</td>\n",
       "      <td>-0.099697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>ΔRecall@5 (NoTopic_trained_obs-MF)</td>\n",
       "      <td>0.253992</td>\n",
       "      <td>0.222519</td>\n",
       "      <td>0.284286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>ΔNDCG@20 (TDFM_pref-MF)</td>\n",
       "      <td>-0.118443</td>\n",
       "      <td>-0.139266</td>\n",
       "      <td>-0.097441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>ΔRecall@20 (NoTopic_trained_obs-MF)</td>\n",
       "      <td>0.268490</td>\n",
       "      <td>0.238702</td>\n",
       "      <td>0.298841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>ΔRecall@20 (TDFM_obs-MF)</td>\n",
       "      <td>0.062291</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>0.094719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>ΔRecall@20 (TDFM_obs_no_topic-MF)</td>\n",
       "      <td>0.084607</td>\n",
       "      <td>0.053167</td>\n",
       "      <td>0.116319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>ΔRecall@20 (TDFM_pref-MF)</td>\n",
       "      <td>-0.067671</td>\n",
       "      <td>-0.102186</td>\n",
       "      <td>-0.036268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    N_NEG   K                               metric      mean    ci_low  \\\n",
       "5      20   5     ΔNDCG@5 (NoTopic_trained_obs-MF)  0.241567  0.218619   \n",
       "1      20   5                ΔNDCG@5 (TDFM_obs-MF) -0.006712 -0.031311   \n",
       "3      20   5       ΔNDCG@5 (TDFM_obs_no_topic-MF)  0.028183  0.004756   \n",
       "7      20   5               ΔNDCG@5 (TDFM_pref-MF) -0.125017 -0.149322   \n",
       "4      20   5   ΔRecall@5 (NoTopic_trained_obs-MF)  0.253992  0.222519   \n",
       "..    ...  ..                                  ...       ...       ...   \n",
       "71    100  20              ΔNDCG@20 (TDFM_pref-MF) -0.118443 -0.139266   \n",
       "68    100  20  ΔRecall@20 (NoTopic_trained_obs-MF)  0.268490  0.238702   \n",
       "64    100  20             ΔRecall@20 (TDFM_obs-MF)  0.062291  0.031070   \n",
       "66    100  20    ΔRecall@20 (TDFM_obs_no_topic-MF)  0.084607  0.053167   \n",
       "70    100  20            ΔRecall@20 (TDFM_pref-MF) -0.067671 -0.102186   \n",
       "\n",
       "     ci_high  \n",
       "5   0.264929  \n",
       "1   0.017045  \n",
       "3   0.053278  \n",
       "7  -0.099697  \n",
       "4   0.284286  \n",
       "..       ...  \n",
       "71 -0.097441  \n",
       "68  0.298841  \n",
       "64  0.094719  \n",
       "66  0.116319  \n",
       "70 -0.036268  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== 8.5 Ranking robustness sweep: (N_NEG × K) + user-level bootstrap CI =====\n",
    "# We precompute per-user per-item scores once (items are only ~100, so this is cheap).\n",
    "\n",
    "assert \"users_eval\" in globals() and \"user_to_pos\" in globals(), \"Need users_eval and user_to_pos from ranking section.\"\n",
    "users = np.array(users_eval, dtype=int)\n",
    "nU = len(users)\n",
    "nI = int(meta[\"n_items\"])\n",
    "item_universe = np.arange(nI, dtype=int)\n",
    "\n",
    "tdfm_model.eval(); mf_model.eval()\n",
    "tdfm_model.to(DEVICE); mf_model.to(DEVICE)\n",
    "\n",
    "# Ensure item_topic_term exists (train-only item theta profile) for observed scoring\n",
    "assert \"item_topic_term\" in globals(), \"Need item_topic_term from earlier train-only topic profile cell.\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def precompute_scores():\n",
    "    # returns dict[name] -> (nU, nI) numpy scores\n",
    "    scores = {}\n",
    "\n",
    "    # Precompute item embeddings/biases for speed\n",
    "    it = torch.tensor(item_universe, device=DEVICE, dtype=torch.long)\n",
    "    mf_item_emb = mf_model.item_emb(it) if hasattr(mf_model, \"item_emb\") else mf_model.item_embedding(it)\n",
    "    mf_item_b   = mf_model.item_b(it).squeeze(1) if hasattr(mf_model, \"item_b\") else mf_model.item_bias(it).squeeze(1)\n",
    "\n",
    "    td_item_emb = tdfm_model.item_embedding(it)\n",
    "    td_item_b   = tdfm_model.item_bias(it).squeeze(1)\n",
    "    topic_term  = torch.tensor(item_topic_term[item_universe], device=DEVICE, dtype=torch.float32)\n",
    "\n",
    "    # exposure bias for each user/item\n",
    "    # we apply tdfm_model.exposure_bias to exp values\n",
    "    exp_all = exposure_matrix[users][:, item_universe]  # (nU,nI) torch on CPU\n",
    "    exp_all_t = exp_all.to(DEVICE).float().reshape(-1, 1)\n",
    "    exp_term_all = tdfm_model.exposure_bias(exp_all_t).reshape(nU, nI)\n",
    "\n",
    "    # user loop (nU ~ 875, nI ~ 100)\n",
    "    mf_scores = np.zeros((nU, nI), dtype=np.float32)\n",
    "    td_pref   = np.zeros((nU, nI), dtype=np.float32)\n",
    "    td_obs    = np.zeros((nU, nI), dtype=np.float32)\n",
    "    td_obs_nt = np.zeros((nU, nI), dtype=np.float32)\n",
    "    nt_trained= np.zeros((nU, nI), dtype=np.float32)\n",
    "\n",
    "    for idx_u, u in enumerate(users):\n",
    "        uu = torch.full((nI,), int(u), device=DEVICE, dtype=torch.long)\n",
    "\n",
    "        # MF\n",
    "        mf_u_emb = mf_model.user_emb(uu) if hasattr(mf_model, \"user_emb\") else mf_model.user_embedding(uu)\n",
    "        mf_u_b   = mf_model.user_b(uu).squeeze(1) if hasattr(mf_model, \"user_b\") else mf_model.user_bias(uu).squeeze(1)\n",
    "        raw_mf = (mf_u_emb * mf_item_emb).sum(dim=1) + mf_u_b + mf_item_b\n",
    "        mf_pred_all = torch.sigmoid(raw_mf) * 4.0 + 1.0\n",
    "        mf_scores[idx_u] = mf_pred_all.detach().cpu().numpy()\n",
    "\n",
    "        # TDFM preference (deconfounded)\n",
    "        td_u_emb = tdfm_model.user_embedding(uu)\n",
    "        td_u_b   = tdfm_model.user_bias(uu).squeeze(1)\n",
    "        raw_pref = (td_u_emb * td_item_emb).sum(dim=1) + td_u_b + td_item_b\n",
    "        td_pref_all = torch.sigmoid(raw_pref) * 4.0 + 1.0\n",
    "        td_pref[idx_u] = td_pref_all.detach().cpu().numpy()\n",
    "\n",
    "        # TDFM observed (with topic + exposure)\n",
    "        raw_obs = raw_pref + topic_term + exp_term_all[idx_u]\n",
    "        td_obs_all = torch.sigmoid(raw_obs) * 4.0 + 1.0\n",
    "        td_obs[idx_u] = td_obs_all.detach().cpu().numpy()\n",
    "\n",
    "        # TDFM observed no-topic\n",
    "        raw_obs_nt = raw_pref + exp_term_all[idx_u]\n",
    "        td_obs_nt_all = torch.sigmoid(raw_obs_nt) * 4.0 + 1.0\n",
    "        td_obs_nt[idx_u] = td_obs_nt_all.detach().cpu().numpy()\n",
    "\n",
    "        # Trained no-topic model observed (its own parameters)\n",
    "        # (MF backbone + exposure, trained)\n",
    "        uu2 = torch.full((nI,), int(u), device=DEVICE, dtype=torch.long)\n",
    "        exp_u = exp_all[idx_u].to(DEVICE).float().view(-1,1)\n",
    "        p = tdfm_no_topic_model(uu2, it, exp_u)\n",
    "        nt_trained[idx_u] = p.detach().cpu().numpy()\n",
    "\n",
    "    scores[\"MF\"] = mf_scores\n",
    "    scores[\"TDFM_pref\"] = td_pref\n",
    "    scores[\"TDFM_obs\"] = td_obs\n",
    "    scores[\"TDFM_obs_no_topic\"] = td_obs_nt\n",
    "    scores[\"NoTopic_trained_obs\"] = nt_trained\n",
    "    return scores\n",
    "\n",
    "scores = precompute_scores()\n",
    "print({k: v.shape for k,v in scores.items()})\n",
    "\n",
    "def recall_at_k_from_rank(rank_items, pos_set, k):\n",
    "    if len(pos_set) == 0: return np.nan\n",
    "    return len(set(rank_items[:k]) & pos_set) / len(pos_set)\n",
    "\n",
    "def ndcg_at_k_from_rank(rank_items, pos_set, k):\n",
    "    if len(pos_set) == 0: return np.nan\n",
    "    dcg=0.0\n",
    "    for r,it in enumerate(rank_items[:k], start=1):\n",
    "        if it in pos_set:\n",
    "            dcg += 1.0 / math.log2(r+1)\n",
    "    ideal = min(len(pos_set), k)\n",
    "    idcg = sum((1.0/math.log2(r+1) for r in range(1, ideal+1)))\n",
    "    return dcg/idcg if idcg>0 else np.nan\n",
    "\n",
    "rng = np.random.default_rng(int(globals().get(\"SEED\", 0)))\n",
    "\n",
    "def eval_ranking_setting(N_NEG, K):\n",
    "    # returns per-user recall/ndcg arrays for each model\n",
    "    rec = {name: [] for name in scores.keys()}\n",
    "    ndc = {name: [] for name in scores.keys()}\n",
    "    for idx_u, u in enumerate(users):\n",
    "        pos_items = np.array(user_to_pos[int(u)], dtype=int)\n",
    "        pos_set = set(pos_items.tolist())\n",
    "\n",
    "        # negatives: from items not in train or test positives\n",
    "        banned = set(train_user_items.get(int(u), set())) | pos_set\n",
    "        pool = np.array([it for it in item_universe if it not in banned], dtype=int)\n",
    "        if len(pool) == 0:\n",
    "            continue\n",
    "        neg = rng.choice(pool, size=min(N_NEG, len(pool)), replace=(len(pool) < N_NEG))\n",
    "        cand = np.unique(np.concatenate([pos_items, neg])).astype(int)\n",
    "\n",
    "        for name, S in scores.items():\n",
    "            sc = S[idx_u, cand]\n",
    "            ranked = cand[np.argsort(-sc)]\n",
    "            rec[name].append(recall_at_k_from_rank(ranked, pos_set, K))\n",
    "            ndc[name].append(ndcg_at_k_from_rank(ranked, pos_set, K))\n",
    "    # convert to arrays\n",
    "    rec = {k: np.asarray(v, dtype=float) for k,v in rec.items()}\n",
    "    ndc = {k: np.asarray(v, dtype=float) for k,v in ndc.items()}\n",
    "    return rec, ndc\n",
    "\n",
    "def bootstrap_ci(arr_delta, B=2000):\n",
    "    arr_delta = np.asarray(arr_delta, dtype=float)\n",
    "    n = len(arr_delta)\n",
    "    if n == 0:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    stats=[]\n",
    "    for _ in range(B):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        stats.append(np.nanmean(arr_delta[idx]))\n",
    "    lo, hi = np.percentile(stats, [2.5, 97.5])\n",
    "    return float(np.nanmean(arr_delta)), float(lo), float(hi)\n",
    "\n",
    "N_NEG_LIST = list(map(int, globals().get(\"RANK_NNEG_LIST\", [20, 50, 100])))\n",
    "K_LIST     = list(map(int, globals().get(\"RANK_K_LIST\", [5, 10, 20])))\n",
    "B_RANK     = int(globals().get(\"RANK_BOOTSTRAP_B\", 2000))\n",
    "\n",
    "summary_rows=[]\n",
    "ci_rows=[]\n",
    "for N_NEG in N_NEG_LIST:\n",
    "    for K in K_LIST:\n",
    "        rec, ndc = eval_ranking_setting(N_NEG=N_NEG, K=K)\n",
    "        # means\n",
    "        for name in scores.keys():\n",
    "            summary_rows.append({\"N_NEG\": N_NEG, \"K\": K, \"model\": name,\n",
    "                                 \"Recall@K\": float(np.nanmean(rec[name])),\n",
    "                                 \"NDCG@K\":   float(np.nanmean(ndc[name]))})\n",
    "        # CIs for deltas (model - MF)\n",
    "        for name in [\"TDFM_obs\", \"TDFM_obs_no_topic\", \"NoTopic_trained_obs\", \"TDFM_pref\"]:\n",
    "            d_rec = rec[name] - rec[\"MF\"]\n",
    "            d_ndc = ndc[name] - ndc[\"MF\"]\n",
    "            m, lo, hi = bootstrap_ci(d_rec, B=B_RANK)\n",
    "            ci_rows.append({\"N_NEG\": N_NEG, \"K\": K, \"metric\": f\"ΔRecall@{K} ({name}-MF)\", \"mean\": m, \"ci_low\": lo, \"ci_high\": hi})\n",
    "            m, lo, hi = bootstrap_ci(d_ndc, B=B_RANK)\n",
    "            ci_rows.append({\"N_NEG\": N_NEG, \"K\": K, \"metric\": f\"ΔNDCG@{K} ({name}-MF)\", \"mean\": m, \"ci_low\": lo, \"ci_high\": hi})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "ci_df = pd.DataFrame(ci_rows)\n",
    "\n",
    "display(summary_df.sort_values([\"N_NEG\",\"K\",\"model\"]))\n",
    "display(ci_df.sort_values([\"N_NEG\",\"K\",\"metric\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036d591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary (aligned test set)\n",
      "• MF RMSE/MAE = 0.6234/0.4066\n",
      "• TDFM(full) RMSE/MAE = 0.5369/0.3333\n",
      "⇒ Improvement (MF − Full): ΔRMSE = 0.0865, ΔMAE = 0.0733\n",
      "\n",
      "Ablation (trained no-topic; fair)\n",
      "• NoTopic(trained) RMSE/MAE = 0.6465/0.4610\n",
      "⇒ Improvement (MF − NoTopic trained): ΔRMSE = -0.0231, ΔMAE = -0.0543\n",
      "⇒ Topic contribution (NoTopic trained − Full): ΔRMSE = 0.1097, ΔMAE = 0.1276\n",
      "(Positive means the topic/text component helps rating prediction.)\n",
      "\n",
      "Notes\n",
      "• Ranking metrics are reported separately (Recall@K / NDCG@K with negative sampling).\n",
      "• If shown, “NoTopic (inference-time removal)” is *diagnostic only* and not a fair ablation because it was not retrained.\n"
     ]
    }
   ],
   "source": [
    "# ===== Summary =====\n",
    "\n",
    "def _rmse_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.sqrt(np.mean((yhat - y) ** 2)))\n",
    "\n",
    "def _mae_np(yhat, y):\n",
    "    yhat = np.asarray(yhat).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    return float(np.mean(np.abs(yhat - y)))\n",
    "\n",
    "def _fmt(x):\n",
    "    return \"NA\" if x is None else f\"{x:.4f}\"\n",
    "\n",
    "# Pull aligned vectors (prefer test_df if available)\n",
    "y = np.asarray(y_test).reshape(-1) if \"y_test\" in globals() else None\n",
    "\n",
    "mf_vec = None\n",
    "td_vec = None\n",
    "nt_tr_vec = None\n",
    "\n",
    "if \"test_df\" in globals():\n",
    "    if \"rating\" in test_df.columns and y is None:\n",
    "        y = test_df[\"rating\"].to_numpy().reshape(-1)\n",
    "    if \"mf_pred\" in test_df.columns:\n",
    "        mf_vec = test_df[\"mf_pred\"].to_numpy().reshape(-1)\n",
    "    if \"td_pred\" in test_df.columns:\n",
    "        td_vec = test_df[\"td_pred\"].to_numpy().reshape(-1)\n",
    "    if \"notopic_trained_pred\" in test_df.columns:\n",
    "        nt_tr_vec = test_df[\"notopic_trained_pred\"].to_numpy().reshape(-1)\n",
    "\n",
    "# fallback to globals\n",
    "if mf_vec is None and \"mf_pred\" in globals():\n",
    "    mf_vec = np.asarray(mf_pred).reshape(-1)\n",
    "if td_vec is None and \"td_pred\" in globals():\n",
    "    td_vec = np.asarray(td_pred).reshape(-1)\n",
    "\n",
    "# trained no-topic (preferred ablation)\n",
    "if nt_tr_vec is None:\n",
    "    if \"no_topic_pred_trained\" in globals():\n",
    "        nt_tr_vec = np.asarray(no_topic_pred_trained).reshape(-1)\n",
    "\n",
    "# diagnostic (inference-time removal; not fair)\n",
    "nt_diag_vec = np.asarray(no_topic_pred).reshape(-1) if \"no_topic_pred\" in globals() else None\n",
    "if nt_diag_vec is None and \"nt_pred\" in globals():  # alternate naming\n",
    "    nt_diag_vec = np.asarray(nt_pred).reshape(-1)\n",
    "\n",
    "def _safe_metrics(pred):\n",
    "    if y is None or pred is None:\n",
    "        return None, None\n",
    "    if len(pred) != len(y):\n",
    "        return None, None\n",
    "    return _rmse_np(pred, y), _mae_np(pred, y)\n",
    "\n",
    "rmse_mf_val, mae_mf_val = _safe_metrics(mf_vec)\n",
    "rmse_td_val, mae_td_val = _safe_metrics(td_vec)\n",
    "rmse_nt_tr, mae_nt_tr   = _safe_metrics(nt_tr_vec)\n",
    "rmse_nt_diag, mae_nt_diag = _safe_metrics(nt_diag_vec)\n",
    "\n",
    "# deltas (positive means second model is better)\n",
    "gain_rmse = (rmse_mf_val - rmse_td_val) if (rmse_mf_val is not None and rmse_td_val is not None) else None\n",
    "gain_mae  = (mae_mf_val  - mae_td_val)  if (mae_mf_val  is not None and mae_td_val  is not None) else None\n",
    "\n",
    "gain_rmse_tr = (rmse_mf_val - rmse_nt_tr) if (rmse_mf_val is not None and rmse_nt_tr is not None) else None\n",
    "gain_mae_tr  = (mae_mf_val  - mae_nt_tr)  if (mae_mf_val  is not None and mae_nt_tr  is not None) else None\n",
    "\n",
    "topic_contrib_rmse_tr = (rmse_nt_tr - rmse_td_val) if (rmse_nt_tr is not None and rmse_td_val is not None) else None\n",
    "topic_contrib_mae_tr  = (mae_nt_tr  - mae_td_val)  if (mae_nt_tr  is not None and mae_td_val  is not None) else None\n",
    "\n",
    "summary = f\"\"\"Results summary (aligned test set)\n",
    "• MF RMSE/MAE = {_fmt(rmse_mf_val)}/{_fmt(mae_mf_val)}\n",
    "• TDFM(full) RMSE/MAE = {_fmt(rmse_td_val)}/{_fmt(mae_td_val)}\n",
    "⇒ Improvement (MF − Full): ΔRMSE = {_fmt(gain_rmse)}, ΔMAE = {_fmt(gain_mae)}\n",
    "\n",
    "Ablation (trained no-topic; fair)\n",
    "• NoTopic(trained) RMSE/MAE = {_fmt(rmse_nt_tr)}/{_fmt(mae_nt_tr)}\n",
    "⇒ Improvement (MF − NoTopic trained): ΔRMSE = {_fmt(gain_rmse_tr)}, ΔMAE = {_fmt(gain_mae_tr)}\n",
    "⇒ Topic contribution (NoTopic trained − Full): ΔRMSE = {_fmt(topic_contrib_rmse_tr)}, ΔMAE = {_fmt(topic_contrib_mae_tr)}\n",
    "(Positive means the topic/text component helps rating prediction.)\n",
    "\n",
    "Notes\n",
    "• Ranking metrics are reported separately (Recall@K / NDCG@K with negative sampling).\n",
    "• If shown, “NoTopic (inference-time removal)” is *diagnostic only* and not a fair ablation because it was not retrained.\n",
    "\"\"\"\n",
    "\n",
    "print(summary.strip())\n",
    "\n",
    "if rmse_nt_diag is not None and mae_nt_diag is not None:\n",
    "    print(\"\\n[Diagnostic only] NoTopic (inference-time removal) RMSE/MAE \"\n",
    "          f\"= {_fmt(rmse_nt_diag)}/{_fmt(mae_nt_diag)}  (not a fair ablation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9cba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IPW] MF weighted metrics:\n",
      "  wRMSE: 0.7341895794831151\n",
      "  wMAE : 0.4821402802727599\n",
      "  weight stats: {'min': 1.019637531802377, 'median': 2.064338779294771, 'mean': 2.968049250916938, 'max': 34.51639776377884}\n"
     ]
    }
   ],
   "source": [
    "# ==== FINAL: Propensity model + IPW-weighted RMSE (ROBUST; uses loaders) ====\n",
    "\n",
    "# --- hard guardrails ---\n",
    "assert \"n_users\" in meta and \"n_items\" in meta, \"meta must contain n_users/n_items\"\n",
    "assert \"mf_train_loader\" in globals() and \"mf_test_loader\" in globals(), \"Need mf_train_loader and mf_test_loader\"\n",
    "assert \"mf_model\" in globals(), \"Need mf_model\"\n",
    "assert \"SEED\" in globals(), \"Need SEED\"\n",
    "assert \"DEVICE\" in globals(), \"Need DEVICE\"\n",
    "\n",
    "# check the helper funcs exist\n",
    "assert \"weighted_rmse\" in globals() and \"weighted_mae\" in globals(), \"Run Block 0 (helpers) first\"\n",
    "\n",
    "# --- Collect observed TRAIN pairs from MF train loader ---\n",
    "u_tr_list, i_tr_list, y_tr_list = [], [], []\n",
    "for (u, it, r) in mf_train_loader:\n",
    "    u_tr_list.append(u.detach().cpu().numpy().astype(np.int64).reshape(-1))\n",
    "    i_tr_list.append(it.detach().cpu().numpy().astype(np.int64).reshape(-1))\n",
    "    y_tr_list.append(r.detach().cpu().numpy().astype(np.float32).reshape(-1))\n",
    "\n",
    "u_tr = np.concatenate(u_tr_list)\n",
    "i_tr = np.concatenate(i_tr_list)\n",
    "y_tr = np.concatenate(y_tr_list)\n",
    "\n",
    "# --- Collect observed TEST pairs from MF test loader ---\n",
    "u_te_list, i_te_list, y_te_list = [], [], []\n",
    "for (u, it, r) in mf_test_loader:\n",
    "    u_te_list.append(u.detach().cpu().numpy().astype(np.int64).reshape(-1))\n",
    "    i_te_list.append(it.detach().cpu().numpy().astype(np.int64).reshape(-1))\n",
    "    y_te_list.append(r.detach().cpu().numpy().astype(np.float32).reshape(-1))\n",
    "\n",
    "u_te = np.concatenate(u_te_list)\n",
    "i_te = np.concatenate(i_te_list)\n",
    "y_te = np.concatenate(y_te_list)\n",
    "\n",
    "n_users = int(meta[\"n_users\"])\n",
    "n_items = int(meta[\"n_items\"])\n",
    "\n",
    "# --- Simple exposure features: user/item activity in TRAIN ---\n",
    "user_deg = np.bincount(u_tr, minlength=n_users)\n",
    "item_deg = np.bincount(i_tr, minlength=n_items)\n",
    "\n",
    "def prop_features(u, i):\n",
    "    return np.column_stack([np.log1p(user_deg[u]), np.log1p(item_deg[i])]).astype(np.float32)\n",
    "\n",
    "# --- Build observed TRAIN set to avoid sampling positives as negatives ---\n",
    "obs_train = set((u_tr * n_items + i_tr).tolist())\n",
    "\n",
    "# --- Negative sampling from full grid ---\n",
    "rng = np.random.default_rng(SEED)\n",
    "n_pos = len(u_tr)\n",
    "n_neg = min(n_pos, 200_000)  # cap for speed; adjust if you want\n",
    "\n",
    "neg_u, neg_i = [], []\n",
    "while sum(len(x) for x in neg_u) < n_neg:\n",
    "    uu = rng.integers(0, n_users, size=n_neg, endpoint=False)\n",
    "    ii = rng.integers(0, n_items, size=n_neg, endpoint=False)\n",
    "    keys = uu.astype(np.int64) * n_items + ii.astype(np.int64)\n",
    "    keep = np.array([k not in obs_train for k in keys], dtype=bool)\n",
    "    neg_u.append(uu[keep])\n",
    "    neg_i.append(ii[keep])\n",
    "\n",
    "neg_u = np.concatenate(neg_u)[:n_neg]\n",
    "neg_i = np.concatenate(neg_i)[:n_neg]\n",
    "\n",
    "# --- Fit propensity model: A=1 for observed train, A=0 for sampled negatives ---\n",
    "X_pos = prop_features(u_tr, i_tr)\n",
    "X_neg = prop_features(neg_u, neg_i)\n",
    "X = np.vstack([X_pos, X_neg])\n",
    "A = np.concatenate([np.ones(len(X_pos)), np.zeros(len(X_neg))])\n",
    "\n",
    "prop_model = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "prop_model.fit(X, A)\n",
    "\n",
    "# --- Propensity for TEST observed pairs ---\n",
    "p_te = prop_model.predict_proba(prop_features(u_te, i_te))[:, 1]\n",
    "\n",
    "# --- IPW weights (clipped) ---\n",
    "eps = 1e-3\n",
    "w_cap = 50.0\n",
    "w_te = 1.0 / np.clip(p_te, eps, 1.0)\n",
    "w_te = np.minimum(w_te, w_cap)\n",
    "\n",
    "# --- Predict MF on (u_te, i_te) ---\n",
    "@torch.no_grad()\n",
    "def predict_mf_pairs(mf_model, u_np, i_np, device=DEVICE, batch_size=4096):\n",
    "    mf_model.eval()\n",
    "    preds = []\n",
    "    for s in range(0, len(u_np), batch_size):\n",
    "        e = min(s + batch_size, len(u_np))\n",
    "        uu = torch.as_tensor(u_np[s:e], dtype=torch.long, device=device)\n",
    "        ii = torch.as_tensor(i_np[s:e], dtype=torch.long, device=device)\n",
    "        preds.append(mf_model(uu, ii).detach().cpu().numpy().reshape(-1))\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "yhat_te_mf = predict_mf_pairs(mf_model, u_te, i_te)\n",
    "\n",
    "print(\"[IPW] MF weighted metrics:\")\n",
    "print(\"  wRMSE:\", weighted_rmse(yhat_te_mf, y_te, w_te))\n",
    "print(\"  wMAE :\", weighted_mae(yhat_te_mf, y_te, w_te))\n",
    "print(\"  weight stats:\", {\"min\": float(w_te.min()), \"median\": float(np.median(w_te)), \"mean\": float(w_te.mean()), \"max\": float(w_te.max())})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_all: torch.Size([6085])\n",
      "items_all: torch.Size([6085])\n",
      "ratings_all: torch.Size([6085])\n",
      "item_universe: (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"users_all:\", getattr(users_all, \"shape\", None))\n",
    "print(\"items_all:\", getattr(items_all, \"shape\", None))\n",
    "print(\"ratings_all:\", getattr(ratings_all, \"shape\", None))\n",
    "\n",
    "if \"item_universe\" in globals():\n",
    "    print(\"item_universe:\", getattr(item_universe, \"shape\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IPW] TDFM(full) weighted metrics:\n",
      "  wRMSE: 0.6546291675036227\n",
      "  wMAE : 0.4013683465222231\n",
      "  weight stats: {'min': 1.019637531802377, 'median': 2.064338779294771, 'mean': 2.968049250916938, 'max': 34.51639776377884}\n"
     ]
    }
   ],
   "source": [
    "# ==== IPW metrics for TDFM(full) ====\n",
    "\n",
    "# In this notebook, the TDFM data loader is named td_test_loader (5-tuple: u,i,bow,exposure,y),\n",
    "# and the trained model is stored in tdfm_model (loaded earlier if needed).\n",
    "\n",
    "assert \"td_test_loader\" in globals(), \"td_test_loader not found. Re-run the loader creation cell (make_loaders_tdfm).\"\n",
    "assert \"tdfm_model\" in globals(), \"tdfm_model not found. Re-run the evaluation cell that loads tdfm_model.pt.\"\n",
    "\n",
    "tdfm_te_loader = td_test_loader\n",
    "tdfm_full = tdfm_model\n",
    "tdfm_full.eval()\n",
    "tdfm_full.to(DEVICE)\n",
    "\n",
    "assert \"prop_model\" in globals() and \"prop_features\" in globals(), \"propensity model (prop_model/prop_features) not found. Run the MF IPW cell first.\"\n",
    "\n",
    "# 3) Collect TEST pairs (u,i,bow,exposure,y) from the TDFM test loader\n",
    "u_te_list, i_te_list, bow_te_list, exp_te_list, y_te_list = [], [], [], [], []\n",
    "for (u, it, bow, exp, y) in tdfm_te_loader:\n",
    "    u_te_list.append(u.detach().cpu().numpy().astype(np.int64).reshape(-1))\n",
    "    i_te_list.append(it.detach().cpu().numpy().astype(np.int64).reshape(-1))\n",
    "    bow_te_list.append(bow.detach().cpu().numpy())   # keep 2D\n",
    "    exp_te_list.append(exp.detach().cpu().numpy())   # keep shape (n,1) or (n,)\n",
    "    y_te_list.append(y.detach().cpu().numpy().astype(np.float32).reshape(-1))\n",
    "\n",
    "u_te_t = np.concatenate(u_te_list)\n",
    "i_te_t = np.concatenate(i_te_list)\n",
    "bow_te = np.vstack(bow_te_list)\n",
    "exp_te = np.vstack(exp_te_list) if exp_te_list[0].ndim == 2 else np.concatenate(exp_te_list).reshape(-1, 1)\n",
    "y_te_t = np.concatenate(y_te_list)\n",
    "\n",
    "# 4) Compute propensities + weights for these TEST pairs (same prop_model)\n",
    "p_te_t = prop_model.predict_proba(prop_features(u_te_t, i_te_t))[:, 1]\n",
    "eps = 1e-3\n",
    "w_cap = 50.0\n",
    "w_te_t = 1.0 / np.clip(p_te_t, eps, 1.0)\n",
    "w_te_t = np.minimum(w_te_t, w_cap)\n",
    "\n",
    "# 5) Predict TDFM on these pairs\n",
    "@torch.no_grad()\n",
    "def predict_tdfm_pairs(model, u_np, i_np, bow_np, exp_np, device=DEVICE, batch_size=2048):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for s in range(0, len(u_np), batch_size):\n",
    "        e = min(s + batch_size, len(u_np))\n",
    "        uu = torch.as_tensor(u_np[s:e], dtype=torch.long, device=device)\n",
    "        ii = torch.as_tensor(i_np[s:e], dtype=torch.long, device=device)\n",
    "        bb = torch.as_tensor(bow_np[s:e], dtype=torch.float32, device=device)\n",
    "        ex = torch.as_tensor(exp_np[s:e], dtype=torch.float32, device=device)\n",
    "        yhat, _ = model(uu, ii, bb, ex)\n",
    "        preds.append(yhat.detach().cpu().numpy().reshape(-1))\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "yhat_te_tdfm = predict_tdfm_pairs(tdfm_full, u_te_t, i_te_t, bow_te, exp_te)\n",
    "\n",
    "print(\"[IPW] TDFM(full) weighted metrics:\")\n",
    "print(\"  wRMSE:\", weighted_rmse(yhat_te_tdfm, y_te_t, w_te_t))\n",
    "print(\"  wMAE :\", weighted_mae(yhat_te_tdfm, y_te_t, w_te_t))\n",
    "print(\"  weight stats:\", {\"min\": float(w_te_t.min()), \"median\": float(np.median(w_te_t)),\n",
    "                        \"mean\": float(w_te_t.mean()), \"max\": float(w_te_t.max())})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfintel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
